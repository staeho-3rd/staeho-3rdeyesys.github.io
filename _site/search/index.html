<!DOCTYPE html>

<html lang="kr">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="preconnect" href="https://fonts.gstatic.com">
		<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">
		<link rel="stylesheet" href="/css/screen.css">
		<link rel="apple-touch-icon" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
		<link rel="icon" type="image/png" href="/images/favicon.png">
		
		<!--link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700"-->

		
			<script async src="https://www.googletagmanager.com/gtag/js?id=G-4Q6RVEFJ3S"></script>
			<script>
			  window.dataLayer = window.dataLayer || [];
			  function gtag(){dataLayer.push(arguments);}
			  gtag('js', new Date());

			  gtag('config', 'G-4Q6RVEFJ3S');
			</script>
		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Search | 3rdeyesys</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="Search" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="써드아이시스템 기술문서" />
<meta property="og:description" content="써드아이시스템 기술문서" />
<link rel="canonical" href="https://docs.3rdeyesys.com/search/" />
<meta property="og:url" content="https://docs.3rdeyesys.com/search/" />
<meta property="og:site_name" content="3rdeyesys" />
<script type="application/ld+json">
{"url":"https://docs.3rdeyesys.com/search/","headline":"Search","description":"써드아이시스템 기술문서","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://docs.3rdeyesys.com/siteicon.png"}},"@type":"WebPage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="https://docs.3rdeyesys.com/feed.xml" title="3rdeyesys" />

		<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
					<div class="logo"><a href="/"><img src="/images/title_logo_white.png" style="width:160px;height:33px;margin-top:5px"></a></div>
					<a class="nav-toggle" id="open-nav" href="#">&#9776;</a>
<nav>
	<a class="editor-link btn" href="cloudcannon:collections/_data/navigation.yml" class="btn" style="padding: 5px;"><strong>&#9998;</strong> Edit navigation</a>
	
	

		
		<a href="/" class="" target="_self">Docs<img src="/images/new_dot_10x10.png" style="width:8px;margin-left:3px;vertical-align:top;"></a>

	
	

		
		<a href="/update/" class="" target="_self">Update<img src="/images/new_dot_10x10.png" style="width:8px;margin-left:3px;vertical-align:top;"></a>

	
	

		
		<a href="/faq/" class="" target="_self">FAQ<img src="/images/new_dot_10x10.png" style="width:8px;margin-left:3px;vertical-align:top;"></a>

	
	

		
		<a href="/news/" class="" target="_self">NEWS<img src="/images/new_dot_10x10.png" style="width:8px;margin-left:3px;vertical-align:top;"></a>

	
	

		
		<a href="https://3rdeyesys.com" class="" target="_blank">Company</a>

	
	

		
		<a href="https://www.3rdeyesys.com/question/" class="" target="_blank">1:1 문의하기</a>

	
	
		<span style="width:100px"><form action="/search/" method="get">
	<input type="search" name="q"  placeholder="Search" autofocus>
	<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
	<input type="submit" value="Search" style="display: none;">
</form></span>
	
</nav>

				</section>
				<section class="hero_search">
					<h1>써드아이시스템(3rdeyesys) 기술문서</h1>
					<p>써드아이시스템이 네이버 클라우드 프리미엄 파트너사로 활동하면서 보유하게 된 네이버 클라우드와 관련된 여러 기술 노하우들을 많은 분들께 공유하려고 합니다.</p>
					<form action="/search/" method="get">
	<input type="search" name="q"  placeholder="Search" autofocus>
	<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
	<input type="submit" value="Search" style="display: none;">
</form>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>
<ul id="search-results"></ul>

<script>
	window.data = {
		
			
				
					
					
					"1-compute-ncloud-server-x-forwarded-for-client-ip-logging-guide": {
						"id": "1-compute-ncloud-server-x-forwarded-for-client-ip-logging-guide",
						"title": "X-Forwarded-For를 이용해 Proxy, Load Balancer 환경에서 Client IP 기록하기",
						"categories": "1.compute",
						"url": " /1.compute/ncloud_server_x_forwarded_for_client_ip_logging_guide/",
						"content": "개요\nX-Forwarded-For (XFF) 는 HTTP Header 중 하나로 Load Balancer(로드밸런서)나 Proxy Server를 통해 웹서버에 접속하는 Client의 IP 주소를 식별하는 표준 헤더입니다.\n웹서버나 WAS 앞쪽에 Load Balancer 혹은 Proxy Server 등이 위치하게 된다면 서버 접근 로그에는 Client IP가 아닌 Load Balancer 혹은 Proxy Server의 IP 주소가 기록됩니다. \n이때 웹 어플리케이션에서 X-Forwarded-For 헤더를 이용하면 Client IP를 서버 접근 로그에 남길 수 있습니다.\n\n여기서는 Load Balancer와 연동된 CentOS 와 Ubuntu의 Apache 웹서버 환경에서 X-Forwarded-For 를 이용하여 Apache access_log에 Clinet의 IP를 저장하는 과정을 살펴보겠습니다.\n\n테스트 환경\n테스트는 CentOS, Ubuntu OS가 각각 설치된 2대의 서버를 Load Balancer와 연동한 후 Cloud Log Analytics에서 Apache access_log를  수집해 IP 주소를 확인하는 방식으로 진행하겠습니다.\n\nNetwork 환경\n\n  VPC 대역 : 172.16.0.0/16\n  Subnet 대역 (Server) : 172.16.10.0/24\n  Sbunet 대역 (Load Balancer) : 172.16.20.0/24\n\n\nServer 환경\n\n  xxf-test-1 : CentOS 7.8\n  xxf-test-2 : Ubuntu 18.04\n\n\n테스트 서버\n위 서버 환경에서 정리한 대로 CentOS, Ubuntu 2대의 서버를 준비했습니다.\n\n\n  VPC 환경에서 서버 생성하는 방법 : https://docs.3rdeyesys.com/1.compute/ncp_server_vpc_create/\n\n\n\n\n로드밸런서도 마찬가지로 준비하고, 서버와 연동까지 완료했습니다.\n\n\n  VPC 환경에서 Application Load Balancer 생성하는 방법 : https://docs.3rdeyesys.com/2.networking/ncp_networking_load_balancer_application_lb/\n\n\n\n\n설정 전 테스트\n우선, X-Forwarded-For (XFF) 설정을 하기 전에 어떻게 기록이 남는지 확인해보겠습니다.\n아래와 같이 Load Balancer 주소로 접속해서 2대의 서버에 각각 접근하도록 합니다.\n위에서 소개한 Application Load Balancer 생성하는 방법을 그대로 따라하면 아래와 같은 메시지를 확인할 수 있습니다.\n\n\n\n\n\nApache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하지만, 저희는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해보겠습니다.\n\n  CentOS : /var/log/httpd/access_log\n  \n    Ubuntu : /var/log/apache2/access.log\n  \n  Cloud Log Analytics 설정 가이드 : https://docs.3rdeyesys.com/7.analytics/ncloud_analytics_cloud_log_analytics_guide/\n\n\nCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 Load Balancer의 IP 대역 (172.16.20.xx)이 기록된 것을 확인할 수 있습니다.\n\n\n\nCentOS 설정\n이제 실제 Client IP가 기록 되도록 설정을 변경해보겠습니다.\n우선 CentOS에서는 httpd.conf 파일만 수정하면 됩니다.\n\n~# vi /etc/httpd/conf/httpd.conf\n\n# vi Line Number 표시하기\n:set number\n\n\nhttpd.conf 파일 196번째 라인의 LogFormat 항목에서 %h 를 %{X-Forwarded-For}i 로 수정합니다.\n\nhttpd.conf 수정 전\n196   LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined\n\n\n\nhttpd.conf 수정 후\n196   LogFormat \"%{X-Forwarded-For}i %l %u %t \\\"%r\\\" %&gt;s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined\n\n\n\nApache 재시작\nhttpd.conf 파일 수정 후에 Apache를 재시작합니다. 로그 테스트는 Ubuntu까지 설정을 마친 후에 진행하겠습니다.\n\n~# systemctl restart httpd\n\n\nUbuntu 설정\nUbuntu에서는 apache2.conf 파일을 수정하기 전에 remoteip 모듈을 사용하도록 설정해줘야 합니다.\n\nremoteip 설정\n아래 명령어를 실행하면 remoteip 모듈이 활성화 됩니다.\n\n~# a2enmod remoteip\n\n\n\nremoteip.load 수정\n다음으로 remoteip.load 파일을 수정해서 아래쪽에 [RemoteIPHeader X-FORWARDED-FOR]을 추가 합니다.\n\n~# vi /etc/apache2/mods-enabled/remoteip.load\n\n\nremoteip.load 수정 전\nLoadModule remoteip_module /usr/lib/apache2/modules/mod_remoteip.so\n\nremoteip.load 수정 후\nLoadModule remoteip_module /usr/lib/apache2/modules/mod_remoteip.so\nRemoteIPHeader X-FORWARDED-FOR\n\n\n\napache2.conf 수정\n다음으로 apache2.conf 파일을 수정합니다.\n\n~# vi /etc/apache2/apache2.conf\n\n# vi Line Number 표시하기\n:set number\n\n\napache2.conf 213번째 라인의 LogFormat 부분에서 %h 를 %a 로 변경합니다.\n\napache2.conf 수정 전\n213 LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined  \n\n\n\napache2.conf 수정 후\n213 LogFormat \"%a %l %u %t \\\"%r\\\" %&gt;s %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined  \n\n\n\nApache 재시작\n~# systemctl restart apache2\n\n\n설정 후 테스트\n위와 같이  CentOS, Ubuntu 2대 서버에서 설정을 모두 마친 후에 로드 밸런서 URL로 접속합니다.\n이후에 Cloud Log Analytics에서 로그를 확인해보면 아래와 같이 로드밸런서 IP가 아닌 실제 접속한 Client의 IP가 기록된 것을 확인할 수 있습니다.\n\n\n\n참고 URL\n\n  X-Forwarded-For 안내\n    \n      https://developer.mozilla.org/ko/docs/Web/HTTP/Headers/X-Forwarded-For\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-12-17"
					}
					
				
			
		
			
				
					,
					
					"7-analytics-ncloud-analytics-cloud-log-analytics-guide": {
						"id": "7-analytics-ncloud-analytics-cloud-log-analytics-guide",
						"title": "Cloud Log Analytics 설정 가이드",
						"categories": "7.analytics",
						"url": " /7.analytics/ncloud_analytics_cloud_log_analytics_guide/",
						"content": "개요\nCloud Log Analytics는 Ncloud(네이버 클라우드)가 제공하는 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석할 수 있는 서비스로, \n검색 기능을 이용해 여러 종류의 로그를 한 곳에서 한번에 조회하고 분석할 수 있어 효과적인 로그 관리가 가능합니다.\n\n로그 템플릿 종류\nCloud Log Analytics는 텍스트 형식으로 생성되는 모든 종류의 로그 데이터 파일을 수집할 수 있는데, 사전에 제공되는 로그 템플릿 종류는 다음과 같습니다.\n\n\n  Server syslog\n  Apache 로그(Access log, Apache Error Log)\n  MySQL 설치형 상품의 로그(Error Log, Slow Log)\n  Microsoft SQL Server 설치형 상품의 Error Log\n  Tomcat 로그(Catalina Log)\n  Windows 서버의 Event Log\n  Windows 서버의 각종 text 형식의 로그\n  Cloud DB for MySQL 로그\n  Cloud DB for MSSQL 로그\n  Cloud DB for MongoDB 로그\n  Application Server Launcher 로그\n  Application Load Balancer 로그\n  Search Engine Service 로그\n  Cloud Data Streaming Service 로그\n  Bare Metal Server 로그\n  그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다\n\n\n저장 용량\n\n  최대 100GB까지 저장할 수 있습니다.\n  100GB 용량을 초과했을 경우 추가 저장 용량 확보를 위해 과거부터 전날까지의 데이터가 삭제될 수 있습니다.\n  CLA로 수집되는 로그량이 하루 10GB 이상을 넘거나 천만 건 이상일 경우 저장된 로그 검색시 성능에 제한이 발생할 수 있습니다.\n  저장 용량과 저장 기간을 더 늘리길 원할 경우 고객지원으로 문의해야 합니다.\n  과거 데이터를 보관하려면 [자동 보내기] 기능을 이용하여 과거 데이터를 Object Storage로 백업할 수 있습니다.\n\n\n로그 보관 기간\n\n  Cloud Log Analytics 서비스는 최대 30일 동안 데이터가 보관되며, 검색 및 대시보드에서 확인할 수 있습니다.\n  30일이 지난 데이터는 과거 데이터부터 순차적으로 삭제됩니다.\n  30일이 지나지 않았더라도 저장된 데이터가 100GB를 초과하면 과거부터 전날까지의 데이터가 매일 삭제될 수 있습니다.\n\n\n이용신청\nNcloud(네이버 클라우드) 콘솔 [Cloud Log Analytics] - [Subscription]에서 [이용 신청] 버튼을 클릭합니다. \nCloud Log Analytics는 Classic, VPC 환경 공통 서비스이므로 어느쪽 환경에서 이용신청을 해도 상관없습니다.\n\n\n\n설정 - Linux\n먼저 Linux 서버에서 설정하는 방법을 알아보겠습니다.\n[Cloud Log Analytics] - [Management]에서 로그를 수집할 서버를 선택하고, [수집 설정] 버튼을 클릭합니다.\n\n\n\nLog 수집 설정 화면에서 수집할 로그 템플릿을 선택하거나, 직접 [Custom Log]를 선택해서 로그 형태를 설정한 후에 [적용] 버튼을 클릭합니다.\n\n\n\n로그 수집 Agent 설치\nLog 수집 설정을 마치면 [로그 수집 Agent] 설치 안내가 나옵니다.\n로그 수집 Agent 설치 명령어에는 URL 뒤쪽에 설치 하려는 서버에 해당하는 설치키(Install Key)가 포함되어 있습니다. 그러므로 URL을 수정해서도 안되고 다른 서버에 사용할 수도 없습니다.\n\n# VPC 환경\n~# curl -s http://cm.vcla.ncloud.com/setUpClaVPC/{설치키(Install Key)} | sudo sh\n\n# Classic 환경\n~# curl -s http://cm.cla.ncloud.com/setUpCla/{설치키(Install Key)} | sudo sh\n\n\n\n\n서버에 실제로 설치해보면 아래와 같이 설치 과정이 진행되고,\n설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n\n\n\n설치된 Agent가 제대로 작동하고 있는지 확인해보면 아래와 같이 active (running) 상태인 것을 확인할 수 있습니다.\n~# systemctl status filebeat\n\n\n\n설정 - Windows\n다음으로 Windows 서버에서 설정하는 방법을 살펴보겠습니다.\n마찬가지로 서버를 선택하고 [수집 설정] 버튼을 클릭합니다.\n\n\n\n로그 수집 설정에서 Log Template은 [EventLog]를 선택합니다.\n\n\n\n설정을 마치면 Agent 설치 가이드를 확인할 수 있습니다.\n서버에서 [Windows PowerShell]을 열고, 아래 명령어를 실행합니다. 마찬가지로 마지막에는 설치 서버에 해당하는 설치키가 포함되어 있습니다.\n\n# VPC 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\n\n# Classic 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\n\n\n\n설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n\n\n\nWindows Server 2019 지원 여부\n현재 Windows Server 2019는 지원하지 않고, 2022년 상반기 지원 예정입니다.\nWindows Server 2019는 아래와 같이 선택을 해도 [수집 설정] 버튼을 활성화되지 않습니다.\n\n\n\n로그 확인\nAgent 설치 후 [Dashboard]를 확인해보면 로그가 수집되고 있을 것을 알 수 있습니다.\n\n\n\n[Search] 메뉴에서는 로그 내용을 자세히 검색, 확인할 수 있고, 굳이 서버에 접속하지 않더라도 필요한 로그를 콘솔 화면에서 직접 확인할 수 있습니다.\n\n\n\n로그 백업\nCloud Log Analytics는 수집된 로그를 Object Storage로 내보내기하거나 Excel 파일로 다운로드 해서 백업할 수 있는 기능을 지원합니다.\n\n수동 백업\n[Search] 메뉴에 [Object Storage로 내보내기]와 [X 다운로드] 버튼이 있습니다.\n\n\n\n[Object Storage로 내보내기] 버튼을 클릭하면 내보내기 할 버킷을 선택할 수 있습니다.\n\n\n\n자동 백업\n[Export Log] 메뉴에서 [자동 내보내기 설정]을 클릭합니다.\n\n\n\n설정 화면에서 내보내기를 할 Object Storage의 버킷을 선택합니다. 혹시 버킷이 생성되지 않았다면 Object Storage로 가서 먼저 버킷을 생성하고 와야 합니다.\n\n\n\n내보내기는 하루에 한번 진행되므로 설정 후 다음 날 Object Storage에서 아래와 같이 파일이 저장되어 있는 것을 확인할 수 있습니다.\n\n\n\n로그 수집 해제\n더 이상 로그를 수집할 필요가 없어지면, 로그 수집 설정을 해제하면 됩니다.\n\nLinux 서버 로그 수집 해제\n서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n\n\n\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\n\n# VPC 환경\n~# curl -s http://cm.vcla.ncloud.com/removeCla | sudo sh\n\n# Classic 환경\n~# curl -s http://cm.cla.ncloud.com/removeCla | sudo sh\n\n\n\nAgent 삭제 명령어를 실행하면 아래와 같이 Success Remove Agent 메시지가 출력됩니다.\n\n\n\nWindows 서버 로그 수집 해제\n마찬가지로 서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n\n\n\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\n\n# VPC 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/removewinCla\"))\n\n# Classic 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/removewinCla\"))\n\n\n\nAgent 삭제 명령어를 실행하면 아래와 같이 Remove Agent 메시지가 출력됩니다.\n\n\n\nWindows 서버 Agent 삭제 오류 상황\nWindows 서버에서 Agent 삭제를 시도할 때 아래와 같이 오류 메시지가 발생하는 경우가 있습니다.\n이때는 당황하지 마시고, Agent 삭제 명령어를 다시 한번 실행하면 됩니다.\n\n오류의 원인 : 로그 수집 설정에서 EventLog만 선택했을 경우 발생합니다.\n로그 수집 Agent는 윈도 이벤트 로그 수집을 위한 winlogbeat와 그 외 로그를 수집하기 위한 filebeat 두가지가 설치되는데, EventLog만 수집하도록 설정할 경우 filebeat는 실행되지 않습니다. \n그 상태에서 Agent를 삭제하려고 하면 실행중이 아닌 filebeat를 실행 중지 시키려고 시도하게 되고, 결국 오류가 발생합니다.\n그러므로 심각한 오류는 아니고 만약을 위해 Agent 삭제 명령어를 한번 더 실행시키는 것으로 문제는 해결됩니다.\n\nStop-Service : Cannot find any service with service name 'filebeat'.\n\n\n\n\n참고 URL\n\n  Cloud Log Analytics 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/cla-cla-1-1\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-12-14"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncloud-database-cdb-mysql-restore-error-1227-troubleshooting": {
						"id": "5-database-ncloud-database-cdb-mysql-restore-error-1227-troubleshooting",
						"title": "MySQL 복구 시 ERROR 1227 (42000) 문제 원인과 해결방법",
						"categories": "5.database",
						"url": " /5.database/ncloud_database_cdb_mysql_restore_error_1227_troubleshooting/",
						"content": "개요\n네이버 클라우드(Ncloud) Cloud DB for MySQL을 사용하면서 백업 데이터를 복구 하려고 할 때 ERROR 1227 (42000) 오류가 발생하는 경우가 있습니다. \n오류 메시지로만 보면 계정 권한에 문제가 있는 것처럼 보이는데 정확하게 문제 원인이 무엇인지, 그리고 해결방법은 어떤 것이 있는지 정리해보겠습니다.\n\n오류 메시지\n전체 오류 메시지는 아래와 같습니다.\n이 오류 메시지의 원인은 크게 2가지로 구분할 수 있는데, 상황에 따라 각각의 원인 1가지에 해당하는 경우도 있고, 2가지 원인이 모두 해당되는 경우도 있습니다.\n\nERROR 1227 (42000) at line 77: Access denied; you need (at least one of) the SUPER privilege(s) for this operation\n\n\n원인 1\n첫번째 원인은 GTID(global transaction identifier)와 관련되어 있습니다.\n네이버 클라우드(Ncloud) Cloud DB for MySQL 상품은 GTID(Global Transaction IDentifier)를 사용하는데, \n보통의 mysql db 복구(Restore)는 GTID를 사용하지 않는 방법이기 때문에 백업(Backup) 단계에서 [–set-gtid-purged=OFF] 옵션을 추가해야 하는데 이 옵션을 사용하지 않았기 때문입니다.\n\nGTID 란?\nGTID는 Global Transaction Identifier의 약자로 MySQL 복제에서 서버의 각 트랜잭션을 구분하는 고유한 식별자입니다. \nGTID는 모든 트랜잭션과 1:1 관계이며, GTID를 활용하면 복제본으로 장애 조치, 계층적 복제, 특정 시점으로 백업 복구하는 등의 작업을 더 쉽게 구현할 수 있으며, 오류 발생 빈도도 줄일 수 있습니다.\n\n오류 상황 재현\n아래와 같이 서버에서 mysqldump 명령으로 Cloud DB for MySQL DB를 백업 받는 상황을 가정해보겠습니다. 여기서는 [–set-gtid-purged=OFF] 옵션을 사용하지 않았습니다.\n[–set-gtid-purged=OFF] 옵션을 사용하지 않고, 백업을 받으면 백업은 정상 진행되지만, 아래와 같이 [–set-gtid-purged=OFF] 해야 한다는 Warning 메시지가 표시됩니다.\n\n~# mysqldump -u user -p -h db-......vpc-cdb.ntruss.com -S /var/lib/mysql/mysql.sock --single-transaction --routines --triggers --events --databases test  &gt; dumpfile1.sql\n\n\n\n\n위에서 생성한 [–set-gtid-purged=OFF] 옵션을 사용하지 않은 백업 파일(dumpfile1.sql)을 이용해서 복구(Restore)시에 아래와 같이 ERROR 1227 (42000) 오류가 발생하면서 복구가 되지 않습니다.\n\n~# mysql -h db-......vpc-cdb.ntruss.com -u user -p &lt; ./dumpfile1.sql\n\n\n\n해결 방법 1\n이번에는 Warning 메시지에 나온 것처럼 [–set-gtid-purged=OFF] 옵션을 사용해서 백업을 받아 보겠습니다.\n\n~# mysqldump --set-gtid-purged=OFF -u user -p -h db-......vpc-cdb.ntruss.com -S /var/lib/mysql/mysql.sock --single-transaction --routines --triggers --events --databases test  &gt; dumpfile2.sql\n\n\n\n\n[–set-gtid-purged=OFF] 옵션을 사용해서 생성한 백업 파일(dumpfile2.sql)을 이용해서 복구를 하면 아래와 같이 문제없이 복구가 잘됩니다.\n그런데 이렇게 옵션을 적용해도 동일한 오류가 발생하는 경우가 있는데 이에 대해서는 아래쪽 [원인 2]에서 확인해보겠습니다.\n\n~# mysql -h db-......vpc-cdb.ntruss.com -u user -p &lt; ./dumpfile2.sql\n\n\n\n해결 방법 2\n그런데 서비스를 하다 보면 DB 사이즈가 너무 커서 다시 백업을 진행하기 어렵다던가 하는 경우가 있습니다. 이럴 때는 백업 파일에 있는 GTID 관련 내용을 삭제하고 복구하시면 문제가 해결됩니다.\n백업 파일 상단과 하단에 각각 아래와 같은 코드가 포함되어 있는데 이 내용을 삭제하거나 주석처리한 후에 복구를 시도하면 문제 없이 복구가 완료됩니다.\n# 백업 파일 상단에 위치\nSET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION.SQL_LOG_BIN;\nSET @@SESSION.SQL_LOG_BIN= 0;\n\n# 백업 파일 하단에 위치\nSET @@GLOBAL.GTID_PURGED='207****-4***-7**-9*****c:1-12,\n2****-4**-9**-b**-d*****:1-19';\n\n\n원인 2\n위에서 설명한 [–set-gtid-purged=OFF]을 적용한 백업 파일을 이용해서 복구를 진행해도 동일한 오류가 발생하는 경우가 있는데 \n원인은 Trigger, Stored Routines (Procedures and Functions), View, Event 생성과 관련된 [DEFINER] 권한 때문입니다.  즉,  Trigger, Stored Routines (Procedures and Functions), View, Event를 생성한 계정과 DB 복구를 시도하는 계정이 다른 경우에 발생하는 문제입니다.\n\n[원인 1]에서는 복구를 시도할 때 [user] 계정을 사용했었는데 이 [user]계정으로 Trigger, Stored Routines (Procedures and Functions), View, Event 등을 생성한 상황에서 다른 계정 [new_user]를 이용해서 복구를 시도하는 상황을 가정보겠습니다. \n[new_user] 계정으로 복구를 시도하면 [–set-gtid-purged=OFF]을 적용한 백업 파일(dumpfile2.sql)을 이용했음에도 동일한 ERROR 1227 (42000) 오류가 발생하는 것을 확인할 수 있습니다.\n\n\n\n아래와 같이 MySQL은 보안 강화를 위해 Trigger, Stored Routines (Procedures and Functions), View, Event를 처음 생성한 계정을 [DEFINER]로 명시해 둠으로써 다른 계정으로 접근하지 못하도록 하는 것이 기본 설정이 되어 있습니다.\n그러므로 DB 복구를 시도할 때는 [DEFINER] 관련 내용을 삭제하거나 동일한 계정 또는 SUPER privilege를 가진 계정으로 복구해야 합니다.\n\n\n\n해결 방법 1\n첫번째 해결 방법은 백업 파일에서 [DEFINER] 관련 내용을 모두 찾아서 삭제하는 방법이 있습니다. \n여기서는 대표적으로 FUNCTION, PROCEDURE, VIEW에 해당하는 예시를 살펴보겠습니다.\n\nFUNCTION\nDB에서 FUNCTION을 사용했다면 아래와 같이 FUNCTION 생성 코드에 [CREATE DEFINER=`user`@`%` FUNCTION]처럼 계정이 표시되는데, 여기서 [DEFINER=`user`@`%`] 이 부분을 삭제하시면 됩니다.\n\n\n\nPROCEDURE\nDB에서 PROCEDURE를 사용했다면 아래와 같이 PROCEDURE 생성 코드에 [CREATE DEFINER=`user`@`%` PROCEDURE]처럼 계정이 표시되는데, 여기서 [DEFINER=`user`@`%`] 이 부분을 삭제하시면 됩니다.\n\n\nVIEW\nDB에서 VIEW를 사용했다면 아래와 같이 VIEW 생성 코드에 [/*!50013 DEFINER=`user`@`%` SQL SECURITY DEFINER */]처럼 계정이 표시되는데, 여기서는 이 라인을 모두 삭제하시면 됩니다.\n\n\n해결 방법 2\n두번째 해결 방법은 백업 파일 [DEFINER=]에 표시되어 있는 계정과 동일한 계정으로 복구를 진행하면 됩니다.\n\n참고 URL\n\n  Cloud DB for MySQL 백업, 복구 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-4\n    \n  \n  GTID를 이용한 Mysql 복제 가이드\n    \n      https://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html\n    \n  \n  GTID를 이용한 MariaDB 복제 가이드\n    \n      http://mariadb.com/kb/en/gtid/\n    \n  \n  MySQL Stored Object Access Control : DEFINER 안내\n    \n      https://dev.mysql.com/doc/refman/5.7/en/stored-objects-security.html\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-12-02"
					}
					
				
			
		
			
				
					,
					
					"81-manage-ncp-manage-classic-vs-vpc-guide": {
						"id": "81-manage-ncp-manage-classic-vs-vpc-guide",
						"title": "네이버 클라우드 Classic 환경 vs VPC 환경 비교",
						"categories": "81.manage",
						"url": " /81.manage/ncp_manage_classic_vs_vpc_guide/",
						"content": "개요\n네이버 클라우드 (nCloud)에는 Classic과 VPC 이렇게 2가지의 환경이 있습니다.\n각각의 특징을 장점을 중심으로 비교해보도록 하겠습니다.\n\nClassic 환경 장점 요약\n\n  서로 다른 계정의 서버들 간에 사설 통신 가능\n  리전간 서버들의 사설 통신 가능 (한국, 미국, 싱가포르, 홍콩, 일본, 독일)\n  다양한 설치형 서버 이미지 이용 가능\n\n\nVPC 환경 장점 요약\n\n  논리적으로 분리된 Network\n  사용자가 직접 Network 설계 가능\n  기존 고객의 데이터센터 네트워크와 유사하게 구현 가능\n  좀 더 상세하고, 높은 수준의 보안 설정 가능\n\n\n\nClassic 환경 장점 상세\n위에서 요약한 장점들을 좀 더 상세하게 살펴보겠습니다.\n\n서로 다른 계정의 서버들 간에 사설 통신 가능\n사용자가 2개 이상의 계정을 보유하고 있을 경우 각 계정에 생성된 서버들간에 사설 통신을 할 수 있습니다.\n\n리전간 서버들의 사설 통신 가능\n현재 네이버 클라우드는 한국, 미국, 싱가포르, 홍콩, 일본, 독일 이렇게 6개의 리전으로 서비스가 구분되어 있는데, 각 리전에 생성된 서버들끼리 사설 통신을 할 수 있습니다.\n\n다양한 설치형 서버 이미지 이용 가능\nClassic 환경에서는 LAMP, Wordpress 등 사용자들이 편하게 각 종 애플리케이션과 DB가 미리 설치된 서버를 쉽게 생성할 수 있도록 설치형 서버 이미지를 제공하고 있습니다. \n지원하는 주요 이미지는 다음과 같습니다.\n\n\n  Jenkins, Tensorflow, RabbitMQ, Pinpoint, LAMP, WordPress, Magento, Drupal, Joomla!, Shadowsocks, LEMP, Hugo, Gitlab CE, Node.js, Superset, Tomcat, JEUS, WebtoB, Gradle\n  MySQL, MSSQL, Cubrid, PostgreSQL, MariaDB, Redis, Tibero\n\n\nVPC 환경 장점 상세\n위에서 요약한 장점들을 좀 더 상세하게 살펴보겠습니다.\n\n논리적으로 분리된 Network\n\n  논리적으로 분리된 Network 체계를 제공하기 때문에 다른 이용자와의 간섭 없이 더 안전하고, 투명한 환경을 구현할 수 있습니다.\n\n\n사용자가 직접 Network 설계 가능\n\n  네트워크 서브넷(Subnet) 기능을 통해 용도에 따라 네트워크를 세분화하여 서비스 맞춤형 네트워크를 사용자가 직접 구성하실 수 있습니다\n  Load Balancer가 Application Load Balancer / Network Load Balancer / Network Proxy Load Balancer 등 3가지로 구분되어 있어, 고객이 각자의 서비스 환경에 최적화된 Load Balancer를 선택할 수 있습니다.\n  원하는 사설 IP 대역을 직접 할당할 수 있습니다. \n그러므로 사용해야 하는 사설 IP대역이 정해져 있어 변경할 수 없거나, 서버의 사설 IP를 변경하기 어려운 경우에도 VPC 환경에서는 원하는 대역의 원하는 IP를 직접 부여할 수 있습니다.\n\n\n기존 고객의 데이터센터 네트워크와 유사하게 구현 가능\n\n  기존 고객 데이터센터 네트워크와 유사하게 구현 가능합니다.\n즉, 기존에 AWS를 사용하고 있었던 고객은 AWS는 VPC 환경만 제공하기 때문에 거의 비슷하게 구현 가능합니다.\n또한 온프레미스 환경의 IDC 센터를 이용했던 고객이 클라우드 환경으로 마이그레이션해야 할 때 VPC 환경은 기존의 구조를 거의 그대로 구현해서 마이그레이션할 수 있습니다.\n\n\n좀 더 상세하고, 높은 수준의 보안 설정 가능\n\n  서버 측면에서 접근 제어를 위한 ACG(Access Control Group) 외에도,  네트워크 서브넷 측면에서 접근 제어를 할 수 있도록 NACL(Network Access Control List)을 제공합니다. \n이처럼 여러가지 접근제어 기능을 이용해 클라우드 상에서 발생할 수 있는 다양한 공격에 대한 대비가 가능합니다.\n  ACG, NACL등의 네트워크 접근제어 설정에서 Inbound, Outbound 각각에 대한 제어 설정 등 상세한 보안 설정을 직접 할 수 있습니다.\n\n\nVPC 환경 활용사례\n\n  \n    외부와 인터넷 연결이 필요한 서브넷과 이와 별개로 중요 데이터를 저장하기 위해 외부 접속을 최소화하기 위한 서브넷을 구성하는 경우\n하나의 서브넷에 인터넷 게이트웨이를 연결하여 프런트-엔드(Front-end) 전용 서브넷을 구성하고, 다른 하나의 서브넷에는 NAT 게이트웨이를 연결하여 백-엔드(Back-end)용 서브넷으로 활용\n  \n  \n    Cloud Connect만을 이용하여 접근할 수 있는 서브넷을 구성하는 경우\n Cloud Connect를 이용하여 On-Premise에 있는 고객의 전산망을 클라우드로 확장한 하이브리드 클라우드 구성\n  \n  \n    외부와 인터넷 연결이 필요한 서브넷과 이와 별개로 외부 인터넷 연결을 차단하고 VPN을 통해 On-Premise에서만 접근할 수 있는 서브넷을 구성하는 경우\n하나의 서브넷은 외부와 연결되는 일반 구성으로 하고, 다른 하나의 서브넷에 IPsec VPN을 연결하여 VPN 전용 서브넷(VPN Only Subnet)을 구성하는 방식\n  \n  \n    다른 두개의 서비스를 각각 다른 사설 IP대역에서 서비스하려는 경우\nVPC를 2개 생성해서 각각 다른 사설 IP 대역을 할당해서 구성 가능\n  \n\n\nClassic vs VPC 선택\n\nClassic 선택\n\n  구축하려는 서비스 규모가 작으며 네트워크 설정은 신경 쓰고 싶지 않은 경우는 Classic 환경\n  리전간 서버끼리 사설통신이 필요하다면 (ex. DB 한국리전, 서비스서버 일본리전) Classic 환경\n  다양한 설치형 서버 이미지들이 필요하다면 Classic 환경\n\n\nVPC 선택\n\n  네트워크 세분화및  서비스에 별도 사설 대역이 필요한 경우는 VPC 환경\n  서버, 네트워크 통신의 inbound, outbound를 직접 통제하고 싶은 경우는 VPC 환경\n  좀 더 다양한 기능을 지원하는 상품을 이용하고자 할때는 VPC환경\n\n\n참고 URL\n\n  VPC 제품 설명\n    \n      https://www.ncloud.com/product/networking/vpc\n    \n  \n  VPC 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/networking-vpc-vpcoverview\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-12-03"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-vpc-peering-guide": {
						"id": "2-networking-ncp-networking-vpc-peering-guide",
						"title": "VPC Peering 생성 가이드",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_vpc_peering_guide/",
						"content": "개요\nVPC(virtural Private Cloud)는 퍼블릭클라우드상에서 제공되는 사설 가상 네트워크 입니다. 계정당 3개의 VPC를 만들수 있으며 다른 VPC 네트워크와 논리적으로 분리되어 있어 독립적인 네트워크 환경을 구현할 수 있습니다.\n그런데, 간혹 VPC 환경에서 분리되어 있는 VPC간의 통신이 필요할때가 있는데 이때 사용할 수 있는 서비스가 [VPC Peering] 입니다. VPC Peering은 공인 아이피를 거치지 않고 Ncloud 내부 네트워크를 이용하여 VPN없이 VPC간 통신을 할수 있게 해주는 서비스 입니다.\n\nVPC 생성\n우선 테스트에 사용할 VPC로 [test-vpc], [test2-vpc] 이렇게 2개를 준비했습니다.\n\n\n\nSubnet 생성\n\n이제 각 VPC에 서브넷을 생성합니다. [test-vpc]에는 [test-subnet(192.168.10.0/24)]으로 생성합니다.\n\n\n\n[test2-vpc]에는 [test2-subnet(172.16.10.0/24)]으로 생성합니다.\n\n\n\n생성된 Subnet은 다음과 같습니다.\n\n\n\nVPC Peering 생성\n네이버 클라우드(Ncloud) 콘솔에서 [Networking] -&gt; [VPC] -&gt; [VPCPeering] 메뉴로 이동해서 [VPC peerig 생성] 버튼을 클릭합니다.\n\n\n\n\n  ① 이름을 적고\n  ② 요청 VPC는 [testVPC]를 선택\n  ③ 수락 VPC는 [내계정], [test2VPC]를 선택\n\n\n설정이 끝났으면 생성버튼을 클릭합니다.\n\n\n  다른 계정의 VPC와 연결하는 경우는 아래쪽에서 살펴보겠습니다.\n\n\n\n\n마지막으로 VPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n\n\n\n[test-vpc] -&gt; [test2-vpc]로 설정된 VPC Peering을 아래와 같이 확인할 수 있습니다.\n\n\n\n역방향 설정 추가\n그런데 VPC peering은 단방향 통신이기에 TCP, ICMP 등의 양방향 통신을 하는 프로토콜을 이용하려면 역방향 즉, [test2-vpc] -&gt; [test-vpc]로 설정된 VPC Peering도 추가해야 합니다.\n\n\n  ① 이름을 적고\n  ② 요청 VPC에는 test2VPC를 선택\n  ③ 수락 VPC에는 testVPC를 선택\n\n\n\n\nVPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n\n\n\n아래와 같이 [test-vpc] -&gt; [test2-vpc] , [test2-vpc] -&gt; [test-vpc] 2가지 VPC Peering을 모두 생성했으므로 양방향 통신이 가능하게 되었습니다.\n\n\n\nRoute Table 설정\n\n이제 통신할 서브넷 혹은 서버의 아이피를 Route Table 설정에 추가 합니다. 여기서는 서브넷을 추가하도록 하겠습니다.\n\n우선 [VPC] - [Route Table]에서, [test-vpc-default-public-table]의 [Routes 설정]을 클릭합니다.\n\n\n\n\n  Destination에는 [test2-subnet]의 아이피 대역을 입력 (서버의 아이피로 입력해도 됨)\n  Target Type은 [VPCPEERING]을 선택\n  Target Name은 [test-vpc-peering]을 선택\n\n\n\n\n다음으로 [test2-vpc-default-public-table]의 [Routes 설정]을 클릭합니다.\n\n\n\n\n  Destination에는 [test-subnet]의 아이피 대역을 입력 (서버의 아이피로 입력해도 됨)\n  Target Type은 [VPCPEERING]을 선택\n  Target Name은 [test2-vpc-peering]을 선택\n\n\n\n\n서버 준비\n아래와 같이 테스트로 사용할 서버 2대를 준비했습니다.\n테스트는 [test-vpc]에 위치한 [test-vpc-peering-svr]서버 -&gt; [test2-vpc]에 위치한 [test2-vpc-peering-svr]로 접속 시도를 해보겠습니다.\n\n\n\nACG 설정\nACG를 설정하지 않고 [test-vpc-peering-svr] -&gt; [test2-vpc-peering-svr]로 접속 시도를 하면 접속이 되지 않는 것을 확인할 수 있습니다.\n\n\n\n[test2-vpc-peering-svr]로 접속할 것이므로 해당 서버에 설정된 acg인 [test2-vpc-default-acg]를 선택하고 [ACG 설정] 버튼을 클릭합니다.\n\n\n\n접근소스에는 [test-vpc-peering-svr] 서버의 subnet 대역인 [192.168.10.0/24]를 입력하고, 포트는 22번 포트를 입력하고 추가해서 적용합니다.\n\n\n\n접속 테스트\nACG 설정까지 완료하고 나서 다시 접속 테스트를 해보면 아래와 같이 접속이 잘 되는 것을 확인할 수 있습니다.\n\n\n\n다른 계정 VPC 연결\n위에서는 동일한 내 계정에 생성된 VPC들 간의 Peering을 살펴보았는데, 아래에서는 다른 계정에 생성된 VPC와 연결할 때의 화면을 살펴보겠습니다.\n\nVPC Peering 생성 화면에서 [다른 계정]을 선택하면 아래와 같이 [로그인 ID (이메일)], [VPC ID], [VPC 이름]을 입력하게 됩니다.\n\n\n\n마찬가지로 VPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n\n\n\n다음으로 수락을 요청받은 다른 계정의 VPC Peering 화면에 가면 요청 내용을 확인할 수 있고, 요청 응답에서 [수락] 버튼을 클릭합니다.\n\n\n\n한번 더 VPC Peering 연결 요청을 수락할 것인지 확인하는 창이 나타납니다.\n\n\n\n수락하고 나면 역방향의 VPC Peering 연결을 생성해야 한다는 안내와 함께 역방향 VPC Peering 생성 화면이 나타납니다.\n역방향은 위의 설정과 반대로 진행하면 되고, 그 이후에는 내 계정에서 설정했던 것과 마찬가지로 설정하시면 완료됩니다.\n\n\n\n제한사항\n\n  VPC Peering은 연결하려는 VPC들의 IP주소 대역이 달라야 합니다. 일치되거나 중첩되는 대역이 있으면 설정되지 않습니다.\n  VPC Peering은 단방향입니다. TCP등 양방향 통신을 해야 하는 경우에는 요청 / 수락 VPC를 맞바꾸어 역방향 Peering도 추가 생성해야 합니다.\n  VPC Peering은 전이적 연결 관계를 지원하지 않습니다. 즉, Peering된 VPC를 통하여 다른 VPC 혹은 외부로 통신하는 것은 불가능 합니다.\n  VPC Peering은 동일한 리전 내 VPC 끼리만 연결할 수 있습니다.\n\n\n참고 URL\n\n  VPC Peering 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailedpeering\n    \n  \n  VPC Peering 설정 시나리오\n    \n      https://guide.ncloud-docs.com/docs/networking-vpc-vpcuserscenario4\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-11-25"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-archive-storage-cli-windows-guide": {
						"id": "4-storage-ncp-storage-archive-storage-cli-windows-guide",
						"title": "Archive Storage CLI 사용 가이드 - Windows 환경",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_archive_storage_cli_windows_guide/",
						"content": "개요\n네이버 클라우드(Ncloud) Archive Storage CLI를 Windows 환경에서 사용하는 방법에 대해 정리해보겠습니다.\n\nCLI 정보\nArchive Storage가 OepnStack으로 구성되어 있고, Client는 Python 기반의 Client를 사용하게 됩니다.\n\n\n  python-keystoneclient : 3.17.0\n  python-swiftclient : 3.6.0\n\n\nPython 다운로드\n먼저 Python을 다운로드 합니다. 권장하는 버전은 3.6 이상입니다. 여기서는 3.9를 설치하겠습니다.\n\nhttps://www.python.org/downloads/\n\n\n\nPython 설치\n\nPATH 추가\nPython 설치 시작화면에 PATH에 python을 추가하는 옵션이 있습니다.\n“Add Python 3.9 to PATH” 옵션을 선택하고 설치를 시작하면 됩니다.\n\n\n\nPATH 문자 길이 제한 해제\nWindows에는 기본설정에 파일경로가 최대 260자로 제한되어 있는데, 이 제한을 풀것인지 확인하는 과정입니다.\n“Disable path length limit” 옵션이 나오는데, 특별한 문제가 없다면 해제하고 가면 됩니다.\n\n\n\nCLI Client 설치\n\npython-keystoneclient : 3.17.0 설치\n우선 OepnStack 서비스의 인증을 담당하는  KeyStone Client를 설치합니다.\n\npip install python-keystoneclient==3.17.0\n\n\n\npython-swiftclient : 3.6.0 설치\n다음으로 실제 명령을 수행하는 Swift Client를 설치합니다.\n\npip install python-swiftclient==3.6.0\n\n\n\n\nClient 설치 오류\nPython Clinet를 설치하는 도중에 아래와 같은 메시지가 나타나면서 오류가 발생하는 경우가 있습니다. \nMicrosoft Visual C++ Build Tools 등이 설치되어 있지 않아서 인데 설치하는 방법 2가지 중에서 하나를 선택해서 설치하시면 됩니다.\n\nerror: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\" : https://visualstudio.microsoft.com/downloads/\n\n\nfatal error C1083: 포함 파일을 열 수 없습니다. 'basetsd.h' : No such file or directory\nerror: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\....... .....\\\\cl.exe' failed with exit code 2\n\n\n\n방법 1 : Build Tools 직접 설치\n첫번째 방법은 Build Tools를 따로 설치하는 방법입니다. \n아래 링크에서 [Microsoft Build Tools 2015 업데이트3]를 다운로드 받아서 설치하시면 되는데, [Visual Studio]가 설치되어 있는 경우에는 설치가 실패하기도 합니다.\n이때는 아래에 나오는 두번째 방법으로 설치하시면 됩니다.\n\nhttps://visualstudio.microsoft.com/ko/vs/older-downloads/\n\n\n\n방법 2 : Visual Studio Installer 설치\nVisual Studio가 설치되어 있는 경우에는 위 1번 방법으로 설치가 되지 않는 경우가 있으므로 Visual Studio Installer에서 설치하도록 하겠습니다.\n[Visual Studio Installer]를 실행하셔서 설치된 Visual Studio 메뉴의 [수정] 버튼을 클릭합니다.\n\n\n\n나타난 화면에서 [C++를 사용한 데스크톱 개발]을 선택하시고 오른쪽 [설치 세부정보]에서  다음 2가지를 선택해서 설치하시면 됩니다.\n\n  MSVC vXXX - VS 20XX C++ x64/x86 빌드 도구\n  Windows 10 SDK\n\n\n\n\n인증 토큰 생성\nCLI Client가 모두 설치되었으면 이제 접속을 위한 인증 토큰을 생성해야 합니다. \n인증 토큰을 생성하는 명령어는 다음과 같은데 여기에 필요한 값이 4가지 있습니다.\n\nswift --os-auth-url https://kr.archive.ncloudstorage.com:5000/v3 --auth-version 3 --os-username {access_key_id} --os-password {secret_key} --os-user-domain-id {domain_id} --os-project-id {project_id} auth\n\n\n네이버 클라우드 API 인증키 : access_key_id, secret_key\n두가지 Key는 네이버 클라우드 API 인증키로 [네이버 클라우드 포탈] -&gt; [마이페이지] -&gt; [계정관리] -&gt; [인증키 관리] - [API 인증키 관리] 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n\nArchive Storage API 정보:  domain_id, project_id\n두가지 id 값은 Archive Storage API 이용을 위한 Domain ID와 Project ID로 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n\n[API 이용 정보 확인] 창에서 Domain ID와 Project ID를 확인하고, 인증토큰 생성 코드에 입력합니다.\n\n\n\n위에서 확인한 설정 값 4가지를 추가해서 인증토큰 생성 명령을 실행하면 아래와 같이 생성된 인증토큰이 출력됩니다.\nexport OS_STORAGE_URL=https://kr.archive.ncloudstorage.com/v1/AUTH_{project_id}\nexport OS_AUTH_TOKEN={인증 토큰}\n\n\n\n\n인증 토큰 유효 시간\nAPI 인증 토큰의 유효 시간은 24시간이고 삭제 요청을 호출하면 삭제할 수 있습니다.\n\n환경 변수 설정\n위에서 생성된 인증토큰과 URL을 환경 변수에 설정합니다. Windows에서는 export 명령을 set로 변경해서 실행합니다.\nset OS_STORAGE_URL=https://kr.archive.ncloudstorage.com/v1/AUTH_{project_id}\nset OS_AUTH_TOKEN={인증 토큰}\n\n\n\n\n컨테이너(버킷) 조회\n현재 Archive Storage에 생성되어 있는 컨테이너(버킷)을 확인할 수 있는 명령어는 다음과 같습니다.\nswift list\n\n\n\n컨테이너(버킷)의 모든 오브젝트 조회\n특정 컨테이너(버킷)의 모든 오브젝트 목록을 확인하는 명령어는 마지막에 컨테이너(버킷) 이름을 적어주면 됩니다.\nswift list {컨테이너(버킷) 이름}\n\n\n\n파일 업로드\n파일 업로드 명령은 특정 파일을 업로드 하는 명령과 폴더를 통째로 업로드 하는 명령을 각각 확인해보겠습니다.\n\n폴더 업로드\n폴더를 통째로 업로드 하는 명령은 다음과 같습니다.\nswift upload {컨테이너(버킷) 이름} --object-name {저장할 Archive Storage 폴더명} {로컬PC 폴더명}\n\n\n폴더 파일을 업로드 후에 list 명령어로 컨테이너(버킷)의 오브젝트 목록을 확인할 수 있습니다.\n\n\n\n개별 파일 업로드\n특정 파일을 업로드 하려면 다음처럼 명령을 실행하면 됩니다.\nswift upload {컨테이너(버킷) 이름} --object-name {저장할 Archive Storage 폴더명/저장할 파일명} {로컬PC 파일 경로}\n\n\n마찬가지로 파일을 업로드 후에 list 명령어로 확인해보시면 됩니다.\n\n\n\n파일 삭제\n파일 삭제도 개별 파일 삭제와 폴더 삭제 2가지로 나누어서 확인해보겠습니다.\n\n개별 파일 삭제\n특정 파일을 삭제하는 명령은 다음과 같습니다.\nswift delete {컨테이너(버킷) 이름} {Archive Storage 파일 전체 경로}\n\n\n\n폴더 삭제\n폴더 전체를 삭제하는 명령은 prefix 옵션이 들어갑니다.\nswift delete {컨테이너(버킷) 이름} --prefix {Archive Storage 폴더 경로}\n\n\n\n파일 다운로드\n파일 다운로드는 개별 파일 다운로드와 폴더 다운로드 그리고, 컨테이너(버킷) 파일 전체 다운로드를 실행해 보고, 로컬PC에서 다운로드 된 것을 확인해보겠습니다.\n\n개별 파일 다운로드\n개별 파일 다운로드에는 output 옵션이 필요합니다.\nswift download {컨테이너(버킷) 이름} --output {저장할 로컬PC 파일 전체 경로} {Archive Storage 파일 전체 경로}\n\n\n\n로컬PC에서 확인을 해보면 아래와 같이 다운로드된 파일을 확인할 수 있습니다.\n\n\n\n폴더 다운로드\n폴더 다운로드에는 output-dir 옵션이 필요합니다.\nswift download {컨테이너(버킷) 이름} --output-dir {저장할 로컬PC 폴더 경로} {Archive Storage 폴더 경로}\n\n\n\n\n로컬PC에서 확인을 해보면 아래와 같이 폴더가 다운로드 된 것을 확인할 수 있습니다.\n\n\n\n컨테이너(버킷) 전체 다운로드\n컨테이너(버킷)에 있는 모든 파일을 다운로드 할 때는 아래와 같이 폴더 다운로드 명령에서 마지막에 있는 파일명이나 폴더명 파라미터를 지우시면 됩니다.\nswift download {컨테이너(버킷) 이름} --output-dir {저장할 로컬PC 폴더 경로}\n\n\n\n로컬PC에서 확인을 해보면 폴더와 파일이 모두 다운로드 된 것을 확인할 수 있습니다.\n\n\n\n주의 사항\n\nArchive Storage CLI를 사용해야 하는 이유\n마지막으로 Archive Storage를 관리할 때는 AWS S3용 Client Tool (ex, CloudBerry Explorer, S3 Browser) 대신에 Archive Storage CLI를 사용해야 하는 이유에 대해 정리해보겠습니다.\n\n네이버 클라우드(Ncloud) Archive Storage는 Object Storage의 데이터를 장기 백업하기 위한 용도 등으로 주로 사용되다 보니 Object Storage와 비슷한 시스템이라고 오해하는 경우가 많습니다. \n하지만, Object Storage가 AWS S3와 호환되는 시스템 구조로 되어 있는 것에 반해, Archive Storage는 OpenStack 기반의 시스템 구조로 되어 있어 전혀 다르다고 보시면 됩니다.\n\n그러다 보니, Object Storage를 관리하는데 자주 사용되는 AWS S3용 Client Tool (ex, CloudBerry Explorer, S3 Browser) 등을 Archive Storage를 관리할 때도 사용하는 경우가 있는데, 가급적 사용하지 않는 것이 좋습니다. \n왜냐하면 AWS S3용 Client Tool로 Archive Storage에서 업로드, 다운로드, 삭제, 이름변경 등의 작업을 진행하면 해당 파일에 문제가 생기거나 때로는 컨테이너(버킷) 데이터 전체에 문제가 생길 수도 있기 때문입니다.\n\n혹시나 AWS S3용 Client Tool을 사용하더라도 파일(오브젝트)을 조회하는 용도 정도로만 한정해서 사용하는 것을 추천합니다. 물론 파일 조회도 가능하면 Archive Storage용의 CLI나 API를 이용하는 것이 좋습니다.\n\n참고 URL\n\n  Archive Storage CLI 가이드\n    \n      https://cli.ncloud-docs.com/docs/guide-archivestorage\n    \n  \n  OpenStack CLI 가이드\n    \n      https://docs.openstack.org/ocata/cli-reference/swift.html\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-11-19"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-archive-storage-api-get-container-by-php": {
						"id": "4-storage-ncp-storage-archive-storage-api-get-container-by-php",
						"title": "PHP로 Archive Storage API 호출하기 - 컨테이너(버킷) 오브젝트 목록 조회",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_archive_storage_api_get_container_by_php/",
						"content": "개요\n네이버 클라우드(Ncloud) Archive Storage API를 이용해서 컨테이너(버킷)에 있는 오브젝트 전체 목록을 PHP로 조회하는 방법에 대해 정리해보겠습니다.\n\nAPI 정보\n\n  OpenStack Swift API : 2.15.1 (Pike)\n  OpenStack Keystone V3 API : v3.8\n\n\n인증 토큰 생성\nArchive Storage API를 호출할 때는 먼저 인증 토큰을 생성해야 하는데, 생성 방법은 내용이 다소 긴 관계로 다른 문서에서 자세히 설명해두었습니다. \n아래 문서를 참고 하시기 바랍니다.\n\nPHP로 Archive Storage API 인증 토큰 생성하는 방법 (docs.3rdeyesys.com)\n\n오브젝트 목록 조회 코드\n&lt;?php\n\n  $x_auth_token = \"Archive Storage API 인증 토큰\";\n\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n  $ncloud_container = \"Archive Storage 컨테이너(버킷) 이름\";\n  \n  $api_server = \"https://kr.archive.ncloudstorage.com\";\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json\";\t\t\n\n  // http 호출 헤더값 설정\n  $http_header = array();\n  $http_header[0] = \"X-Auth-Token: \".$x_auth_token;\n  $http_header[1] = \"charset=UTF-8\";\n\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //request에 header 값도 수신\n  curl_setopt($ch, CURLOPT_POST, FALSE); //GET 방식으로 호출\n\n  $response = curl_exec($ch);\n  $http_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n  curl_close($ch);\n  \t\t\n  if ($response)\n  {\n  \tif ($http_code == 200)\n\t{\n\t\t// response에서 header 값 분리\n\t\t$headers = array();\n\t\t$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n\t\tforeach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n\t\t{\n\t\t\tif ($i === 0)\n\t\t\t{\n\t\t\t   $headers[\"http_code\"] = $line;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t   list ($key, $value) = explode(\": \", $line);\n\t\t\t   $headers[$key] = $value;\n\t\t\t}\n\t\t}\n\n\t\t// response에서 json형태의 body 값 분리\n\t\t$json_response = substr($response, strpos($response, \"\\r\\n\\r\\n\"));\n\t\t$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n\n\t\t$object_count = $headers[\"X-Container-Object-Count\"];\n\t\t$used_bytes = $headers[\"X-Container-Bytes-Used\"];\n\t\t$used_k_bytes = $used_bytes / 1024;\n\t\t$used_m_bytes = $used_k_bytes / 1024;\n\t\t$used_g_bytes = $used_m_bytes / 1024;\n\t}\n\telse if ($http_code == 404)\n\t{\n\t\techo(\"존재하지 않는 컨테이너(버킷)입니다\");\n\n\t\t$rows_response = [];\t\n\n\t\t$object_count = 0;\n\t\t$used_bytes = 0;\n\t\t$used_k_bytes = 0;\n\t\t$used_m_bytes = 0;\n\t\t$used_g_bytes = 0;\n\t}\n\telse\n\t{\n\t\techo($response);\n\t}\n\n  }\n  else\n  {\n  \techo(\"Error\");\n  }\n\n?&gt;\n\n\n&lt;?php\n  // 오브젝트 목록 출력\n  $cnt = 0;\n  foreach ($rows_response as $row)\n  {\t\t\t\t\n  \t$archive_object_name = $row[\"name\"];\n  \t$archive_object_hash = $row[\"hash\"];\n  \t$archive_object_content_type = $row[\"content_type\"];\n  \t$archive_object_last_modified = $row[\"last_modified\"];\n  \t$archive_object_bytes = $row[\"bytes\"];\n\n  \t$cnt++;\n  ?&gt;\n\t&lt;tr&gt; \t  \t\t\t\t\t\t\n\t  &lt;td&gt;&lt;?php echo($cnt);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_name);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_content_type);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_hash);?&gt;&lt;/td&gt;\t\t\t\t\t  \n\t  &lt;td&gt;&lt;?php echo($archive_object_last_modified);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo(number_format($archive_object_bytes));?&gt;&lt;/td&gt;\n\t&lt;/tr&gt;\n\n&lt;?php\t\n  }\n?&gt;\n\n\n코드 상세 설명\n\n\nArchive Storage API 이용 정보\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n  $ncloud_container = \"Archive Storage 컨테이너(버킷) 이름\";\n\nArchive Storage API 이용을 위한 Project ID는 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n테스트에 사용할 컨테이너(버킷)은 [test]로 설정해두었습니다.\n\n\n\n[API 이용 정보 확인] 창에서 Project ID를 확인하고, PHP 소스코드에 입력합니다.\n\n\n\nAPI 서버와 URL 설정\n  $api_server = \"https://kr.archive.ncloudstorage.com\";\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json\";\n\nArchive Storage API 서버와 컨테이너(버킷)에 있는 오브젝트 목록을 조회하기 위한 URL 정보는 위와 같습니다. \n[프로젝트 ID]와 [컨테이너(버킷) 이름]을 URL에 포함시키고, 파라미터로는 전달받을 목록의 형태를 설정하게 되는데, 여기서는 json형태로 받겠습니다.\n\nHeader 값 설정\n  // http 호출 헤더값 설정\n  $http_header = array();\n  $http_header[0] = \"X-Auth-Token: \".$x_auth_token;\n  $http_header[1] = \"charset=UTF-8\";\n\nArchive Storage API 인증 토큰은 [X-Auth-Token] 라는 이름으로 header에 담아서 전송합니다.\n\nAPI 호출\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\n  curl_setopt($ch, CURLOPT_POST, FALSE); //GET 방식으로 호출\n\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\ncurl_setopt($ch, CURLOPT_HEADER, TRUE); 는 Response에 body 뿐만 아니라 header 값도 수신하기 위해 설정합니다.\n\nAPI 호출 응답 수신\n  $response = curl_exec($ch);\n  $http_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n  curl_close($ch);\n\nAPI를 호출하고 응답을 수신합니다. 성공, 실패 등에 대한 HTTP 상태코드도 확인합니다.\n\nHeader, Body 값 분리\n  // response에서 header 값 분리\n  $headers = array();\n  $header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n  foreach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n  {\n\tif ($i === 0)\n\t{\n\t   $headers[\"http_code\"] = $line;\n\t}\n\telse\n\t{\n\t   list ($key, $value) = explode(\": \", $line);\n\t   $headers[$key] = $value;\n\t}\n  }\n\n  // response에서 json형태의 body 값 분리\n  $json_response = substr($response, strpos($response, \"\\r\\n\\r\\n\"));\n  $rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n\nResoponse에서 Header, Body 값을 따로 분리해서 배열에 저장합니다.\n\n컨테이너(버킷) 기본 정보 확인\n  $object_count = $headers[\"X-Container-Object-Count\"];\n  $used_bytes = $headers[\"X-Container-Bytes-Used\"];\n  $used_k_bytes = $used_bytes / 1024;\n  $used_m_bytes = $used_k_bytes / 1024;\n  $used_g_bytes = $used_m_bytes / 1024;\n\n분리한 Header 값에서 컨테이너(버킷)의 기본 정보를 확인합니다.\n[전체 오브젝트 개수], [사용 중인 용량]을 확인하고 용량은 Bytes 단위이기에 KB, MB, GB 단위로도 변환합니다.\n\nHTTP 상태코드\n  if ($http_code == 200){\n    //성공\n  }\n  else if ($http_code == 404){\n    echo(\"존재하지 않는 컨테이너(버킷)입니다\");\n  }\n\n요청이 성공하게 되면 OK (200), 컨테이너(버킷)이 존재하지 않는 경우는 Not Found (404) 상태 코드를 응답합니다.\n\n오브젝트 목록 html 출력\n&lt;?php\n  // 오브젝트 목록 출력\n  $cnt = 0;\n  foreach ($rows_response as $row)\n  {\t\t\t\t\n  \t$archive_object_name = $row[\"name\"];\n  \t$archive_object_hash = $row[\"hash\"];\n  \t$archive_object_content_type = $row[\"content_type\"];\n  \t$archive_object_last_modified = $row[\"last_modified\"];\n  \t$archive_object_bytes = $row[\"bytes\"];\n\n  \t$cnt++;\n  ?&gt;\n\t&lt;tr&gt; \t  \t\t\t\t\t\t\n\t  &lt;td&gt;&lt;?php echo($cnt);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_name);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_content_type);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_hash);?&gt;&lt;/td&gt;\t\t\t\t\t  \n\t  &lt;td&gt;&lt;?php echo($archive_object_last_modified);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo(number_format($archive_object_bytes));?&gt;&lt;/td&gt;\n\t&lt;/tr&gt;\n\n&lt;?php\t\n  }\n?&gt;\n\n오브젝트 목록을 html로 출력합니다.\n출력하는 정보는 [이름], [해시값], [Content Type], [최종 수정일], [용량(Bytes)] 입니다.\n\n목록 출력 예시\n위의 코드를 실행하면 다음과 같이 오브젝트 목록이 출력됩니다.\n\n\n\n출력된 오브젝트 정보가 올바른지 확인하기 위해 네이버 클라우드(Ncloud) 콘솔에서 해당 컨테이너(버킷)의 정보를 확인하면 다음과 같이 일치하는 것을 알 수 있습니다.\n\n\n\n제한 사항\nArchive Storage API를 이용해서 가져올 수 있는 오브젝트 목록의 최대 개수는 10,000개입니다. \n1만개 이상이 등록된 컨테이너(버킷)에서 오브젝트 목록을 요청해도 아래와 같이 최대 10,000개 까지만 가져올 수 있습니다.\n\n\n\n\n  컨테이너(버킷)에 10,000개 이상의 오브젝트가 저장되어 있을 경우에는 아래쪽에서 소개하는 방법처럼 폴더별로 오브젝트 목록을 따로 조회하시면 됩니다.\n\n\n오브젝트 검색\n위에서는 컨테이너(버킷)에 저장된 모든 오브젝트들을 조회하는 기능을 확인해보았습니다.\n다음으로는 특정 이름으로 시작되는 오브젝트나 특정 폴더에 있는 오브젝트만 조회하는 방법에 대해 위에서 확인한 PHP 예제 소스코드에서 변경이 필요한 부분만 확인해보겠습니다.\n\n테스트에 사용된 오브젝트와 폴더 구조는 다음과 같습니다.\n- Test_Folder_0001.png\n- Test_Folder\n    L Sub_Folder\n        L Sub_Sub_Folder\n\n\n\n특정 이름으로 시작하는 오브젝트 목록\n  $ncloud_object_prefix = \"Test_Folder\";\n\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json&amp;prefix=\".$ncloud_object_prefix;\t\t\n\nAPI URL을 호출할 때 파라미터로 prefix를 전송하면 prefix 값에 해당하는 특정 문자열로 시작하는 오브젝트 목록을 모두 가져 옵니다.\n예를 들어 prefix 값을 [Test_Folder]로 설정하면, 아래와 같이 [Test_Folder]라는 이름으로 시작되는 모든 오브젝트 목록을 가져오게 됩니다.\n\n\n\n특정 폴더 아래에 있는 오브젝트 목록\n  $ncloud_object_prefix = \"Test_Folder/\";\n\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json&amp;prefix=\".$ncloud_object_prefix;\t\t\n\n특정 폴더 아래에 있는 오브젝트 목록을 가져 올 때는 prefix 값 마지막에 슬래시 [ / ]를 추가하면 됩니다.\n예를 들어 prefix 값을 [Test_Folder/]로 설정하면, 아래와 같이 [Test_Folder]라는 이름의 폴더 아래에 있는 모든 오브젝트 목록을 가져오게 됩니다.\n\n위쪽에서 확인한 [특정 이름으로 시작하는 오브젝트 목록]의 결과 예시와는 다르게 폴더 자체인 [Test_Folder] 그리고 [Test_Folder_0001.png]는 포함되어 있지 않습니다.\n\n\n\nAPI 기타 기능\nArchive Storage API에서 지원하는 기능은 컨테이너(버킷)의 오브젝트 목록 외에도 아래와 같이 여러가지가 있습니다. \n위에서 사용한 것은 컨테이너(버킷) 오퍼레이션의 GET 기능입니다.\n\n어카운트 오퍼레이션\n\n  GET : 어카운트에 속한 컨테이너(버킷) 목록을 조회합니다.\n  HEAD : 어카운트의 메타데이터를 조회합니다.\n  POST : 어카운트에 메타데이터를 설정 및 변경합니다.\n\n\n컨테이너(버킷) 오퍼레이션\n\n  PUT : 컨테이너(버킷)을 생성합니다.\n  GET : 컨테이너(버킷)에 속한 오브젝트 목록을 조회합니다.\n  HEAD : 컨테이너(버킷)의 메타데이터를 조회합니다.\n  POST : 컨테이너(버킷)에 메타데이터를 설정 및 변경합니다.\n DELETE : 빈 컨테이너(버킷)을 삭제합니다.\n\n\n오브젝트 오퍼레이션\n\n  PUT : 오브젝트를 업로드합니다. 동일한 이름의 오브젝트가 있을 경우 덮어쓰기를 합니다.\n  COPY : 다른 위치에 있는 오브젝트를 복제합니다.\n  GET : 오브젝트를 다운로드합니다.\n  HEAD : 오브젝트의 메타데이터를 조회합니다.\n  POST : 오브젝트에 메타데이터를 설정 및 변경합니다.\n  DELETE : 오브젝트를 삭제합니다.\n\n\n참고 URL\n\n  Archive Storage API 기본 가이드\n    \n      https://api.ncloud-docs.com/docs/common-archivestorageapi-archivestorageapi\n    \n  \n  Archive Storage API 상세 가이드\n    \n      https://api.ncloud-docs.com/docs/storage-archivestorage\n    \n  \n  OpenStack Keystone V3 API 가이드\n    \n      https://docs.openstack.org/api-ref/identity/v3/\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-11-17"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-archive-storage-api-access-token-create": {
						"id": "4-storage-ncp-storage-archive-storage-api-access-token-create",
						"title": "PHP로 Archive Storage API 인증 토큰 생성하는 방법",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_archive_storage_api_access_token_create/",
						"content": "개요\n네이버 클라우드(Ncloud) Archive Storage API를 이용하려고 할 때 먼저 인증 토큰을 생성하고 생성된 토큰을 이용해서 API로 Archive Storage에 접근해야 합니다. \n여기서는 PHP로 API 인증 토큰을 생성하는 방법에 대해 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\nAPI 정보\n\n  OpenStack Swift API : 2.15.1 (Pike)\n  OpenStack Keystone V3 API : v3.8\n\n\n인증 토큰 생성 코드\n&lt;?php\n\n  // 전송해야 할 설정값\n  $ncloud_accesskey = \"네이버 클라우드 AccessKey\";\n  $ncloud_secretkey = \"네이버 클라우드 SecretKey\";\n  $ncloud_domain_id = \"Archive Storage 도메인 ID\";\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n\n  $api_server = \"https://kr.archive.ncloudstorage.com:5000\";\n  $api_url = \"/v3/auth/tokens\";\t\t \n\n  // http 호출 헤더값 설정\n  $http_header = array();\n  $http_header[0] = \"Content-Type: application/json\";\n\n  // 전송할 값들을 배열 형태로 저장한다\n  $postvars = [\n  \t\"auth\"=&gt; [\n  \t\t\"identity\"=&gt; [\n  \t\t\t\"methods\"=&gt; [\n  \t\t\t\t\"password\"\n  \t\t\t],\n  \t\t\t\"password\"=&gt; [\n  \t\t\t\t\"user\"=&gt; [\n  \t\t\t\t\t\"name\"=&gt; $ncloud_accesskey,\n  \t\t\t\t\t\"password\"=&gt; $ncloud_secretkey,\n  \t\t\t\t\t\"domain\"=&gt; [\n  \t\t\t\t\t\t\"id\"=&gt; $ncloud_domain_id\n  \t\t\t\t\t]\n  \t\t\t\t]\n  \t\t\t]\n  \t\t],\n  \t\t\"scope\"=&gt; [\n  \t\t\t\"project\"=&gt; [\n  \t\t\t\t\"id\"=&gt; $ncloud_project_id\n  \t\t\t]\n  \t\t]\n  \t]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환해서 전송\n  $json_portvars = json_encode($postvars);\n\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_POST, TRUE); //POST 방식으로 호출\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\n  curl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\n\n  $response = curl_exec($ch);\n\n  curl_close($ch);\n\n  if ($response)\n  {\n  \t// X-Subject-Token 토큰 값은 request body가 아닌 header로 전달되므로\n  \t// header를 분리해서 배열에 저장한다 \n  \t$headers = array();\n  \t$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n  \tforeach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n  \t{\n  \t\tif ($i === 0)\n  \t\t{\n  \t\t   $headers[\"http_code\"] = $line;\n  \t\t}\n  \t\telse\n  \t\t{\n  \t\t   list ($key, $value) = explode(\": \", $line);\n  \t\t   $headers[$key] = $value;\n  \t\t}\n  \t}\n\t\n\t// 인증 토큰 확인\n  \t$x_auth_token = $headers[\"X-Subject-Token\"]; \n  \techo($x_auth_token);\n\n  \t//var_dump($headers);\n  \t//echo(\"&lt;hr&gt;\");\n  \t//var_dump($response);\n  } \n  else \n  {\n  \techo \"Curl error: \" . curl_error($ch);\n  }\n?&gt;\n\n\n코드 상세 설명\n\n네이버 클라우드 인증키\n  $ncloud_accesskey = \"네이버 클라우드 AccessKey\";\n  $ncloud_secretkey = \"네이버 클라우드 SecretKey\";\n\n네이버 클라우드 인증키는 [네이버 클라우드 포탈] -&gt; [마이페이지] -&gt; [계정관리] -&gt; [인증키 관리] - [API 인증키 관리] 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n\nArchive Storage API 이용 정보\n  $ncloud_domain_id = \"Archive Storage 도메인 ID\";\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n\nArchive Storage API 이용을 위한 Domain ID와 Project ID는 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n\n[API 이용 정보 확인] 창에서 Domain ID와 Project ID를 확인하고, PHP 소스코드에 입력합니다.\n\n\n\nAPI 서버와 URL 설정\n  $api_server = \"https://kr.archive.ncloudstorage.com:5000\";\n  $api_url = \"/v3/auth/tokens\";\n\nArchive Storage API 서버와 토큰 생성을 위한 URL 정보는 위와 같습니다.\n\nHTTP 호출 header 값 설정\n  $http_header = array();\n  $http_header[0] = \"Content-Type: application/json\";\n\nHTTP header에는 json 형태로 호출한다는 것을 설정합니다.\n\n전송할 값 설정\n  // 전송할 값들을 배열 형태로 저장\n  $postvars = [\n  \t\"auth\"=&gt; [\n  \t\t\"identity\"=&gt; [\n  \t\t\t\"methods\"=&gt; [\n  \t\t\t\t\"password\"\n  \t\t\t],\n  \t\t\t\"password\"=&gt; [\n  \t\t\t\t\"user\"=&gt; [\n  \t\t\t\t\t\"name\"=&gt; $ncloud_accesskey,\n  \t\t\t\t\t\"password\"=&gt; $ncloud_secretkey,\n  \t\t\t\t\t\"domain\"=&gt; [\n  \t\t\t\t\t\t\"id\"=&gt; $ncloud_domain_id\n  \t\t\t\t\t]\n  \t\t\t\t]\n  \t\t\t]\n  \t\t],\n  \t\t\"scope\"=&gt; [\n  \t\t\t\"project\"=&gt; [\n  \t\t\t\t\"id\"=&gt; $ncloud_project_id\n  \t\t\t]\n  \t\t]\n  \t]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환해서 전송\n  $json_portvars = json_encode($postvars);\n\n네이버 클라우드 AccessKey, SecretKey, Archive Storage 도메인 ID, 프로젝트 ID를 전송하기 위해 지정된 형태의 배열로 저장한 후에 json 형태로 변환합니다. \n물론 처음부터 json 형태로 저장해도 됩니다.\n\nAPI 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_POST, TRUE); //POST 방식으로 호출\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\n  curl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\n\n  $response = curl_exec($ch);\n  curl_close($ch);\n\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\ncurl_setopt($ch, CURLOPT_HEADER, TRUE); 는 Response에 body 뿐만 아니라 header 값도 수신하기 위해 설정합니다.\n\nAPI 인증 토큰 분리\n  if ($response)\n  {\n  \t$headers = array();\n  \t$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n  \tforeach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n  \t{\n  \t\tif ($i === 0)\n  \t\t{\n  \t\t   $headers[\"http_code\"] = $line;\n  \t\t}\n  \t\telse\n  \t\t{\n  \t\t   list ($key, $value) = explode(\": \", $line);\n  \t\t   $headers[$key] = $value;\n  \t\t}\n  \t}\n\t\n\t// 인증 토큰 확인\n  \t$x_auth_token = $headers[\"X-Subject-Token\"]; \n  \techo($x_auth_token);\n\n  \t//var_dump($headers);\n  \t//echo(\"&lt;hr&gt;\");\n  \t//var_dump($response);\n  } \n\nAPI 인증 토큰값은 X-Subject-Token이라는 이름으로 request body가 아닌 header로 전달되므로 header를 분리해서 배열에 저장합니다.\n실제 전송되는 header 값은 아래와 같은 형태입니다.\nHTTP/1.1 201 Created \nDate: Thu, 11 Nov 2021 07:59:32 GMT \nServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips mod_wsgi/3.4 Python/2.7.5 \nX-Subject-Token: gAAAAABhjM1lbeTW3Vq......중간 생략 ......txWYsWGrC1siPt8CE0rs_KgNMTQ \nVary: X-Auth-Token \nx-openstack-request-id: req-1ce......중간 생략 ......a85eb5b \nContent-Length: 1762 \nContent-Type: application/json\n\n\n인증 토큰 유효 시간\nAPI 인증 토큰의 유효 시간은 24시간이고 삭제 요청을 호출하면 삭제할 수 있습니다.\n\n참고 URL\n\n  Archive Storage API 기본 가이드\n    \n      https://api.ncloud-docs.com/docs/common-archivestorageapi-archivestorageapi\n    \n  \n  OpenStack Keystone V3 API 가이드\n    \n      https://docs.openstack.org/api-ref/identity/v3/\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-11-11"
					}
					
				
			
		
			
				
					,
					
					"99-etc-ncp-etc-php-to-telegram-message-send": {
						"id": "99-etc-ncp-etc-php-to-telegram-message-send",
						"title": "PHP로 텔레그램 비공개 채널에 메시지 전송하기",
						"categories": "99.ETC",
						"url": " /99.etc/ncp_etc_php_to_telegram_message_send/",
						"content": "개요\n업무를 진행하다보면 서버나 서비스에 장애가 발생했을 때 즉시 알림을 받거나 서버 상태 모니터링이나 매출 등의 서비스 이용 지표 등을 매일 자동으로 통보 받는 경우가 있습니다. \n예전에는 이메일이나 SMS 메시지로 받는 경우가 대부분이었는데, 요즘은 관련된 사람들이 함께 들어와 있는 메신저 채팅방으로 알림을 동시에 받는 경우도 많아지고 있습니다.\n그럴 때 사용하는 방법 중에서 여기서는 텔레그램(Telegram)의 대화방인 비공개 채널에 메시지를 전송하는 것을 PHP로 구현해보겠습니다.\n\n구현 순서\n\n  텔레그램 채팅 봇을 생성\n  텔레그램 채널을 비공개로 생성\n  비공개 채널에 위에서 생성한 채팅 봇을 관리자로 등록\n  PHP로 채팅 봇을 이용해 비공개 채널에 메시지를 전송\n\n\n채팅 봇 생성\n텔레그램(Telegram) 메신저에서 채팅 봇을 생성하고 관리해주는 봇인 [BotFather]를 검색합니다. \n여러 개의 봇들이 나타나는데 그 중에서 인증 마크가 붙어 있는 텔레그램 공식 봇을 선하고 채팅 방에  들어갑니다.\n\n\n\n[BotFather] 채팅 봇 방에 들어가면 채팅 봇에 대한 설명과 봇 API 매뉴얼 링크를 확인할 수 있습니다.\n\n\n\n이제 채팅 봇 생성을 위해 /start 명령을 입력하면 아래와 같이 채팅 봇 생성, 관리에 대한 명령어들을 확인할 수 있습니다.\n\n\n\n다음으로 새로운 채팅 봇을 생성하는 명령어인 /newbot을 입력하면, 채팅 봇 이름과 채팅 봇 유저명을 입력하라는 안내가 나옵니다. \n차례대로 입력하면 되는데, 여기서 입력하는 이름을 텔레그램 내에서 고유한 값이므로 간단한 이름을 입력하면 중복된 이름이라 생성이 되지 않으니 자신만의 고유한 이름을 입력합니다.\n\n그리고 두번째로 입력하는 채팅 봇 유저명(username for your bot)은 반드시 마지막이 bot로 끝나야 합니다. \n두가지 모두 입력하고 나면 아래쪽에 채팅 봇과 연동하기 위한 API Token을 확인할 수 있는데, 이 Token을 PHP에서 사용하게 됩니다.\n\n\n\n채팅 봇이 생성되었는지 텔레그램에서 검색해보면 아래와 같이 확인할 수 있습니다.\n\n\n\n채널 생성\n채널을 생성하기 위해 텔레그램 왼쪽 메뉴를 클릭합니다.\n\n\n\n메뉴 화면에서 [채널 만들기]를 클릭합니다.\n\n\n\n원하는 채널명을 입력하고, 만들기를 클릭하면, 공개-비공개를 선택할 수 있는데 여기서는 [비공개 채널]을 선택하고 저장합니다.\n\n\n\n저장하고 나면 다음으로 [참가자 추가] 화면이 나타나는데 위에서 생성했던 채팅 봇 이름을 입력해서 확인하고, 선택 후에 [추가] 버튼을 클릭합니다.\n\n\n\n그러면 아래와 같이 [봇은 관리자로서만 추가될 수 있습니다]라는 메시지가 나타납니다. 바로 [관리자로 세우기] 버튼을 클릭합니다.\n\n\n\n관리자의 권한은 여러가지가 있는데 원하는 권한을 부여하고 [저장] 버튼을 클릭합니다.\n\n\n\n채팅 방 ID 확인\n메시지를 전송하기 위해서는 현재 생성된 비공개 채널의 chat_id를 확인해야 합니다.\n우선, 채널에서 아무 메시지나 입력합니다. (꼭 하셔야 합니다)\n\n\n\n다음으로 웹브라우저에서 다음 주소를 입력합니다.  주소에는 위에서 확인했던 API Token이 들어갑니다.\n\nhttps://api.telegram.org/bot[API Token]/getUpdates\n\n# 예시\nhttps://api.telegram.org/bot123456789:JFDS89FMJK8932-MKJE8FNBH3289I/getUpdates\n\n\n입력하면 나타나면 결과에서 “chat” : {“id” : -12586498, ….} 와 같은 형식의 id 값을 복사합니다. 이 값이 바로 비공개 채널의 chat_id 입니다.\n\n\n\n메시지 전송 코드 작성\n마지막으로 메시지를 전송하는 PHP 코드를 작성해보겠습니다.\n위에서 구했던 [API Token], [chat_id]를 아래 코드에 입력하고 실행하면 됩니다.\n&lt;?php\n\n  function php_to_telegram_msg_send($msg) \n  {\n    $api_token = \"API Token\";\n    $chat_id = \"채팅방 ID\";\n    $api_url = \"https://api.telegram.org/bot\".$api_token.\"/sendMessage\";\n\n    $post_vars = \"chat_id=\".$chat_id.\"&amp;text=\".urlencode($msg);\n    $content_type = \"Content-Type: application/x-www-form-urlencoded\";\n\n    $ch = curl_init();\n\n    curl_setopt($ch, CURLOPT_URL, $api_url);\n    curl_setopt($ch, CURLOPT_HEADER, false);\n    curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n    curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);\n    curl_setopt($ch, CURLOPT_POST, true);\n    curl_setopt($ch, CURLOPT_TIMEOUT, 5);\n    curl_setopt($ch, CURLOPT_HTTPHEADER, array($content_type));\n    curl_setopt($ch, CURLOPT_POSTFIELDS, $post_vars);\n\n    $return = curl_exec($ch);\n\n    curl_close($ch);\n\n    return $return;\n  }\n\n\n  $tgm_msg = \"\";\t\t\n  $tgm_msg = $tgm_msg.\"메시지 테스트\";\n\n  $output = php_to_telegram_msg_send($tgm_msg);\t\n?&gt;\n\n\n위 코드를 실행하면 아래와 같이 비공개 채널에 메시지가 도착한 것을 확인할 수 있습니다.\n\n\n\n메시지 스타일 적용\n텔레그램 채팅 봇 API는 메시지에 bold, underline 등의 몇가지 html 스타일을 지원합니다.\nhtml 스타일을 적용하기 위해서는 전송 파라미터에 parse_mode=html을 추가해야 합니다.\n그러면 위 전송 코드 중에서 변경해야 하는 코드만 정리해보겠습니다.\n\n&lt;?php\n\n  /* 전송 파라미터에 parse_mode=html을 추가합니다. */\n  $post_vars = \"chat_id=\".$chat_id.\"&amp;text=\".urlencode($msg).\"&amp;parse_mode=html\";\t\t\n\n  $tgm_msg = $tgm_msg.\"&lt;b&gt;bold&lt;/b&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;i&gt;italic&lt;/i&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;code&gt;\\$now_date = date('Y-m-d');&lt;/code&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;s&gt;strike&lt;/s&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;u&gt;underline&lt;/u&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;pre language='php'&gt;\\$now_date = date('Y-m-d');&lt;/pre&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"email@test.com\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;pre&gt;email@test.com&lt;/pre&gt;\".\"\\r\\n\";\n?&gt;\n\n\n위 코드처럼 스타일을 적용하고 실행하면 아래와 같이 표시됩니다.\n\n\n\n참고 URL\n\n  텔레그램 채팅 봇 안내\n    \n      https://core.telegram.org/bots/\n    \n  \n  텔레그램 채팅 봇 API 가이드\n    \n      https://core.telegram.org/bots/api/\n    \n  \n  텔레그램 채팅 봇 API 메시지 스타일 가이드\n    \n      https://core.telegram.org/api/entities/\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-11-10"
					}
					
				
			
		
			
				
					,
					
					"3-security-ncp-security-ssl-vpn-vpc-guide": {
						"id": "3-security-ncp-security-ssl-vpn-vpc-guide",
						"title": "VPC 환경에서 SSL VPN 설정하고 접속하는 방법",
						"categories": "3.security",
						"url": " /3.security/ncp_security_ssl_vpn_vpc_guide/",
						"content": "개요\nNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 VPC 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\n\nSSL VPN이란?\n\n  VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다.\n  사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다.\n  가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다.\n\n\nSSL VPN 생성 요청\n[SSL VPN 생성] 버튼을 클릭합니다.\n\n\n\n우선 접근할 서버가 속해 있는 VPC를 선택하고, 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다.\nVPC 환경에서는 3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 선택 가능합니다.\n\n\n\nVPC 환경의 SSL VPN은 콘솔에서 자동으로 생성하는 것이 아니라 생성 요청을 하면 Ncloud 담당자가 직접 생성하고 결과를 안내 받는 구조로 되어 있습니다. \n생성 완료까지 걸리는 기간은 업무일 기준 2~3일 정도이며, 생성이 완료되면 SSL VPN 상태가 [운영중]으로 변경되고, 안내 메일이 도착합니다.\n\n\n\n아래와 같이 생성 요청을 하고 나면 상태가 [생성중] 상태로 표시 됩니다. 2~3일 후 생성 완료 안내 메일이 도착할때까지 기다리시면 됩니다.\n\n\n\nSSL VPN 생성 완료\nSSL VPN 생성이 완료되면 아래와 같은 메일을 받을 수 있습니다. \n메일 내용에는 [SSL VPN IP POOL] 정보와 접속 경로 정보가 포함되어 있으니 잘 확인해야 합니다.\n\n\n  특히 [SSL VPN IP POOL] 정보는 Ncloud 콘솔에서 확인할 수 없고, 오로지 생성 완료 메일에서만 확인 가능하니 잘 보관해야 합니다.\n\n\n\n\n생성 완료 메일 확인 후에 콘솔에 접속하면 아래와 같이 [운영중] 으로 상태 메시지가 바뀐 것을 확인할 수 있습니다.\n\n\n\n사용자 설정\nSSL VPN에 접속할 사용자 정보를 설정합니다.  리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n\n\n\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\nVPC 환경은 Classic 환경과 달리 이차인증이 필수이므로  SMS와 Email 정보를 함께 입력합니다.\n\n\n\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\n\n\n\nRoute Table 설정\n네트워크 설정에서는 우선 접속할 서버가 속해 있는 VPC Subnet의 Route Table에 SSL VPN으로 접근할 수 있게 [SSL VPN IP POOL]을 등록해야 합니다.\n아래와 같이 접속할 서버의 상세정보에서 VPC와 Subnet을 확인합니다. 여기서는 Private Subnet에 생성한 서버에 접속할 예정입니다.\n\n\n\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭합니다.\nPublic Subnet에 생성한 서버에 접근해야 할 경우에는 public-table을 선택하고 설정하시면 됩니다.\n\n\n\n[Destination]에 SSL VPN 생성 완료 메일에서 확인한 [SSL VPN IP POOL] 정보를 등록하고, [Target Type]은 SSLVPN을 선택, [Target Name]은 위에서 생성한 SSL VPN 이름을 선택하고 [생성] 버튼을 클릭합니다.\n\n\n\nACG 설정\n다음으로 서버에 적용된 ACG에 [SSL VPN IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다.\n\n\n\nACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다.\n\n\n\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n\nACG 규칙 설정 화면에서 위에서 확인했던 [SSL VPN IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. \n기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\n\n\n\nAgent 다운로드\nSSL VPN 접속을 위한 Agent를 다운로드 합니다.\n\n\n  윈도우 용 다운로드\n  맥 용 다운로드\n\n\n\n\nAgent 접속\nAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다.\nAgent에는 Classic 환경 SSL VPN 서버(Ncloud-kr-01)가 기본으로 설정되어 있는데, VPC 환경 SSL VPN 서버 주소로 바꾸기 위해 [연결끊기] 클릭해서 연결을 끊고, [서버 변경] 버튼을 클릭합니다.\n\n\n\n서버 선택 창에 https://sslvpn-kr-vpc-01.ncloud.com 주소를 입력합니다.\n\n\n\n주소 변경 후에 [연결] 버튼을 클릭하면 로그인 화면이 나타나는데 위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\n\n\n\n그리고 도착한 OTP 인증 번호를 입력합니다.\n\n\n\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에  [SSL VPN IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n\n\n\n서버 접속\n이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\n\n\n\nAgent 기타 설정\nSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n\n트래픽 그래프\nAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n\n\n\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n\n\n\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n\n\n\n스펙 변경\n처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [스펙 변경] 버튼을 클릭합니다.\n\n\n\n3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n\n\n\n주의사항\nSSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다.  이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n\n\n\n삭제\n삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n\n\n\n하지만, 바로 삭제가 되지 않고 다음과 같이 “Route Table에서 Target으로 지정된 Route 정보를 모두 삭제해야 삭제가 가능합니다”라는 메시지가 뜹니다.\n\n\n\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭해서 등록된 설정을 확인하고 [X] 버튼을 클릭해서 설정을 삭제합니다. \nRoute Table 정보를 삭제한 후에 SSL VPN을 삭제하시면 됩니다.\n\n\n\n참고 URL\n\n  SSL VPN 사용 가이드(VPC)\n    \n      https://guide.ncloud-docs.com/docs/security-security-5-2\n    \n  \n  SSL VPN 요금\n    \n      https://www.ncloud.com/product/security/sslVpn\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-11-02"
					}
					
				
			
		
			
				
					,
					
					"3-security-ncp-security-ssl-vpn-classic-guide": {
						"id": "3-security-ncp-security-ssl-vpn-classic-guide",
						"title": "Classic 환경에서 SSL VPN 설정하고 접속하는 방법",
						"categories": "3.security",
						"url": " /3.security/ncp_security_ssl_vpn_classic_guide/",
						"content": "개요\nNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 Classic 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\n\nSSL VPN이란?\n\n  VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다.\n  사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다.\n  가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다.\n\n\nSSL VPN 생성\n[SSL VPN 생성] 버튼을 클릭합니다.\n\n\n\n우선 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다. Classic 환경에서는 3개, 5개, 10개 상품만 선택 가능합니다. \n다음으로 인증 방식은 ID/PW 만으로 접속하는 일차인증과 OTP까지 사용하는 이차 인증 중에서 원하는 방식을 선택합니다. \n그리고 이차인증을 선택했을 경우에는 SMS와 Email 어떤 것을 이용할 것인지도 선택하게 됩니다.\n\n\n  인증방식과 OTP 전송 방식은 SSL VPN 생성 시에 한번 선택하면 변경할 수 없으니 주의해야 합니다. 만약 변경을 하고 싶을 경우에는 SSL VPN을 새로 생성해야 합니다.\nClassic 환경에서는 이차인증을 선택하면 별도의 이용요금이 부과됩니다.\n\n\n\n\n다음으로 개인정보 수집 및 이용에 동의해야 합니다.\n\n\n\nSSL VPN이 생성되면 다음과 같이 리스트에 서 확인 가능하며 여기서 [SSL VPN IP POOL]은 뒤쪽에서 네트워크 접근 제한을 설정할 때 필요한 중요한 정보입니다.\n\n\n\n사용자 설정\nSSL VPN에 접속할 사용자 정보를 설정합니다.  리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n\n\n\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\n\n\n\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\n\n\n\nACG 설정\nSSL VPN을 사용하려면 서버에 적용된 ACG에 [SSL VPN IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 적용된 ACG를 확인합니다.\n\n\n\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n\nACG 규칙 설정 화면에서 위에서 확인했던 [SSL VPN IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. \n기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\n\n\n\nAgent 다운로드\nSSL VPN 접속을 위한 Agent를 다운로드 합니다.\n\n\n  윈도우 용 다운로드\n  맥 용 다운로드\n\n\n\n\nAgent 접속\nAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다.\nAgent에는 Classic 환경 SSL VPN 서버(Ncloud-kr-01)가 기본으로 설정되어 있는데, 혹시 빠져 있다면 [서버 변경] 버튼을 클릭해서 https://sslvpn-kr-01.ncloud.com을 입력하고 연결 버튼을 클릭합니다.\n\n\n\n위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\n\n\n\nOTP 접속도 설정했다면 도착한 인증 번호를 입력합니다.\n\n\n\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에  [SSL VPN IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n\n\n\n서버 접속\n이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\n\n\n  이때 혹시나 포트 포워딩이나 공인 IP를 설정하고 그 IP를 입력하는 일이 없도록 주의해야 합니다.\n\n\n\n\nAgent 기타 설정\nSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n\n트래픽 그래프\nAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n\n\n\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n\n\n\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n\n\n\n스펙 변경\n처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [스펙 변경] 버튼을 클릭합니다.\n\n\n\n3개, 5개, 10개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n\n\n\n주의사항\nSSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다.  이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n\n\n\n삭제\n삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n\n\n\n참고 URL\n\n  SSL VPN 사용 가이드(Classic)\n    \n      https://guide.ncloud-docs.com/docs/security-security-5-1\n    \n  \n  SSL VPN 요금\n    \n      https://www.ncloud.com/product/security/sslVpn\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-10-28"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-repository-change-on-private-network": {
						"id": "1-compute-ncp-server-repository-change-on-private-network",
						"title": "외부 네트워크에 연결할 수 없는 환경에서 Repository를 변경해 리눅스 패키지 설치하기",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_repository_change_on_private_network/",
						"content": "개요\nNcloud(네이버 클라우드) Secure Zone이나 VPC 환경의 Private Network처럼 외부와 통신이 단절된 환경에서 \n리눅스 패키지를 설치해야 할 때 repository 경로를 네이버 클라우드 내부 repository로 바꾸면 문제없이 패키지 설치를 할 수 있습니다. \n여기서는 OS별로, Classic/VPC 환경별로 변경하는 방법을 정리해보겠습니다.\n\nCentOS\n\nCentOS는 /etc/yum.repos.d/CentOS-Base.repo 를 열어보면 아래 repository주소를 확인할 수 있습니다.\n\n~# vi /etc/yum.repos.d/CentOS-Base.repo\n\n\n\nClassic 환경 - CentOS\n네이버 클라우드 Classic 환경 CentOS에서 repository 주소는 미러 사이트가 기본으로 설정 되어 있는 것을 확인할 수 있습니다.\n\n\n\n하지만 현재 서버는 Secure Zone 등 외부와 통신이 되지 않는 상태이므로 이대로는 패키지 설치를 할 수 없습니다.\n이때 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 접속하도록 mirrorlist를 주석처리하고, baseurl을 주석해제하고, 경로를 수정해주면 됩니다.\n\n## 원본\nmirrorlist=http://mirrorlist.centos.org/?release=$releaserver&amp;arch=$basearch....\n#baseurl=http://mirror.centos.org/centos/$releaserver/extras/$basearch/\n\n## 수정\n#mirrorlist=http://mirrorlist.centos.org/?release=$releaserver&amp;arch=$basearch....\nbaseurl=http://mirror.ncloud.com/centos/$releaserver/extras/$basearch/\n\n\n\n\n변경 후 패키지 설치 테스트를 해봅니다.\n\n~# yum -y install httpd\n\n\n웹서버 설치가 문제없이 되는 것을 확인할 수 있습니다.\n\n\n\nsed 명령어 사용\nsed 명령어를 사용하면 더욱 편하게 변경할 수 있습니다.\n\n## mirrorlist 주석처리\n~# sed -i 's/mirrorlist=/#mirrorlist=/g' /etc/yum.repos.d/CentOS-Base.repo\n\n## baseurl 주석해제, 경로수정\n~# sed -i 's/#baseurl=http:\\/\\/mirror.centos.org\\/centos/baseurl=http:\\/\\/mirror.ncloud.com\\/centos/g' /etc/yum.repos.d/CentOS-Base.repo\n\n\n\nVPC 환경 - CentOS\n네이버 클라우드 VPC 환경은 이미 repository 경로가 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 설정되어 있으므로 별도로 수정할 필요가 없습니다.\n\n\n\nUbuntu\n\nUbuntu는 /etc/apt/sources.list 에서 repository list 를  확인할 수 있습니다.\n다만, 기본 미러사이트 주소가 Classic, VPC 두 환경이 다르게 설정되어 있습니다.\n\n  Classic :  kr.archive.ubuntu.com\n  VPC : archive.ubuntu.com\n\n\n~# vi /etc/apt/sources.list\n\n\nClassic 환경 - Ubuntu\n\n\nVPC 환경 - Ubuntu\n\n\n현재 서버는 Secure Zone 또는 Private Network  등 외부와 통신이 되지 않는 상태이므로 이대로는 패키지 설치를 할 수 없습니다.\n이때 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 접속하도록 경로를 수정해주면 됩니다.\n\n## Classic 환경 - Ubuntu\nkr.archive.ubuntu.com --&gt; mirror.ncloud.com (변경)\nsecurity.ubuntu.com --&gt; mirror.ncloud.com (변경)\n\n## VPC 환경 - Ubuntu\narchive.ubuntu.conm --&gt; mirror.ncloud.com (변경)\n\n\n\n/etc/apt/sources.list 에서 위와 같이 변경-저장한 후에 apt update 를 해주면 변경해준 Ncloud 내부 repository에서 패키지 리스트를 가져와 설치를 합니다.\n\n\n\n설치 된 repository를 테스트 하기 위해 apt install 을 사용하여 패키지 다운로드를 해보면 Ncloud 내부 repository에서 패키지 설치가 진행되는 것을 확인 할 수 있습니다.\n\n~# apt -y install apache2\n\n\n\n\nUbuntu 또한 sed 명령어로 간단하게 변경할 수 있습니다.\n\n## Classic 환경 - Ubuntu\nsed -i 's/kr.archive.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\nsed -i 's/security.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\n\n## VPC 환경 - Ubuntu\nsed -i 's/archive.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\n\n\n참고 URL\n\n  CentOS mirror 사이트 안내\n    \n      https://www.centos.org/download/mirrors/\n    \n  \n  Ubuntu mirror 사이트 안내\n    \n      https://launchpad.net/ubuntu/+archivemirrors\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-10-25"
					}
					
				
			
		
			
				
					,
					
					"81-manage-ncp-manage-cloud-insight-guide": {
						"id": "81-manage-ncp-manage-cloud-insight-guide",
						"title": "모니터링 서비스 Cloud Insight 설정 가이드",
						"categories": "81.manage",
						"url": " /81.manage/ncp_manage_cloud_insight_guide/",
						"content": "개요\n네이버 클라우드와 사용자 애플리케이션의 성능/운영 지표를 통합 관리하고, 장애나 이벤트가 발생했을 때 SMS 및 Email로 알람 통보를 해주는 서비스인 Cloud Insight 서비스를 설정하는 방법에 대해 정리해보겠습니다.\n\nMonitoring 서비스 vs Cloud Insight 서비스\nClassic 환경에 있는 Monitoring 서비스와 Cloud Insight 서비스의 차이점을 정리하면 다음과 같습니다.\n\n\n  Monitoring 서비스는 Classic 환경에서만 사용할 수 있다.\n  Cloud Insight 서비스는 Classic, VPC 양쪽에서 모두 사용할 수 있고, 두가지 환경을 통합해서 보여준다.\n  Monitoring 서비스는 Server 제품 (AutoScaling 포함)만 모니터링 한다.\n  Cloud Insight 서비스는 Server 뿐만 아니라 Object Storage, Load Balancer 등 10여개의 서비스를 모니터링 한다.\n\n\n적용 서비스 리스트\n위 비교에서도 설명했듯이 Cloud Insight는 Server 뿐만 아니라 네이버 클라우드의 다양한 서비스의 모니터링 정보를 확인할 수 있는데 해당 리스트는 다음과 같습니다.\n\nClassic\n\n  Server\n  Load Balancer\n\n\nVPC\n\n  Server(VPC)\n  Load Balancer(VPC)\n  Cloud DB for MySQL(VPC)\n  Cloud DB for MSSQL(VPC)\n  Cloud DB for Redis(VPC)\n  Cloud DB for MongoDB(VPC)\n  Cloud Hadoop(VPC)\n  Auto Scaling Group(VPC)\n  Kubernetes Service(VPC)\n  Search Engine Service(VPC)\n  Cloud Data Streaming Service(VPC)\n\n\n통합\n\n  Cloud Search\n  Object Storage\n\n\n이용 신청\nCloud Insight 서비스는 이용 신청을 해야 사용할 수 있습니다. Classic, VPC 어떤 환경에서든 [Cloud Insight(Monitoring)] - [Subscription]에서 [상품 이용 신청] 버튼을 클릭해서 이용 신청을 합니다.\n\n\n\n대시보드\n이용 신청을 한 후에 [Dashboard] 메뉴에 가면 아래와 같이 현재 사용 중인 서비스 중에서 모니터링 가능한 서비스 리스트를 확인할 수 있습니다.\n또한 기본으로 제공되는 대시보드에서 확인할 수 있는 모니터링 항목을 각 서비스별로 고정되어 있습니다. \n추가적인 항목을 확인하려면 별도로 대시보드를 생성해야 하는데 이에 대해서는 아래쪽에서 확인해보겠습니다.\n\n\n  일부 서비스의 경우 리스트에 나타날 때까지 시간이 걸릴 수도 있습니다. 여유있게 1시간 정도 후에 확인해보시면 됩니다.\n\n\n\n\nLoad Balancer 모니터링\n\n\nObject Storage 모니터링\n\n\nServer 모니터링\n위에서 설명했듯이 Server 제품도 GPU 관련 항목을 제외하면 5가지 정도의 기본 모니터링 항목을 확인할 수 있습니다.\n\n\n\n커스텀 대시보드\n좀 더 상세한 모니터링 데이터를 확인하려면 커스텀 대시보드가 필요하고 그전에 [상세 모니터링]을 설정해야 합니다. 서버 설정에서 [상세 모니터링 설정 변경] 메뉴를 클릭합니다.\n\n\n\n[상세 모니터링 신청] 팝업에서 [예] 버튼을 클릭합니다.\n\n\n\n대시보드 생성\n[Dashboard] 화면에서 [대시보드 생성] 버튼을 클릭합니다.\n\n\n\n생성 팝업에서 대시보드 이름과 설명을 입력합니다.\n\n\n생성된 대시보드에서 [위젯 추가] 버튼을 클릭해서 위젯을 추가합니다.\n\n\n위젯 이름을 입력하고, 종류는 [Time Series], [Pie Chart], [Table], [Index], [Markdown] 중에서 하나를 선택합니다.  여기서는 [CPU Usage]와 [Time Series]를 선택했습니다.\n\n\n\n다음으로 데이터 설정에서 CPU 사용율에 해당하는 CPU/used_rto 등 필요한 항목을 선택하고 [선택 항목 추가] 버튼을 클릭합니다.\n\n\n\n항목을 추가하면 아래쪽 화면에 다음과 같이 리스트를 확인할 수 있습니다. 설정이 완료되었으면 [다음] 버튼을 클릭해 마지막 확인을 하고 생성을 완료합니다.\n\n\n\n위에서 추가한 [CPU Usage] 위젯과 함께 추가로 [Server - Load Average], [File System], [Memory Usage], [Net Work (Max In/Out bps)] 데이터를 확인할 수 있는 위젯을 추가하면 다음과 같은 대시보드를 확인할 수 있습니다.\n\n\n\n통보 대상자 등록\n이제 이벤트를 등록하고 알람을 통보 받을 대상자를 등록해보겠습니다.\n먼저 통보 대상자 그룹을 생성합니다.  [Cloud Insight(Monitoring)] - [Notification Recipient] 메뉴에서 [전체 대상자] 옆에 있는 [ + ] 버튼을 클릭하고 아래 입력칸에 그룹명을 입력합니다.\n\n\n\n네이버 클라우드 계정 생성을 할 때 기본으로 1명의 대상자가 등록됩니다. 해당 대상자를 위에서 생성한 그룹에 할당하기 위해 선택하고 [할당] 버튼을 클릭합니다.\n\n\n\n그룹 할당 팝업에서 [할당] 버튼을 클릭합니다.\n\n\n대상자 리스트에서 해당 대상자에 그룹이 할당된 것을 확인할 수 있습니다.\n\n\n\n이벤트 규칙 등록\n이제 이벤트를 등록해보겠습니다. [Cloud Insight(Monitoring)] - [Configuration] - [Event Rue]에서 [Event Rule 생성] 버튼을 클릭합니다.\n\n\n\n이벤트 규칙을 생성해서 감시가 필요한 상품을 선택합니다. 여기서는 [Sever(VPC)]를 선택하겠습니다.\n\n\n\n[감시 대상 설정]에서 [전체 보기]를 선택하고, 감시 대상에 체크한 후 [다음] 버튼을 클릭합니다.\n\n\n\n감시 항목 및 조건 설정에서 [전체 보기]를 선택하고, CPU, Memory 등의 항목 중에서 원하는 항목을 선택합니다.\n여기서는 [CPU]에서 CPU 사용율에 해당하는 [CPU/used_rto]를 선택하고, 90% 이상인 상태가 5분 이상 지속되면 경고 알림을 보내도록 설정했습니다.\n\n\n\n다음으로 감시 대상에서 설정한 이벤트가 발생했을 때 어떤 액션을 취할 것인가를 설정해보겠습니다.\n설정 가능한 액션은 [알림 메시지 발송], [Integration], [Cloud Functions], [Auto Scaling 정책] 중에서 선택할 수 있는데, 여기서는 [알림 메시지 발송]을 선택하겠습니다.\n통보 대상자 그룹을 선택하고, [Email]과 [SMS]중에서 원하는 것을 선택하고, [다음] 버튼을 클릭합니다.\n\n\n\n마지막으로 이벤트 규칙 이름을 입력하고, 앞에서 설정한 내용들을 확인한 후에 [생성] 버튼을 클릭합니다.\n\n\n유지보수 계획 설정\n앞에서 설정한 이벤트 규칙이 업데이트나 점검 등의 유지보수가 진행되는 동안에도 작동되면 유지보수 시간 동안 쉼없이 통보 알람이 울리게 됩니다.\n이런 불편함이 없도록 Cloud Insight에서는 유지보수 계획 일정을 등록해두면 등록된 기간 동안에는 이벤트 규칙에 따른 통보알람이 울리지 않습니다.\n\n유지보수 일정은 아래와 같이 달력 행태나 리스트 형태로 확인 가능하며 [유지보수 계획 설정하기] 버튼으로 일정을 등록할 수 있습니다.\n\n\n\n제목을 입력하고, 작업 기간, 작업 대상, 디멘션을 선택하면 아래와 같이 선택한 대상과 디멘션이 리스트로 나타납니다.  보통 위에서 설정했던 이벤트 규칙에 해당하는 항목들을 선택하면 됩니다.\n\n\n\n유지보수 계획을 설정하면 아래와 같이 일정에서 확인할 수 있으며 해당 기간 동안에는 이벤트 통보가 진행되지 않습니다.\n\n\n\n참고 URL\n\n  Cloud Insight 소개\n    \n      https://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightoverview\n    \n  \n  Cloud Insight 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightconsole\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-10-18"
					}
					
				
			
		
			
				
					,
					
					"81-manage-ncp-manage-monitoring-guide": {
						"id": "81-manage-ncp-manage-monitoring-guide",
						"title": "서버 모니터링 서비스 Monitoring 설정 가이드",
						"categories": "81.manage",
						"url": " /81.manage/ncp_manage_monitoring_guide/",
						"content": "개요\n네이버 클라우드 Classic 환경에서 서버 모니터링을 설정하는 가이드입니다.\nClassic에서는 Monitoring 서비스와 Cloud Insite(Monitoring) 서비스 이렇게 2가지 서비스가 있는데 여기서는 Monitoring 서비스를 설정하는 방법에 대해 정리해보겠습니다.\n\n기본 모니터링 vs 상세 모니터링\n\n  \n    기본 모니터링 : 네이버 클라우드에서 서버를 생성하면 별다른 설정을 하지 않아도 CPU, Memory 사용 등의 기본적인 항목들의 데이터를 확인할 수 있는데 이를 기본 모니터링이라고 하며 5분 단위의 데이터를 확인할 수 있습니다.\n확인 가능한 데이터는 [CPU Used], [Memory Used (except cache/buffer)], [Disk Used], [Swap Used], [Network In (bps)], [Network Out (bps)], [Disk Read (bytes)], [Disk Write (bytes)] 입니다.\n  \n  \n    상세 모니터링 : 기본 모니터링보다 훨씬 많고 상세한 데이터를 확인하고, 상태 감시와 통보 알람 설정을 통해 지정한 수치 이상의 상태가 되면 문자나 메일로 통보 받을 수 있는 모니터링 서비스이며, 1분 단위의 데이터를 확인할 수 있습니다. \n네이버 클라우드 [Console] - [Monitoring] 서비스가 바로 [상세 모니터링]입니다. 또한 [Monitoring] 서비스에서는 Auto Scaling 그룹에 대한 이벤트 설정도 할 수 있습니다.\n  \n\n\n기본 모니터링\n아래와 같이 서버 리스트에서 모니터링할 서버를 선택하고 위에 있는 [모니터링] 버튼을 클릭합니다.\n\n\n\n기본 모니터링에서는 5분 주기의 데이터를 확인할 수 있고, 날짜와 기간을 선택해서 데이터를 확인할 수 있습니다.\n\n\n\n상세 모니터링\n[Monitoring] 서비스 즉, 상세 모니터링 서비스는 별도로 설정이 필요한데 설정하는 방법은 아래와 같이 기본 모니터링 화면에서 [상세 모니터링 설정] 링크를 클릭하거나, \n서버 리스트에서 [서버 관리 및 설정 변경] 메뉴 - [상세 모니터링 설정 변경] 메뉴를 클릭하면 됩니다.\n\n\n\n\n\n[상세 모니터링] 신청화면입니다. 특별한 설정이 필요한 것은 아니므로 신청 화면에서 [예] 버튼을 클릭합니다.\n\n\n\n[상세 모니터링] 신청이 끝나면 바로 [Monitoring] - [Notification Recipient] 즉, 이벤트 통보 대상자 화면으로 넘어갑니다.  여기서는 모니터링 대상인 서버에서 이벤트가 발생했을 때 연락이 가도록 대상자를 등록하게 됩니다.\n기본으로 계정 사용자 정보가 등록되어 있는데, 혹시 등록되지 않았을 경우에는 [대상자 추가] 버튼을 클릭해서 통보 대상자를 등록합니다.\n\n\n\n대시보드\n\n통합 대시보드\n[Monitoring] - [Integrated Dashboard] 즉, 통합 대시보드 메뉴로 이동합니다.\n여기서는 일별 이벤트 발생 횟수와 히스토리, 그리고, 각 모니터링 항목별로 상위 5개의 서버 정보를 통합해서 표시합니다.\n\n\n\n서버 대시보드\n[Monitoring] - [Dashboard] - [Server Dashboard]에서는 전체 서버들의 상세한 모니터링 데이터를 리스트로 확인할 수 있습니다.\n\n\n\n좀 더 자세한 정보를 확인하고 싶으면 서버 리스트에서 원하는 서버를 선택합니다.\n\n\n\n서버를 선택하면 아래와 같이 모니터링 데이터를 차트로 확인할 수 있습니다.\n\n\n\n그리고 서버 Process와 File System 사용 정보도 상세하게 확인할 수 있습니다.\n\n\n\n감시-통보 설정\nMonitoring 시스템에서 수집하는 성능 Item 중 사용자가 지정한 Item이 임계치 값을 벗어난 경우에 Event가 발생합니다. \nEvent를 발생 하게 하는 조건을 감시설정이라 하며 해당 Event를 Mail or SMS로 수신 받는 설정을 통보설정이라고 합니다.\n\n[Monitoring] - [Configuration] - [New Observation] 메뉴에서 우선 감시설정에 등록하고자 하는 서버를 먼저 선택하고 하단의 감시설정 버튼을 클릭합니다.\n\n\n\n다음으로 감시할 항목을 설정합니다. CPU, Memory 등 원하는 분류와 항목을 선택하고 임계치 등의 수치를 입력 후 추가 버튼을 클릭합니다.\n또한, 미리 Template을 등록해 두면 이후에 여러 서버들에 설정을 쉽게 적용할 수 있습니다.\n\n분류 항목별 주의 사항\n\n  프로세스: 상세 입력칸에 프로세스명을 입력할 때는 정규 표현식으로 입력해야 합니다.\n  파일 시스템:  상세 입력칸에 경로 입력 시 Linux의 경우 ‘/’ 경로로 입력하고, Windows의 경우 ‘C:, D:’ 등의 경로로 반드시 대문자로 입력합니다.\n\n\n\n\n그 다음은 통보 받을 대상자와 통보 방법을 선택하고 [추가] 버튼을 클릭합니다. 통보 대상자가 리스트에 없을 경우 위쪽에 있는 [통보대상관리] 버튼을 클릭해서 대상자를 등록한 후에 다시 추가합니다.\n\n\n\n마지막으로 지금까지 설정한 내용들을 다시 한번 확인 한 후에 [최종 확인] 버튼을 클릭합니다.\n\n\n\n통보 알람 중지\n서버 점검 등을 진행할 때는 통보 알람 기능을 중지 시켜두면 불필요한 알람을 받을 필요가 없어서 편리합니다.\n[Monitoring] - [Configuration] - [Notification Stop] 메뉴에서 서버를 선택하고 [알람중지] 버튼을 클릭합니다.\n\n\n\n알람 중지 팝업 화면에서 목적과 기간 등을 선택해서 적용합니다.\n\n\n\n참고 URL\n\n  Sub Account 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/management-management-1-1\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-10-08"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-autoscaling-classic-guide": {
						"id": "1-compute-ncp-server-autoscaling-classic-guide",
						"title": "Classic 환경에서 AutoScaling 설정하는 방법",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_autoscaling_classic_guide/",
						"content": "개요\nAutoScaling 서비스는 미리 등록한 설정에 따라 서버 수를 자동으로 증가 또는 감소시켜 안정적인 서비스를 유지하면서 비용을 절감할 수 있도록 해주는 서비스입니다.\n여기서는 네이버 클라우드 Classic 환경에서 AutoScaling 설정하는 방법을 정리해보겠습니다.\n\n기본 설정\nAuto Scaling 설정은 우선 [Auto Scaling] - [Launch Configuration]에서\n[Launch Configuration 생성] 버튼을 클릭하는 것으로 시작합니다.\n\n\n\n서버 이미지 선택\n서버 이미지는 네이버 클라우드에서 제공하는 기본 이미지를 선택할 수도 있고, 기존 서버로 만들어 둔 [내 서버 이미지]를 사용할 수도 있습니다. 여기서는 기본 이미지를 사용하는 것으로 하겠습니다.\n\n\n\n서버 설정\n스토리지 종류와 서버 타입 등을 선택합니다.\n\n\n\n이름 설정\nLaunch Configuration의 이름을 입력합니다.\n\n\n\n인증키 설정\n인증키는 기존에 보유하고 있던 인증키를 이용해도 되고, 새로운 인증키를 설정해도 됩니다.\n\n\n\n네트워크 접근 설정 (ACG)\nACG 설정도 기존에 보유하고 있던 ACG 중에서 선택해도 되고, 새로운 ACG를 생성해도 됩니다. 여기서는 새로운 ACG를 생성하는 방법으로 진행하겠습니다.\n\n\n\nACG 이름을 입력하고, [myIp]를 클릭, 허용할 포트를 입력한 후 [추가] 버튼을 클릭합니다.\n\n\n\n최종 확인\n지금까지 설정한 정보를 마지막으로 확인 한 후에 이상이 없으면 [Launch Configuration 생성] 버튼을 클릭합니다.\n\n\n\nGroup 생성\n다음으로 Auto Scaling Group을 생성합니다. [Auto Scaling] - [Auto Scaling Group]에서 [Auto Scaling Group 생성] 버튼을 클릭합니다.\n\n\n\nLaunch Configuration 선택\n위에서 생성했던 Launch Configuration을 선택합니다.\n\n\n\n그룹 설정\n여기서는 생성될 서버들의 이름과 최소, 최대 개수 등을 설정합니다.\nAuto Scaling Group당 최대 30대의 서버를 생성할 수 있고, Zone, NAT Gateway 설정은 생성 후 변경할 수 없으며, 변경이 필요하면 새로 생성하여 사용해야 합니다.\n\n\n\n\n  서버이름 Prefix : 최대7자까지 지정할 수 있고, 나머지 이름의 뒷부분은 영문,숫자의 조합으로 무작위로 자동 생성됩니다.\n  서버 용량 : 최소, 최대, 기대 용량은 서버 대수를 의미하며 각각 0~30까지 입력 가능합니다.\n  \n    쿨다운 기본값 : 새로운 서버가 생성되었다고 해도, init script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. \n즉, 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 반응하지 않고 무시하도록 설정한 기간입니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n  \n  헬스체크 보류기간 : 서버 인스턴스가 생성되어 상태가 ‘운영 중’으로 바뀌었더라도, 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. \n이런 경우 헬스 체크 보류 기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버에 이상이 있다고 판단하지 않습니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n\n\n\n\n정책/일정 설정\n정책과 일정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있습니다. 여기서는 [나중에 설정]으로 선택하고 아래쪽에서 다시 살펴보겠습니다.\n\n\n\n통보 설정\n통보 설정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있습니다. 여기서는 [나중에 설정]으로 선택하고 아래쪽에서 다시 살펴보겠습니다.\n\n\n\n최종확인\n생성된 Group 설정값들을 마지막으로 확인하고 [Auto Scaling Group 생성] 버튼을 클릭합니다.\n\n\n\n서버 생성 확인\n위에서 Auto Scaling Group을 생성하면 아래와 같이 즉시 서버가 생성되는 것을 확인할 수 있습니다. 처음에는 [기대용량]에 입력한 개수만큼 서버가 생성됩니다.\n\n\n\n설정 관리 - 정책\n위에서 나중에 설정하기로 하고 넘어갔던 Auto Scaling Group의 정책, 일정, 이력, 통보 설정 등을 확인해보겠습니다.\n[Auto Scaling Group]에서 해당 그룹을 선택하고, [설정 및 관리] 버튼을 클릭합니다.\n\n\n\n정책 설정\n먼저 [정책] 탭을 선택하고, [생성] 버튼을 클릭합니다.\n\n\n\n우선 서버를 증가시킬 정책으로 increase라는 이름을 입력하고, 증가시킬 서버 개수를 입력 후 [추가] 옵션을 선택하고 [생성] 버튼을 클릭합니다.\n\n\n\n다음으로 서버를 감소시킬 정책으로 decrease라는 이름을 입력하고, 감소시킬 서버 개수를 입력 후 [반납] 옵션을 선택하고 [생성] 버튼을 클릭합니다.\n\n\n\n서버 증가, 감소를 위한 정책 2가지가 생성된 것을 확인할 수 있습니다.\n\n\n\n그룹 이벤트 설정\n위에서 설정한 정책이 언제 실행되게할 것인가 즉, 서버에 어떤 이벤트가 발생했을 때 정책을 실행할 것인가를 결정하는 그룹 이벤트를 설정합니다.\n그룹 이벤트 설정은 [Classic] - [Monitoring] - [Group Event Setting]에서 할 수 있으며, 위에서 만든 Auto Scaling 그룹을 선택하고 [그룹 이벤트 설정] 버튼을 클릭합니다.\n\n\n\n그룹 이벤트 설정 화면에 들어가면 위에서 만든 increase, decrease 2가지 정책이 리스트에 나타나는 것을 확인할 수 있습니다.\n\n\n\n정책이 발동되게 하는 이벤트는 여러가지가 있는데, 가장 많이 선택하는 것이 CPU 사용률입니다.\n여기서는 CPU 사용률(used)이 60% 이상일 때 increase 정책, CPU 사용률(used)이 30% 이하일 때 decrease 정책이 실행되도록 이벤트를 추가했습니다.\n\n\n\n설정 관리 - 일정\n위에서는 서버에 설정한 이벤트가 발생했을 때 정책이 발동되도록 했지만, 그 외에도 특정한 시간대에 사용자가 몰리는 피크 타임이 일정하다면 해당 시간 전후로 서버를 늘리거나 감소시키는 방법도 가능합니다.\n여기 [일정] 탭에서 해당 내용을 설정해두면 피크 타임에 미리 서버를 증가시켜서 좀 더 안정적인 서비스가 가능하게 설정할 수 있습니다.\n\n\n\n설정 관리 - 이력\n[이력] 탭에서는 서버가 생성되고 반납된 기록을 확인할 수 있습니다.\n\n\n\n설정 관리 - 통보\n[통보] 탭에서는 서버가 생성되거나 반납될 때 지정한 담당자에게 SMS나 Email로 통보하도록 설정할 수 있습니다.\n\n\n\n설정 관리 - 서버\n[서버] 탭은 현재 작동중인 서버 리스트를 확인할 수 있습니다.\n\n\n\n중지 - 서버삭제\n마지막으로, Auto Scaling을 중지하고, 작동중인 서버를 한번에 모두 삭제하는 방법을 확인해보겠습니다.\n\n[Auto Scaling] - [Auto Scaling Group]에서 해당 그룹을 선택하고 상단에 있는 [수정] 버튼을 클릭합니다.\n\n\n\n여기서 [최소 용량], [최대 용량], [기대 용량] 항목의 값을 모두 0으로 설정하면, 현재 작동중인 서버가 모두 반납되고, 더 이상 서버가 추가로 생성되지 않아서 Auto Scaling이 중지되게 됩니다.\n사실 [최소 용량], [기대 용량] 2가지 항목만 0으로 설정해도 되지만, 혹시나 모르는 상황을 위해서 깔끔하게 3가지 항목 모두 0으로 설정합니다.\n\n\n\n서비스 제한사항\nAuto Scaling 설정과 서버 스펙 등에 대한 제한 사항을 정리해보겠습니다.\n\n스펙 및 서비스 환경 제한 사항\n\n  총 디스크 사이즈 150GB 이하 서버만 가능\n  Windows OS는 Windows 2012. 2016만 지원\n  내 서버 이미지의 경우, 원본 서버의 부팅 디스크 크기가 50GB인 경우만 지원(100GB 디스크에 대해서는 추후 지원 예정)\n\n\n설정 제한 사항\n\n  고객별 생성 가능한 Auto Scaling Group 최대 수: 10\n  고객별 생성 가능한 Launch Configuration 최대 수: 100\n  Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100\n  Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10\n  Auto Scaling Group당 생성 가능한 최대 서버 수: 30대\n  Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10\n\n\n용어 정리\nAuto Scaling에서 사용되는 주요 용어들을 정리해보겠습니다.\n\n\n  \n    \n      용어\n       \n      설명\n    \n  \n  \n    \n      Scale-in / Scale-out\n       \n      Auto Scaling Group을 생성하여 고객이 설정한 Policy에 따라 사용하고 있는 가상 서버의 자동 확장(Scale-out) 및 자동 축소(Scale-in)하도록 제공합니다.\n    \n    \n      Auto Scaling Group\n       \n      여러 개의 서버 인스턴스들을 Auto Scaling Group 이라는 하나의 그룹으로 묶어 놓게 됩니다.\n    \n    \n      Launch Configuration\n       \n      Auto Scaling Group에서 가상 서버를 시작 구성하는 데 사용하는 템플릿입니다. Auto Scaling Group을 생성할 때는 Launch Configuration을 지정해야 합니다.\n    \n    \n      Auto Scaling Group의 최소 용량/최대 용량\n       \n      Auto Scaling Group의 최소/최대 서버 수를 말합니다. 최소 서버 수의 경우, 항상 이 값과 같거나 이 값보다 더 큰 서버 수가 유지됩니다. 서버를 한 대도 보유하지 않을 수 있게 하려면 0으로 설정합니다.\n    \n    \n      기대 용량 (Desired Capacity)\n       \n      서버의 수는 기대 용량값에 따라서 조정됩니다. 이 값은 최소 용량 이상, 최대 용량 이하여야 합니다. 이 값이 지정되어 있지 않으면 초기에 최소 용량만큼 서버를 생성합니다.\n    \n    \n      쿨다운 기본값(초) (Default Cooldown)\n       \n      Default Cooldown(초) 새로운 서버가 생성되었다고 해도, Init-Script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 무시하도록 설정한 기간입니다.\n    \n    \n      헬스체크\n       \n      Auto Scaling Group의 가상 서버에 주기적인 상태 확인을 수행하여 상태가 비정상인 가상 서버를 식별하도록 Health Check를 합니다.\n    \n    \n      헬스체크 보류 기간\n       \n      서버가 생성되어 ‘운영중’으로 변경되었더라도 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. 이런 경우 헬스 체크 보류기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버 헬스에 이상이 있다고 판단하지 않습니다.\n    \n    \n      헬스체크 유형\n       \n      서버와 Load Balancer 둘 중에 선택할 수 있습니다. Auto Scaling Group 설정에서 Load Balancer 이름을 지정한 경우에는 헬스 체크 유형 역시 Load Balancer로 설정합니다. 이런 경우 Auto Scaling은 Load Balancer 헬스 체크 방식과 기준에 따라 서버의 상태를 판단합니다.\n    \n    \n      반납 정책\n       \n      Auto Scaling 과정에서 추가된 서버에 대한 Scale-in 작업에 대해, 고객이 API 질의 형식으로먼저 반납할 서버를 지정할 수 있습니다. 기본 설정은 먼저 생성된 서버부터 반납합니다.\n    \n    \n      Policy\n       \n      Auto Scaling이 일어나는 방식을 정의하고 있는데, 이를 ‘Policy’로 정의하고 있습니다. Auto Scale-out 이 발생할 때, 몇 대의 가상 서버를 늘릴 것인지, 반대로 Scale-in이 발생할 때 몇 대의 가상서버를 줄일 것인지를 정의합니다. 대수로 정의할 수 도 있고, %로 정의할 수도 있습니다.\n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview\n\n\n  문서 최종 수정일 : 2021-09-17"
					}
					
				
			
		
			
				
					,
					
					"3-security-ncp-security-ssl-dcv-method": {
						"id": "3-security-ncp-security-ssl-dcv-method",
						"title": "SSL인증서 DCV (Domain Control Validation) 인증 방법과 유의사항 정리",
						"categories": "3.security",
						"url": " /3.security/ncp_security_ssl_dcv_method/",
						"content": "개요\nHTTPS 접속을 위한 SSL 인증서를 발급 받기 위해서는 DCV (Domain Control Validation)를 인증받아야 하는데, 이때 필요한 인증방법과 유의 사항을 정리해보겠습니다.\n\nDCV 인증 방법\nDCV 인증방법은 3가지가 있습니다.\n\n\n  Email 인증\n  DNS 인증\n  http 인증\n\n\nEmail 인증\nEmail 인증은 도메인 등록정보에서 확인되는 이메일과 추가로 5개의 임의로 지정된 메일주소로 인증메일을 발송합니다.\n\n도메인 등록 정보 이메일\n도메인 등록 기관에서 도메인 소유자 정보를 노출하지 않는 블라인드 서비스를 이용하고 있을 경우 인증메일을 받을 수 없습니다.\nEmail 인증을 하기 전에 블라인드 서비스를 해제하고 인증을 요청하셔야 합니다.\n\n추가 5개의 임의로 지정된 이메일\n임의로 지정된 이메일 주소는 admin, administrator, hostmaster, postmaster, webmaster 등 5가지이며 추가/수정이 불가능합니다.\n\n\n  위의 총 6개 메일 주소 중에서 적어 1개는 유효한 메일주소여야 이메일 인증을 문제없이 완료할 수 있습니다.\n\n\n이메일 인증 유의사항\n\n  해외 발신 이메일이 차단되도록 설정되어 있지 않은지 확인이 필요합니다.\n  메일함 용량 부족으로 반송되지 않도록 확인이 필요합니다.\n  자체 메일 서버일 경우 메일서버가 장애가 생기지 않도록 확인이 필요합니다.\n  스팸 차단 서비스나 장비에서 차단이 될 수도 있으므로 확인이 필요합니다.\n\n\n참고 : https://www.sslcert.co.kr/products/domain-control-validation#email\n\nDNS 인증\nDNS 인증은 다음과 같은 순서로 진행하면 됩니다.\n\n\n  인증서 신청 사이트에서 CNAME 처리를 위한 DNS 인증용 Host, Record 용 값을 확인합니다.\n  DNS에 위에서 확인한 값으로 CNAME Record를 등록합니다.\n  인증서 신청 사이트에서 DNS 인증 요청 버튼을 클릭합니다.\n\n\n# 예시\n# {Host값}.test.co.kr CNAME {Record Value}\n_PVG823NLK4DFSVFSANLK.test.co.kr CNAME 089DFCHKJFDSUIFDSLKJ38NF.ssltest.com\n\n\n\nDNS 인증 유의사항\n\n  Host 값 첫번째 문자열이 _(언더바)입니다. CNAME 등록시에 빠뜨리지 않도록 주의해야 합니다.\n  DNS서버에서 TTL 값을 너무 길게 설정하면 그 시간 만큼 인증을 받을 수 없으므로 주의해야 합니다.\n\n\n참고 : https://www.sslcert.co.kr/products/domain-control-validation#dns\n\nhttp 인증\nhttp인증은 http 인증용 코드를 다운로드 받아 해당 도메인 웹사이트에 등록하는 방법입니다.\n\n\n  인증서 신청 사이트에서 http 인증용 코드 파일을 다운로드 받습니다.\n  해당 도메인 사이트에  /.well-known/pki-validation/ 경로를 생성합니다.\n  다운로드 받은 인증 코드 파일을 위 경로에 업로드 합니다.\n  인증서 신청 사이트에서 http 인증 요청 버튼을 클릭합니다.\n\n\n해당 도메인이 test.co.kr 일 경우 인증 코드 파일의 경로는 다음과 같은 형식이어야 합니다.\n   http://test.co.kr/.well-known/pki-validation/[파일명].txt\n\n\n\nhttp 인증 유의사항\n\n  인증 코드 파일은 수정하면 안됩니다.\n  인증 코드 파일 포맷은 ANSI 포맷이어야 합니다.\n  SSL 발급 신청시 도메인에 www. 입력하였더라도, DCV 인증시에는 www를 제외하고 검사가 진행됩니다.\n만약  현재 사이트가 www. 로만 접속가능한 상태라면, DCV 인증을 위해 임시라도 www. 제외된 접속이 가능하게 만들어 놓아야 합니다.\n\n\n참고 : https://www.sslcert.co.kr/products/domain-control-validation#http\n\n로드밸런서(Load Balancer)를 사용하면서 http 인증할 때 사전작업\nhttp 인증을 하려고 할 때 로드밸런서를 사용하게 될 경우 로드밸런서의 도메인을 DNS에서 CNAME 처리를 먼저 진행하고, DNS 전파가 완료된 것을 확인한 후에 http 인증을 요청해야 합니다.\n\n예를 들어 네이버 클라우드에서는 다음과 같이 처리하면 됩니다.\n\n# DNS CNAME 처리 예제\nwww.test.co.kr  CNAME  slb-****.ncloudslb.com\n\n\n참고 URL\n\n  인증서 발급 사이트 : SecureSign\n    \n      https://www.sslcert.co.kr/\n    \n  \n  DCV 인증 절차 안내\n    \n      https://www.sslcert.co.kr/products/domain-control-validation\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-09-10"
					}
					
				
			
		
			
				
					,
					
					"81-manage-ncp-manage-sub-account-guide": {
						"id": "81-manage-ncp-manage-sub-account-guide",
						"title": "Sub Account 생성 가이드",
						"categories": "81.manage",
						"url": " /81.manage/ncp_manage_sub_account_guide/",
						"content": "개요\nSub Account(서브 계정)는 네이버 클라우드의 서비스 자원을 여러 사용자가 동시에 이용, 관리해야 할 때 필요한 만큼만 권한을 부여해서 사용할 수 있게 해주는 서비스입니다.\nSub Account를 사용하면 사내 담당부서나 담당자별로 지정된 자원에만 접근하도록 하거나, 협력사에게 일부 접근권한을 부여해야 할 때 효과적입니다.\n\n특징\n네이버 클라우드의 Sub Account는 다음과 같은 특징이 있습니다.\n\n\n  별도의 로그인 페이지를 이용하여 접속\n  대시보드에서 서브 계정 수, 그룹 수, 정책 수, 접속 페이지 설정을 확인할 수 있음\n  그룹, 정책, 역할을 생성해 상세한 권한 설정을 할 수 있음\n  Access Key를 별도로 생성해서 사용할 수 있음\n\n\n주요 권한\n\n\n  \n    네이버 클라우드 메인 계정과 동일한 접근 권한\n  NCP_ADMINISTRATOR 정책을 부여하시면 메인 계정과 동일하게 네이버클라우드플랫폼 내 포털, 콘솔을 접근할 수 있습니다\n  \n  \n    네이버 클라우드 콘솔 내 모든 상품/서비스 접근 권한\n  NCP_INFRA_MANAGER 정책을 부여하시면 메인 계정과 동일하게 콘솔 내 모든 상품/서비스에 접근할 수 있습니다.\n  \n  \n    네이버 클라우드 콘솔 내 각 상품/서비스별 접근 권한\n  NCP_상품/서비스명_MANAGER/VIEWER 정책을 부여하시면 해당 상품/서비스에 접근할 수 있습니다.\n  \n  \n    네이버 클라우드 포털 내 마이페이지 “이용관리” 메뉴 접근 권한\n  NCP_FINANCE_MANAGER 정책을 부여하시면 포털 마이페이지 내 “서비스 이용내역/현황, 프로모션 내역, 청구 내역 추세” 메뉴에 접근할 수 있습니다.\n  \n\n\n서브 계정 생성\n[Console] - [Sub Account] - [Sub Accounts]에서 [서브 계정 생성] 버튼을 클릭합니다.\n\n\n\n서브 계정 생성 화면에서는 로그인 아이디, 이름, 이메일 주소를 우선 입력합니다.\n\n다음으로 접근 유형으로 [Console 접근]과 [API 접근]을 모두 허용할 것인지, 하나만 허용할 것인지 선택하고, \nConosole 접근의 경우에 지정한 IP대역에서만 접근하게 할 것인지, 모두 허용할 것인지도 선택합니다.\n\n휴대폰 문자인증 또는 이메일 인증 등의 2차 인증을 적용할 것인지도 선택합니다.\n\n\n\n마지막으로 로그인 비밀번호를 입력하고, 해당 서브 계정으로 로그인 시에 비밀번호를 변경하도록 할 것인지 선택할 수 있습니다.\n\n\n\n계정 정책 추가\n생성된 서브 계정을 클릭하면 서브 계정 상세 설정 화면으로 이동합니다.\n\n\n\n서브 계정 상세 화면에서는 정책, 그룹, Access Key를 추가하고 관리할 수 있습니다.  우선 정책 탭에서 [추가] 버튼을 클릭합니다.\n\n\n\n정책 추가 화면에서는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책]과 사용자가 직접 정의하는 [사용자 정의 정책]이 있습니다.\n우선 [관리형 정책]에서 필요한 정책을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n\n여기서는 네이버 클라우드의 Server 상품 내 모든 기능을 이용할 수 있는 권한인 [NCP_SERVER_MANAGER] 선택했고, 아래와 같이 추가된 것을 확인할 수 있습니다.\n\n\n\n접속 환경 설정\n네이버 클라우드 서브 계정은 별도의 접속 페이지가 존재하는데, \n[Sub Account] - [Dashboard]에서 서브 계정으로 접속하기 위한 페이지 주소를 입력할 수 있습니다.\nhttps://www.ncloud.com/nsa/ 까지는 공통이고, 그 다음 페이지 주소를 직접 입력하고 저장하시면 됩니다.\n\n\n\n다음으로 [미사용 세션 만료 설정]에서는 로그인된 서브 계정이 아무 활동없이 미사용일 경우 지정한 시간 기준으로 자동 로그아웃이 되도록 설정할 수 있습니다.\n\n\n\n[비밀번호 만료 설정]은 비밀번호 만료를 활성화할 경우 지정된 만료일을 초과했을 때 비밀번호를 변경해야만 접속 할 수 있습니다.\n활성화 하지 않았을 경우에는 90일이 지난 후에 비밀번호 변경 안내 팝업만 나타납니다.\n\n\n\n접속 - 로그인\n위에서 설정한 접속 페이지 [ https://www.ncloud.com/nsa/******] 에 접속하면 아래와 같이 서브 계정 로그인 화면을 확인할 수 있습니다.\n바꿔말하면 서브 계정(Sub Account)은 반드시 위에서 설정한 접속 페이지로 접속해야 합니다.\n\n\n\nAccess Key 설정\n서브 계정에서 Access Key를 사용해야 할 경우 서브 계정 상세 화면 [Access Key]탭에서 [추가] 버튼을 클릭해 생성할 수 있습니다.\n\n\n\n계정 그룹 설정\n여러 개의 서브 계정을 묶어서 하나의 그룹으로 구성하면 해당 그룹의 서브 계정에 동일한 정책을 동시에 적용할 수 있습니다.\n\n\n\n사용자 정의 정책 생성\n서브 계정 정책에는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책] 외에도 사용자가 직접 설정하는 [사용자 정의 정책]도 사용할 수 있습니다. \n[Sub Account] - [Plicies]에서 [정책 생성] 버튼을 클릭합니다.\n\n\n\nVPC 환경에서 정책 생성\n정책 이름을 입력하고, VPC를 선택 후, 어떤 서비스 상품에 적용할 것인지 선택합니다.\n\n\n\n다음으로 Actions 항목에서는 읽기 권한인 View 또는 수정 권한인 Change를 선택하면 아래쪽에 리소스별로 상세한 권한 설정을 할 수 있는 화면이 나타납니다. \n모든 설정을 마치고, 아래쪽 [적용대상 추가] 버튼을 클릭하면 됩니다.\n\n\n\nClassic 환경에서 정책 생성\nClassic 환경에서는 리소스별 상세 권한은 설정할 수 없고, View 또는 Change를 선택한 후에 [적용대상 추가] 버튼을 클릭하면 모든 권한이 추가됩니다.\n\n\n아래와 같이 선택한 서비스 상품에 대해 모든 리전, 모든 리소스에 선택한 권한이 지정됩니다.\n\n\n\n참고 URL\n\n  Sub Account 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/management-management-4-1\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-08-20"
					}
					
				
			
		
			
				
					,
					
					"91-aws-aws-s3-lifecycle-management": {
						"id": "91-aws-aws-s3-lifecycle-management",
						"title": "AWS S3 수명 주기 (LifeCycle) 설정하기",
						"categories": "91.AWS",
						"url": " /91.aws/aws_s3_lifecycle_management/",
						"content": "개요\nAWS S3에서는 버킷내 특정 디렉토리 하위 파일들에 대해 지정된 날짜가 지난 후 만료(삭제)가 되도록 설정할 수 있습니다. \n수명 주기 관리(LifeCycle Management)라고 불리는 이 방법은 파일관리 뿐만 아니라 비용절감에도 도움이 됩니다.\n\n수명주기 설정\nAWS 콘솔에 접속 후 수명 주기를 적용할 S3 버킷으로 이동해 [관리] 메뉴 클릭합니다.\n\n\n\n[수명 주기 규칙 생성] 버튼을 클릭합니다.\n\n\n\n수명 주기 규칙 이름을 입력하고, 규칙 범위는 [하나 이상의 필터를 사용하여 이 규칙의 범위 제한]을 선택합니다.\n접두사에는 수명 주기를 적용할 디렉토리나 파일 등의 필터를 작성합니다. 예를 들어 images 디렉토리가 포함된 모든 파일에 적용하려면 images/ 라고 입력합니다. 이때 버킷명은 제외하고 입력해야 합니다.\n\n\n\n수명 주기 규칙 작업에서 [객체의 현재버전 만료],  [객체의 이전버전 영구 삭제] 두가지 항목을 선택하면, 몇일 후에 삭제할 것인지를 설정할 수 있는 [객체 생성 후 경과 일수], [객체가 이전 버전이 된 후 경과 일수] 항목이 나타납니다. \n여기에 원하는 날짜를 각각 입력하고, [규칙 생성] 버튼을 클릭합니다.\n\n\n\n주의사항\nAWS 수명 주기 관련해서 주의해야 할 사항이 몇가지 있습니다.\n\n수명 주기 규칙 작동 시점\n수명 주기 규칙이 생각한 것보다 늦게 작동하는 경우가 있습니다. 이는 Amazon S3가 객체의 전환 또는 만료(삭제) 날짜를 익일 자정(UTC)부터 계산하기 때문입니다.\n예를 들어 2020년 1월 1일 10:30(UTC)에 객체를 생성하고 3일 후 객체가 만료(삭제)되도록 수명 주기 규칙을 설정할 경우 객체의 만료(삭제) 날짜는 2020년 1월 5일 00:00(UTC)이 됩니다. \n따라서 수명 주기 규칙이 충족되었는지 확인하기 전에 충분한 시간이 경과했는지 확인해야 합니다.\n\n수명 주기 규칙 접두사 필터 설정\n수명 주기 규칙에서 접두사 필터에 디렉토리를 지정할 경우 접두사 필터의 끝에 / 문자를 지정해야 합니다. 접두사 필터의 처음에 / 문자가 있으면 수명 주기 규칙이 올바르게 평가되지 않습니다.\n즉, images 디렉토리가 포함된 모든 파일에 적용하려면 images/ 라고 입력해야 합니다.\n\n\n\n참고 URL\n\n  AWS S3 수명 주기 관리 가이드\n    \n      https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lifecycle-mgmt.html\n    \n  \n  수명 주기 규칙 작동 지연 관련 FAQ\n    \n      https://aws.amazon.com/ko/premiumsupport/knowledge-center/s3-lifecycle-rule-delay/\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-09-16"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mysql-root-password-set-update-guide": {
						"id": "5-database-ncp-database-mysql-root-password-set-update-guide",
						"title": "설치형 MySQL DB에서 root Password 설정, 변경하는 방법",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mysql_root_password_set_update_guide/",
						"content": "개요\n네이버 클라우드에서는 MySQL Password 정책에 따라 처음 MySQL DB를 설치할 때 root의 초기 패스워드가 설정되지 않습니다. \n그러므로 보안 침해 방지를 위해 설치 후에 root Password를 설정한 후에 DB를 사용하는 것이 안전합니다.\n여기서는 Classic환경에서 MySQL 5.6과 5.7 버전의 root Password를 설정, 변경하는 방법에 대해 정리해보겠습니다.\n\nMySQL 버전\n네이버 클라우드 Classic환경에서 지원하는 설치형 MySQL 버전은 5.6과 5.7 입니다.\n\n\n\n\n  네이버 클라우드는 Classic환경에서는 DB 서버 이미지를 제공하지만, VPC 환경에서는 제공하지 않습니다. \n그러므로 VPC 환경에서 DB서버를 사용하려면 OS에 사용자가 직접 DB를 설치해서 사용하는 방법과 Cloud DB를 사용하는 방법 중에서 선택해야 합니다.\n\n\nMySQL 5.6 설정\n우선 mysql 5.6 DB서버를 생성한 후 root 계정의 패스워드 상태를 확인해봅니다. 그 이후에 패스워드를 설정합니다.\n\n#mysql 접속\n~# mysql -u root\n\n#계정 정보 조회\nmysql&gt; select host, user, password from mysql.user;\n\n#패스워드 설정-변경\nmysql&gt; set password = password('패스워드');\n\n#변경된 패스워드 조회\nmysql&gt; select host, user, password from mysql.user;\n\n\n초기 패스워드가 설정되어있지 않기 때문에 -p 옵션을 사용하지 않고 바로 접속 해서 user 테이블에 있는 계정 정보를 확인해보면 password 값이 비어 있는 것을 확인할 수 있습니다.\n\n\n\n패스워드를 설정하고 다시 확인을 해보면 localhost의 root 계정에 패스워드가 설정된 것을 확인할 수 있습니다.\n\n\n  MySQL의 계정은 host-user 두개를 합쳐서 키로 사용하게 되어 있습니다. 같은 user라도 접속하는 host 값이 다르면 별도의 계정처럼 인식합니다.\n\n\n\n\n그런데 위에서 사용한 set password = password(‘패스워드’)는 localhost@root에 대해서만 패스워드를 설정-변경합니다.\n만약 외부에서 접속하기 위해 특정 IP를 추가했다거나 외부 접속을 모두 허용하기 위해 host에 %값을 설정했을 경우에는 패스워드가 설정-변경되지 않습니다. \n이때 사용하는 방법은 아래와 같습니다.\n\nmysql&gt; update mysql.user set password = password('패스워드') where user = 'root';\n\nmysql&gt; select host, user, password from mysql.user;\n\n\n쿼리를 실행한 후에 조회를 해보면 user값이 root인 모든 계정의 password 값이 동일하게 설정된 것을 확인할 수 있습니다.\n\n\n\nMySQL 5.7 설정\n마찬가지로 mysql 5.7 DB서버를 생성한 후 root 계정의 패스워드 상태를 확인해봅니다. 그 이후에 패스워드를 설정합니다.\nMySQL 5.7은 패스워드 칼럼이 password가 아니고 authentication_string로 변경되었습니다.\n\n#mysql 접속\n~# mysql -u root\n\n#계정 정보 조회\nmysql&gt; select host, user, authentication_string from mysql.user;\n\n#패스워드 설정-변경\nmysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '패스워드';\n\n#변경된 패스워드 조회\nmysql&gt; select host, user, authentication_string from mysql.user;\n\n\n초기 패스워드가 설정되어있지 않기 때문에 -p 옵션을 사용하지 않고 바로 접속 해서 user 테이블에 있는 계정 정보를 확인해보면 password 값이 비어 있는 것을 확인할 수 있습니다.\n\n\n\n이때 MySQL 5.6 이하 버전처럼 update 명령어로 authentication_string 칼럼 값을 변경하려고 해도 적용되지 않습니다.\n위에 적은 것처럼 ALTER 명령으로 변경해야 적용되니 주의해야 합니다.\n\n\n\nMySQL 패스워드 정책\nMySQL은 아래와 같이 기본 패스워드 정책이 설정되어 있습니다. 그러므로 패스워드 설정 시에는 아래 조건에 맞게 입력하셔야 합니다.\n\n\n  최소 길이 8자 이상\n  특수문자 1개 이상\n  숫자 1개 이상\n  대소문자 조합 1개 이상\n\n\nMySQL DB에 접속해서 아래와 같이 설정된 정책을 조회할 수 있습니다.\n\nmysql&gt; SHOW VARIABLES LIKE 'validate_password%';\n\n\n\n참고 URL\n\n  설치형 MySQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-1-1\n    \n  \n  MySQL 패스워드 정책 가이드\n    \n      https://dev.mysql.com/doc/refman/5.7/en/validate-password-options-variables.html\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-08-05"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-cloud-db-for-mysql-public-domain-guide": {
						"id": "5-database-ncp-database-cloud-db-for-mysql-public-domain-guide",
						"title": "Cloud DB for MySQL 생성후 Public 도메인으로 접속하기",
						"categories": "5.database",
						"url": " /5.database/ncp_database_cloud_db_for_mysql_public_domain_guide/",
						"content": "개요\n네이버 클라우드의 Cloud DB for MySQL 서비스는 MySQL 데이터베이스를 쉽고 간편하게 구축하고 관리할 수 있고 자동 Fail-Over, 자동백업, 네이버 서비스에서 검증된 최적화된 설정 등을 제공해주는 \n완전 관리형 클라우드 데이터베이스 서비스입니다.\n여기서는 VPC환경에서 Cloud DB for MySQL 서비스를 생성하고, Public 도메인으로 접속하는 과정을 정리해보겠습니다.\n\n\n  네이버 클라우드는 Classic환경에서는 DB 서버 이미지를 제공하지만, VPC 환경에서는 제공하지 않습니다. \n그러므로 VPC 환경에서 DB서버를 사용하려면 OS에 사용자가 직접 DB를 설치해서 사용하는 방법과 Cloud DB를 사용하는 방법 중에서 선택해야 합니다.\n\n\n특징\n\n  기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6,000GB까지 자동으로 용량이 증가합니다.\n  하나의 마스터 DB마다 최대 10대의 슬레이브 DB를 생성할 수 있습니다.\n  Load Balancer 상품을 통해 슬레이브 DB 서버들을 읽기 전용 복제본으로 사용함으로써 데이터베이스의 읽기 부하를 분산 시킬 수 있습니다.\n  매일 1회 고객이 원하는 시간에 DB를 자동으로 백업하며, 백업한 데이터를 최대 30일까지 보관할 수 있습니다.\n  VPC 환경에서는 멀티 존으로 구성해 높은 안정성을 보장받을 수 있습니다.\n  Cloud DB for MySQL 서비스는 완전 관리형 상품으로 사용자는 DB서버의 운영체제에 접근할 수 없습니다.\n\n\nDB 접속 방법 3가지\n\n  Private 도메인을 이용해 접속하는 방법\n  SSL VPN을 이용해 접속하는 방법\n  Public 도메인을 이용해 접속하는 방법\n\n\n아래에서는 VPC환경 기준으로 네이버 클라우드 외부 환경에서  Cloud DB for MySQL로 접속할 때 필요한 Public 도메인을 이용해 접속하는 방법을 정리하도록 하겠습니다.\n\nVPC-Subnet  생성\n\nVPC 생성\nVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\n\n\n\n\n\nSubnet 생성\nSubnet은 Public Subnet을 생성합니다.\n\n\n\n\n\nDB 서버 생성\n[Database] - [Cloud DB for MySQL]에서 [DB Server 생성] 버튼을 클릭합니다.\n\n\n\nDB 서버 엔진 버전\nDB 엔진 버전은 MySQL 최신 버전 중 네이버에서 안정성이 검증된 버전인 5.7버전과 8.0버전을 제공합니다. (기본값 5.7.32)\n\n\n\nDB 서버 이름과 DB 서비스 이름\n\n  DB Server 이름은 고객이 DB 서버를 구분하기 위한 명칭으로, 사용자가 입력한 이름 뒤에 001, 002와 같이 숫자를 붙여 서버를 구분하게 됩니다.\n  예를 들어 DB 서버 이름을 mydb라고 입력하면 생성되는 DB 서버 이름은 mydb-001, mydb-002와 같습니다.\n  DB 서비스 이름은 역할별 DB 서버를 구분하기 위한 이름입니다.\n  일반적으로 하나의 액티브 마스터 DB, 스탠바이 마스터 DB, 다수의 슬레이브 DB로 구성되는 DB 서버군을 말하며, 동일한 데이터를 갖고 있는 DB 서버들을 하나의 DB 서비스라 말합니다.\n  예를 들어 “쇼핑 메인 DB”, “게임 유저 DB”와 같은 식으로 DB 서비스의 역할을 구분하기 위해 사용합니다.\n\n\n\n\n\n  Cloud DB를 위한 ACG는 자동 생성됩니다(예: cloud-mysql-*)\n\n\nDB 서버 설정\nDB 이름과 계정. 비번, 접속 포트 등을 설정합니다.\nHOST(IP) 설정에는 DB에 접근을 허용할 IP대역을 입력합니다. 여기서는 Public 도메인을 이용하게 되므로 우선 모든 대역을 허용하기 위해 [%]를 입력합니다.\n대신 접속 IP 제한의 경우 ACG에서 설정하게 됩니다.\n\n\n  DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n\n\nACG 설정\nCloud DB for MySQL을 생성할 때 자동 생성된 ACG [cloud-mysql-*]을 선택하고 ACG 설정을 클릭합니다.\n\n\n\nInbound 설정에 접속을 허용할 IP를 입력합니다. 여기서는 테스트를 위해 [myIp] 버튼을 클릭해 현재 로컬PC IP를 입력합니다.\n\n\n\nPublic 도메인 할당\nDB 서버를 생성한 직후에는 아래 스샷과 같이 Public 도메인이 미할당 상태입니다.\n\n\n\n[DB 관리] - [Public 도메인 관리] 메뉴를 클릭해 Public 도메인을 신청합니다.\n\n\n\nPublic 도메인을 신청하면 네이버 클라우드 플랫폼 외부에서 DB 서버로 접근할 수 있습니다. \n이때 외부에서 통신하는 데이터는 네트워크 사용량으로 과금이 됩니다.\n\n\n\nPublic 도메인 신청을 하고  나면 할당된 Public 도메인을 확인할 수 있습니다.\n\n\n\nDB User 관리\n네이버 클라우드 외부에서 DB에 접속하려고 할때는 보안을 위해 별도의 계정을 추가해서 사용하는 것을 추천합니다.\n계정을 추가하기 위해 [DB 관리] - [DB User 관리] 메뉴를 클릭합니다.\n\n\n\nUSER_ID, HOST, DB 권한, 암호를 입력하고 DB User 추가 버튼을 클릭합니다.\n\n  사용자가 변경한 DB 계정은 DB 서비스 전체에 적용됩니다.\n  USER_ID + HOST(IP) 단위로 계정 추가 및 권한 관리를 합니다.\n  DB 권한에서 DDL 권한은 CRUD 권한을 포함합니다.\n  최대 1,000개까지 계정을 추가 및 조회 할 수 있습니다.\n\n\n\n\n외부접속 테스트\n네이버 클라우드 외부 접속을 테스트 하기 위해 로컬PC에 MySQL Workbench를 설치해서 접속해보겠습니다. \nMySQL Workbench는 아래 경로에서 다운 받을 수 있습니다.\n\nhttps://www.mysql.com/products/workbench/\n\n앞에서 확인한 Public 도메인을 입력하고 Port와 Username도 함께 입력한 후에 [Test Connection]을 클릭해 문제없이 연결되는지 확인합니다.\n\n\n\nDB 서버 접속 후에 Database를 확인해보면 처음 Cloud DB for MySQL을 생성할 때 설정한 test Database가 존재하는 것을 확인할 수 있습니다.\n\n\n\n기타\n\nDB 서버 상세보기\nDB 서버 상세보기 메뉴에서는 [Process list], [Variables], [Status], [Database 관리], [DB Config 관리], [DB User 관리], [Backup 설정 관리], [DB Server Logs] 등을 확인할 수 있습니다.\n\n\n\n\n\n참고 URL\n\n  Cloud DB for MySQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-6\n    \n  \n  Cloud DB 서버 외부 접근 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-10\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-12-13"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-cloud-db-for-mysql-guide": {
						"id": "5-database-ncp-database-cloud-db-for-mysql-guide",
						"title": "VPC환경에서 Cloud DB for MySQL 생성하기",
						"categories": "5.database",
						"url": " /5.database/ncp_database_cloud_db_for_mysql_guide/",
						"content": "개요\n네이버 클라우드의 Cloud DB for MySQL 서비스는 MySQL 데이터베이스를 쉽고 간편하게 구축하고 관리할 수 있고 자동 Fail-Over, 자동백업, 네이버 서비스에서 검증된 최적화된 설정 등을 제공해주는 \n완전 관리형 클라우드 데이터베이스 서비스입니다.\n여기서는 VPC환경에서 Cloud DB for MySQL 서비스를 생성하는 과정을 정리해보겠습니다.\n\n\n  네이버 클라우드는 Classic환경에서는 DB 서버 이미지를 제공하지만, VPC 환경에서는 제공하지 않습니다. \n그러므로 VPC 환경에서 DB서버를 사용하려면 OS에 사용자가 직접 DB를 설치해서 사용하는 방법과 Cloud DB를 사용하는 방법 중에서 선택해야 합니다.\n\n\n특징\n\n  기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6,000GB까지 자동으로 용량이 증가합니다.\n  하나의 마스터 DB마다 최대 10대의 슬레이브 DB를 생성할 수 있습니다.\n  Load Balancer 상품을 통해 슬레이브 DB 서버들을 읽기 전용 복제본으로 사용함으로써 데이터베이스의 읽기 부하를 분산 시킬 수 있습니다.\n  매일 1회 고객이 원하는 시간에 DB를 자동으로 백업하며, 백업한 데이터를 최대 30일까지 보관할 수 있습니다.\n  VPC 환경에서는 멀티 존으로 구성해 높은 안정성을 보장받을 수 있습니다.\n  Cloud DB for MySQL 서비스는 완전 관리형 상품으로 사용자는 DB서버의 운영체제에 접근할 수 없습니다.\n\n\nDB 접속 방법 3가지\n\n  Private 도메인을 이용해 접속하는 방법\n  SSL VPN을 이용해 접속하는 방법\n  Public 도메인을 이용해 접속하는 방법\n\n\n아래에서는 VPC환경에서 Private 도메인을 이용해 접속하는 방법을 설명하도록 하겠습니다.\n만약 네이버 클라우드 외부 환경에서  Cloud DB for MySQL로 접속하려면 Public 도메인을 사용해야 합니다.\n\nVPC-Subnet  생성\n\nVPC 생성\nVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\n\n\n\n\n\nSubnet 생성\nSubnet은 Cloud DB for MySQL을 위한 Private Subnet과 DB 접속 테스트를 위한 Server용 Public Subnet을 각각 생성합니다.\n\n\n\nCloud DB for MySQL을 위한 Private Subnet\n\n\n테스트용 Server를 위한 Public Subnet\n\n\n테스트 Server 생성\nDB 서버 접속을 테스트 하기 위한 Server를 생성합니다.\n\n\n\nDB 서버 생성\n[Database] - [Cloud DB for MySQL]에서 [DB Server 생성] 버튼을 클릭합니다.\n\n\n\nDB 서버 엔진 버전\nDB 엔진 버전은 MySQL 최신 버전 중 네이버에서 안정성이 검증된 버전인 5.7버전과 8.0버전을 제공합니다. (기본값 5.7.32)\n\n\n\nDB 서버 이름과 DB 서비스 이름\n\n  DB Server 이름은 고객이 DB 서버를 구분하기 위한 명칭으로, 사용자가 입력한 이름 뒤에 001, 002와 같이 숫자를 붙여 서버를 구분하게 됩니다.\n  예를 들어 DB 서버 이름을 mydb라고 입력하면 생성되는 DB 서버 이름은 mydb-001, mydb-002와 같습니다.\n  DB 서비스 이름은 역할별 DB 서버를 구분하기 위한 이름입니다.\n  일반적으로 하나의 액티브 마스터 DB, 스탠바이 마스터 DB, 다수의 슬레이브 DB로 구성되는 DB 서버군을 말하며, 동일한 데이터를 갖고 있는 DB 서버들을 하나의 DB 서비스라 말합니다.\n  예를 들어 “쇼핑 메인 DB”, “게임 유저 DB”와 같은 식으로 DB 서비스의 역할을 구분하기 위해 사용합니다.\n\n\n\n\n\n  Cloud DB를 위한 ACG는 자동 생성됩니다(예: cloud-mysql-*)\n\n\nDB 서버 설정\nDB 이름과 계정. 비번, 접속 포트 등을 설정합니다.\nHOST(IP) 설정에는 DB에 접근을 허용할 IP대역을 입력합니다. 여기서는 테스트용 서버의 Subnet 대역을 모두 허용하기 위해 [192.168.2.%]를 입력합니다.\n만약 특정 서버 1대만 허용하려고 할 경우에는 앞에서 생성한 테스트 서버 IP처럼 [192.168.2.6]을 입력합니다.\n\n\n  DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n\n\nACG 설정\nCloud DB for MySQL을 생성할 때 자동 생성된 ACG [cloud-mysql-*]을 선택하고 ACG 설정을 클릭합니다.\n\n\n\nInbound 설정에 테스트용 Server의 Subnet 대역인 192.168.2.0/24를 접근소스에 입력합니다.\n또는 특정 서버 1대만 허용하려고 할 경우에는 앞에서 생성한 테스트 서버 IP처럼 [192.168.2.6]을 입력합니다.\n\n\n\nMySQL Client 설치\nDB 접속 테스트를 위해 생성한 서버에서 MySQL Client를 설치합니다.\n\n# mariadb\n~# yum install -y mysql mysql-server\n\n# mysql 5.7\n~# yum install -y https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm\n~# yum install -y --disablerepo=\"mysql80-community\" --enablerepo=\"mysql57-community\" mysql-community-server\n~# mysqld --initialize-insecure --user=mysql\n~# systemctl start mysqld\n\n\n\n  CentOS 7부터는 yum으로 설치하는 MySQL의 기본 데이터베이스가 MariaDB로 변경되었습니다\n\n\n\n\nDB 서버 접속\nCloud DB for MySQL에 접속하기 위한 주소인 [Private 도메인]을 확인 합니다.\n\n\n\n테스트용 Server에서 Cloud DB for MySQL로 접속하는 방법은 다음과 같습니다.\n\n~# mysql -h [Private 도메인명] -u [user_id] -p\n\n\nDB에 접속해보면 처음 Cloud DB for MySQL 생성할 때 입력한 테이터베이스 [test]를 확인할 수 있습니다.\n\n\n\nDB 서버 상세보기\nDB 서버 상세보기 메뉴에서는 [Process list], [Variables], [Status], [Database 관리], [DB Config 관리], [DB User 관리], [Backup 설정 관리], [DB Server Logs] 등을 확인할 수 있습니다.\n\n\n\n\n\nDB User 관리\nDB 서버를 이용하다보면 여러 계정이 필요하게 됩니다. 이때 계정을 추가하기 위해 [DB 서버 상세보기] - [DB User 관리] 메뉴를 클릭합니다.\n\nUSER_ID, HOST, DB 권한, 암호를 입력하고 DB User 추가 버튼을 클릭합니다.\n\n  사용자가 변경한 DB 계정은 DB 서비스 전체에 적용됩니다.\n  USER_ID + HOST(IP) 단위로 계정 추가 및 권한 관리를 합니다.\n  DB 권한에서 DDL 권한은 CRUD 권한을 포함합니다.\n  최대 1,000개까지 계정을 추가 및 조회 할 수 있습니다.\n\n\n\n\n참고 URL\n\n  Cloud DB for MySQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-6\n    \n  \n  Cloud DB 서버 외부 접근 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-10\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-12-13"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-nas-vpc-guide": {
						"id": "4-storage-ncp-storage-nas-vpc-guide",
						"title": "NAS 볼륨을 생성하고 Linux 서버에 마운트하기 가이드",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_nas_vpc_guide/",
						"content": "개요\nNAS (Network Attached Storage)는 다수의 서버, 사용자가 함께 사용하는 네트워크 저장공간으로, \n서버 간 데이터 공유, 대용량 스토리지, 유연한 용량 확대/축소, 스냅샷 백업 등이 필요한 경우에 주로 사용하며, \n네이버 클라우드 NAS 서비스의 주요 기능을 활용해 안전하고 편리하게 데이터를 관리할 수 있습니다.\n이번 가이드에서는 NAS 볼륨을 생성하고, Linux 즉, CentOS와 Ubuntu 서버에 마운트하는 방법을 정리해보겠습니다.\n\n특징\n\n  용량: 500GB ~ 10,000GB까지 가능하며, 확장은 100GB단위로 가능\n  접근제어 설정 가능\n  스냅샷 설정: 자동생성의 경우  최대 7개까지 보관 가능\n  볼륨 암호화: 볼륨 단위로 AES-256 알고리즘 기반의 암호화 키를 사용하여 FIPS-140-2 레벨 1 수준의 암호화를 제공\n  모니터링 및 이벤트 설정 가능\n\n\nVPC-Subnet  생성\n\nVPC 생성\nVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\n\n\n\n\n\nSubnet 생성\nSubnet 설정은 [Public]과 [일반]을 선택합니다.\n\n\n\n\n\n서버 생성\nNAS 볼륨을 마운트할 서버 2개를 CentOS 7.8과 Ubuntu 18.04로 생성합니다.\n\n\n\nNAS 생성\n[NAS] - [Volume]에서 [NAS 볼륨 생성] 버튼을 클릭합니다.\n\n\n\nNAS 볼륨 이름과 용량을 입력하고, 리눅스용 프로토콜인 NFS를 선택합니다.  CIFS는 윈도우용 프로토콜입니다.\n용량은 500GB ~ 10,000GB까지 가능하며, 100GB단위로 추가할 수 있습니다.\n\n\n\nNFS 접근 제어 설정\nNFS 접근 제어 설정에서는 NAS 볼륨을 마운트할 장비를 선택해서 ACL(네트워그 접근제어) 설정을 하게 됩니다.\n\n\n\nNAS 볼륨을 마운트할 장비를 선택하고, [ &gt; ] 버튼을 클릭해 오른쪽으로 이동시킵니다.\n\n\n\n\n마지막으로 설정 내용을 확인하고 [볼륨 생성] 버튼을 클릭합니다.\n\n\n\nCentOS 설정\n\nNFS 관련 패키지 설치\nNAS 볼륨을 서버에 마운트하기 위해 우선 서버에 NFS 프로토콜 관련 패키지를 설치합니다.\n\n~# yum install nfs-utils\n\n\n\n\nNAS 볼륨 마운트하기\nNAS 볼륨을 마운트할 디렉토리를 생성하고 {NAS 볼륨 마운트 정보}를 이용해 마운트한 후에 상태를 확인합니다.\n네이버 클라우드에서는 안정성이 높은 NFS v3(-o vers=3)로 마운트하여 사용할 것을 권고하고 있습니다.\n\n~# mkdir /nas\n~# mount -t nfs -o vers=3 {NAS 볼륨 마운트 정보} /nas\n~# df -Th\n\n\n\n\n\nfstab 설정\n부팅 후에도 마운트가 될 수 있도록 /etc/fstab 파일에 추가합니다.\n\n\n\nUbuntu 설정\n\nNFS 관련 패키지 설치\n우분투에서도 우선 NFS 관련 패키지를 설치합니다.\n\n~# apt-get install nfs-common -y\n\n\n\nNAS 마운트하기\nNAS 볼륨을 마운트할 디렉토리를 생성하고 {NAS 볼륨 마운트 정보}를 이용해 마운트한 후에 상태를 확인합니다.\n네이버 클라우드에서는 안정성이 높은 NFS v3(-o vers=3)로 마운트하여 사용할 것을 권고하고 있습니다.\n\n~# mkdir /nas\n~# mount -t nfs -o vers=3 {NAS 볼륨 마운트 정보} /nas\n~# df -Th\n\n\n\nfstab 설정\n부팅 후에도 마운트가 될 수 있도록 /etc/fstab 파일에 추가합니다.\n\n\n\n이벤트 설정\n이벤트 설정에서는 NAS 볼륨 사용량 임계치를 설정하고 이벤트 발생 시 SMS나 Email로 통보를 받습니다.\n볼륨 설정에서 이벤트 설정을 클릭합니다.\n\n\n\n이벤트 통보 방법과 휴대폰 또는 이메일 등을 입력하고 설정을 완료합니다.\n\n\n\n참고 URL\n\n  NAS 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/storage-storage-4-1\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-07-27"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-kubernetes-service-start-guide": {
						"id": "1-compute-ncp-server-kubernetes-service-start-guide",
						"title": "Kubernetes Service 클러스터 생성 및 제어 가이드",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_kubernetes_service_start_guide/",
						"content": "개요\n네이버 클라우드 VPC 환경에서 Kubernetes(쿠버네티스) 서비스를 생성하고 제어하는 방법에 대해 소개합니다.\n\n쿠버네티스란?\n쿠버네티스(Kubernetes)는 배포, 스케일링, 그리고 컨테이너화된 애플리케이션의 관리를 자동화 해주는 오픈 소스 컨테이너 오케스트레이션 엔진으로 \n구글에서 처음 개발하기 시작했으나 현재는 구글이 오픈소스 프로젝트로 공개한 상태입니다.\n\n특징\n쿠버네티스는 다음과 같은 특징이 있으며, 자세한 내용은 쿠버네티스 공식 페이지를 참고하시기 바랍니다.\n\nhttps://kubernetes.io/ko/docs/home/\n\n\n  서비스 디스커버리와 로드 밸런싱\n  스토리지 오케스트레이션\n  자동화된 롤아웃과 롤백\n  자동화된 빈 패킹(bin packing)\n  자동화된 복구(self-healing)\n  시크릿과 구성 관리\n\n\n사전 준비\n먼저 쿠버네티스 클러스터에 사용할 전용 VPC와 Private Subnet, Load Balancer용 Subnet이 필요합니다.\n\n\n\n\n  \n    Private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /17~/26 범위의 Private Subnet, 로드밸런서 전용 Subnet이 필요합니다.\n    Docker Bridge 대역의 충돌을 방지하기 위해 172.17.0.0/16 범위 내의 Private Subnet, 로드밸런서 전용Subnet은 선택할 수 없습니다.\n  \n\n\n클러스터 생성\n\nVPC와 Subnet이 준비되었다면, 다음으로 [Kubernetes Sevice] - [Cluster]에서 생성하기를 클릭합니다.\n\n\n\n생성하실 클러스터의 정보를 설정해줍니다.\n(ACG는 자동으로 생성 됩니다.)\n\n\n\n\n  현재 지원되고 있는 Kubenetes 버전은 [1.17.16], [1.18.17] 입니다.\n\n\n클러스터에 생성되는 노드풀과 서버의 스펙 및 수를 지정해줍니다.\n\n\n\n\n  현재 지원되고 있는 OS는 [ubuntu16.04], [ubuntu18.04] 입니다.\n\n\n워커노드의 로그인키를 설정 합니다.\n\n\n\n설정 정보를 최종적으로 확인한 후 생성버튼을 클릭하여 클러스터를 생성합니다.\n\n\n\nkubectl 설치\n\n사용자 로컬PC에서 클러스터를 제어하기 위해 kubectl을 설치합니다.\nkubctl의 최신 릴리즈 버전은 아래  링크에서 다운받을 수 있습니다.\n\n\n  kubctl v1.21.0 :  https://dl.k8s.io/release/v1.21.0/bin/windows/amd64/kubectl.exe\n\n\n또는 windows에서 cmd 창에서 curl 을 이용하해 다운로드 받을 수도 있습니다.\n&gt; curl -LO https://dl.k8s.io/release/v1.21.0/bin/windows/amd64/kubectl.exe\n\n\nkubectl의 버전 확인이 필요한 경우 다음 명령어를 사용하시면 됩니다.\n&gt; kubectl version --client\n\n\n\n다른 OS 환경에서 설치하는 방법은 아래 링크에서 확인할 수 있습니다.\n\n\n  Linux kubectl 설치 : https://kubernetes.io/ko/docs/tasks/tools/install-kubectl-linux/\n  macOS kubectl 설치 : https://kubernetes.io/ko/docs/tasks/tools/install-kubectl-macos/\n\n\n접속-제어\n\n클러스터를 제어하기 위해서는 네이버 클라우드 쿠버네티스 서비스에서 제공해주는 접속을 위한 인증정보가 있는 설정파일이 필요합니다. \n[설정파일] - [다운로드] 또는 [가이드 보기] - [설정파일 다운로드] 버튼을 클릭해 설정 파일을 다운로드 받습니다.\n\n\n\nkubectl을 실행해 Kubernetes에 접속하고 제어하는 방법은 [가이드 보기] 버튼 클릭하면 아래와 같이 자세히 확인할 수 있습니다.\n\n\n\n다운로드한 설정 파일경로를 %KUBE_CONFIG% 환경변수에 지정합니다.\n\n&gt; SET KUBE_CONFIG=%USERPROFILE%\\Downloads\\kubeconfig-7349***-8***-4***-a***-99e***.yaml\n\n\n이제 –kubeconfig 옵션을 사용하여 쿠버네티스의 클러스터를 제어할수 있습니다.\n\n&gt; kubectl --kubeconfig %KUBE_CONFIG% get nodes\nNAME                 STATUS   ROLES   AGE    VERSION\nnks-pool-1865-w2zy   Ready    node    4d5h   v1.16.6\nnks-pool-1865-w2zz   Ready    node    4d5h   v1.16.6\n\n\n참고 URL\n\n  쿠버네티스 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/vnks-nks-1-1\n    \n  \n  클러스터 이용 가이드\n    \n      https://guide.ncloud-docs.com/docs/vnks-nks-1-2\n    \n  \n  kubectl 설치 가이드\n    \n      https://kubernetes.io/ko/docs/tasks/tools/\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-07-13"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-natgw-routetb": {
						"id": "2-networking-ncp-networking-natgw-routetb",
						"title": "VPC 환경에서 NAT Gateway 설정하기",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_natgw_routetb/",
						"content": "개요\nNAT Gateway는 비공인 IP를 가진 다수의 서버들이 대표 공인 IP를 이용해 외부와 통신을 할 수 있도록 도와주는 네트워킹 서비스입니다.\n그리고, 일반적으로 서버에 직접 공인 IP를 부여하는 것과 달리 외부에서 서버로의 직접 접근은 허용하지 않기 때문에 높은 수준의 보안을 유지할 수 있는 것이 특징입니다.\n여기서는 VPC 환경에서 NAT Gateway를 어떻게 구성하고, NAT Gateway를 적용하기 전과 후의 외부와 통신 상태에 대해 확인해보도록 하겠습니다.\n\n생성개수 제한\n우선 VPC는 리전별로 계정당 3개씩 생성 가능하고, NAT Gateway는 각 VPC별로 Zone당 1개씩 생성 가능합니다.\n현재 한국 리전에는 KR-1, KR-2 이렇게 2개의 Zone이 있으므로 한국 리전 기준으로 VPC당 최대 2개, 계정당 최대 6개의 NAT Gateway를 생성할 수 있습니다.\n\nVPC 생성\n먼저 VPC를 생성합니다. IP주소 범위는 10.0.0.0/16으로 정하겠습니다.\n\n\n\nSubnet 생성\nNAT Gateway 동작 테스트를 위해 Public, Private 이렇게 2가지 Subnet을 생성하겠습니다.\n\nPublic Subnet 생성\nPublic Subnet의 IP 범위는 10.0.0.0/24로 설정하겠습니다.\n\n\n\nPrivate Subnet 생성\nPrivate Subnet의 IP 범위는 10.0.0.1/24로 설정하겠습니다.\n\n\n\nACG 설정\n테스트를 위한 ACG (Access Control Group)를 생성하고 설정합니다.\n\n\n\nInbound 설정\nInbound 규칙에는 Public, Private Subnet과 SSH 접속을 위한 로컬PC IP를 허용하고, Ping 테스트를 위한 ICMP도 허용합니다.\n\n\n\nOutbound 설정\nOutbound 규칙은 TCP, UDP, ICMP 모두 전체 허용으로 추가합니다.\n\n\n\n서버 생성\n테스트를 위해 Public, Private 각각의 Subnet에 1대씩 서버를 설정하고 Public 서버에는 공인 IP도 할당합니다.\n\n\n\nPublic -&gt; Private 서버 접속 확인\nPublic Subnet에 있는 서버에서 Private Subnet에 있는 서버로 통신이 가능한 것을 확인할 수 있습니다.\n다음 단계에서 Private 서버로 SSH로 접속하기 위한 사전 확인 단계입니다.\n\n\n\nPrivate 서버 외부 접속 여부 확인\nPublic 서버에서 Private 서버로 SSH로 접속한 후에 Private 서버에서 외부로 통신이 되는 것을 확인해보면 불가능한 것을 확인할 수 있습니다.\n이후 단계에서 NAT Gateway를 설정하고 Private 서버에서 외부와 통신이 가능한지 확인해보겠습니다.\n\n\n\nRoute Table 설정 확인\nNAT Gateway를 위한 Route Table 설정을 추가하기 전에 현재 상태의 Route Table 설정을 확인해보겠습니다.\n\nPublic Subnet의 Route Table 설정 확인\n위에서 Public Subnet의 서버와 Private Subnet의 서버가 통신이 가능했던 것은 VPC와 Subnet이 생성될때 Route Table이 생성되면서 VPC 내부 통신을 위한 규칙 (10.0.0.0/16 LOCAL)이 기본으로 설정되기 때문입니다.\n그리고 Public의 경우 외부 통신을 위한 INTERNET GATEWAY가 추가되어 있는 것을 확인할 수 있습니다.\n\n\n\nPrivate Subnet의 Route Table 설정 확인\n반면에 Private의 경우는 VPC 내부 통신을 위한 LOCAL만 설정된 것을 확인 할 수 있습니다.\n\n\n\nRoute Table 설정 화면에 들어가도 Target Type에 LOCAL만 선택할 수 있는 것을 확인할 수 있습니다.\n\n\nNAT Gateway 생성\nNAT Gateway 생성 버튼을 클릭합니다.\n\n\n\n이름을 입력하고 VPC와 Zone을 선택하고 NAT Gateway를 생성합니다.\n\n\n\nRoute Table 설정\n앞에서 LOCAL 항목만 존재했던 Private Subnet의 Route Table 설정 화면에 가보면 Target Type에 NATGW가 추가된 것을 확인할 수 있습니다.\n\n\n\n목적지(Destination)에 0.0.0.0/0을 입력하고, Target Type을 NATGW를 선택하고 생성 버튼을 클릭합니다.\n\n\n\n외부 접속 테스트\n마지막으로 다시 한번 Private 서버에서 외부 통신이 가능한지 ping 테스트를 해보면, 아래 화면과 같이 정상적으로 통신이 되는 것을 확인할 수 있습니다.\n\n\n\n고려사항\nNAT Gateway는 사용하지 않고 생성만 해두어도 요금이 부과됩니다. (데이터 처리요금 별도)\n생성 후 보유 시간에 따라 요금이 부과되는데 1개당 56원/시간 입니다. 그러므로 1달간 보유하고만 있다고 가정할 때 비용을 계산해보면\n24시간 * 30일 * 56원 = 40,320원 그러므로 사용하지 않는 NAT Gatway는 반드시 삭제하기를 추천드립니다.\n\n참고 URL\n\n  NAT Gateway 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailenatgw\n    \n  \n  NAT Gateway 특징과 비교\n    \n      https://m.blog.naver.com/n_cloudplatform/221173116642\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-07-09"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-storage-lvm-create": {
						"id": "1-compute-ncp-server-storage-lvm-create",
						"title": "리눅스서버 스토리지(디스크) LVM 구성하기",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_storage_lvm_create/",
						"content": "개요\n네이버 클라우드 서버는 하나의 서버당 로컬 디스크 즉, 블록 스토리지(Block Storage)를 OS가 설치되는 기본 스토리지 1개 이외에 15개를 추가할 수 있으며, 각 스토리지 용량은 10GB ~2,000GB 까지 가능합니다.\n그리고, 2,000GB 이상을 사용해야 할 경우는 NAS 장비를 사용하거나 Object Storage를 활용하는 경우가 많지만, 상황에 따라서는 2,000GB를 초과하는 용량의 블록 스토리지를 사용해야 하는 경우도 있습니다.\n이럴때 사용하는 방법이 LVM (Logical Volume Manager)를 사용하여 여러 개의 스토리지를 합쳐서 대용량으로 사용하거나 합쳐진 대용량을 다시 필요한 용량으로 나누어서 사용하는 방법입니다.\n그래서 이번에는 리눅스 환경에서 LVM으로 대용량 스토리지를 생성하는 방법을 정리해보겠습니다.\n\n스토리지 생성\n2000GB 이상의 용량을 필요로 할 때에 대한 내용이지만, 테스트를 위해 10GB 스토리지 2개를 생성하겠습니다.\n\n\n\nlvm-test-1, lvm-test-2 이름으로 생성된 스토리지 2개를 Ubuntu OS가 설치된 lvm-test-svr 서버에 연결했습니다.\n\n\n\n파티션 설정\n생성된 스토리지 2개에 각각 파티션을 설정합니다.\n파티션 설정에는 parted 명령어를 사용합니다.\n\n~# parted /dev/xvdb\n\n# (parted)\nmklabel gpt\nmkpart primary 0 100%\ni\nset 1 lvm on   # 1번 파티션에 lvm 사용 가능하게 설정\np\nquit\n\n\n\n\n~# parted /dev/xvdc\n\n# (parted)\nmklabel gpt\nmkpart primary 0 100%\ni\nset 1 lvm on   # 1번 파티션에 lvm 사용 가능하게 설정\np\nquit\n\n\n\n\n설정된 파티션들을 확인합니다.\n~# fdisk -l\n\n\n\n\nPhysical Volume 생성\n각 스토리지 장치에 Physical Volume을 생성합니다.\n\n~# pvcreate /dev/xvdb1\n\n~# pvcreate /dev/xvdc1\n\n\n\n\nPhysical Volume이 제대로 생성되었는지 확인합니다.\n~# pvdisplay\n\n\n\n\nVolume Group 생성\n준비된 두개의 Volume으로 하나의 Volume Group을 생성합니다.\n\n~# vgcreate VG01 /dev/xvdb1 /dev/xvdc1\n\n\n\n\n생성된 Volume Group을 확인합니다.\n~# vgdisplay\n\n\n\n\nLogical Volume 생성\n생성된 Volume Group 전체 크기를 사용하는 Logical Volume을 생성합니다.\n~# lvcreate --extents 100%FREE -n LV01 VG01\n\n\n\n\n생성된 Logical Volume을 확인합니다.\n~# lvdisplay\n\n\n\n\n포맷\n다음으로 포맷을 해야하는데, OS별로 명령어가 다르므로 확인 후에 실행해야 합니다.\n여기서는 Ubuntu 기준으로 mkfs.ext4 명령어를 사용했습니다.\n\n~# mkfs.ext4 /dev/VG01/LV01\n\n- CentOS 5.x: mkfs.ext3 /dev/VG01/LV01\n- CentOS 6.x: mkfs.ext4 /dev/VG01/LV01\n- CentOS 7.x: mkfs.xfs /dev/VG01/LV01\n- Ubuntu : mkfs.ext4 /dev/VG01/LV01\n\n\n\n\n마운트\n마운트를 하기 위해 우선 생성된 디스크 장치명을 확인합니다.\n~# fdisk -l\n\n\n\n\n다음으로 디스크를 마운트할 포인트 즉, 디렉토리를 원하는 이름으로 생성하고 마운트를 합니다.\n아래에 있는 마운트 경로 (/mnt/data)는 예시입니다. 원하는 경로를 직접 설정하시면 됩니다.\n\n~# mkdir /mnt/data\n~# mount /dev/mapper/VG01-LV01 /mnt/data\n\n\n\n\nfstab 설정\n새로 생성된 디스크를 부팅 후에도 인식할 수 있게 blkid 명령으로 UUID를 확인하고 fstab에 등록합니다.\n\n~# blkid |grep /dev/mapper/VG01-LV01\n\n\n\n~# vi /etc/fstab\n\n\n\nfstab 설정 상세정보\n\n/etc/fstab은 부팅 단계에서 마운트되어야 할 볼륨 정보들이 저장되는 곳입니다.\n(OS 이미지에 따라 파일 시스템이 다르기 때문에 주의해야 합니다.)\n\n파일의 각 항목이 의미하는 바는 아래와 같으며 각 항목은 Tab 또는 Space Bar로 구분합니다.\n\n(장치명) (마운트 포인트) (파일시스템 종류) (옵션) (dump 설정) (fsck 설정)\n\n\n  \n    장치명: 장치명은 장치의 UUID를 사용하거나 /dev/xvdb1와 같은 장치이름을 사용합니다.\n  \n  \n    마운트 포인트: 볼륨을 마운트하고자 하는 위치입니다. 예시에서는 /mnt/data 디렉토리에 마운트했습니다.\n  \n  \n    파일시스템 종류: OS별로 기본 파일시스템이 다르므로 알맞게 입력합니다.\n\n    \n      CentOS 5.x : ext3\n      CentOS 6.x : ext4\n      CentOS 7.x : xfs\n      Ubuntu Server / Desktop : ext4\n    \n  \n  \n    옵션: 예시에서는 default 옵션을 사용하였으며, 해당 옵션에는 rw, nouser, auto, exec, suid 속성이 포함됩니다.\n각 속성의 내용은 다음과 같습니다. (필요한 옵션만 사용할 시, 각 옵션을 쉼표(,)로 구분하여 작성해주시면 됩니다.)\n\n    \n      auto : 부팅 시 자동 마운트\n      rw : 읽기, 쓰기 모두 가능하도록 마운트\n      nouser : root 계정만 마운트 가능\n      exec : 파일 실행을 허용\n      suid : SetUID와 SetGID를 허용\n    \n  \n  \n    dump 설정: dump 명령으로 백업을 할 것인지에 대한 설정\n\n    \n      0: dump되지 않는 파일 시스템\n      1: dump 가능한 파일 시스템\n    \n  \n  \n    fsck 설정: 부팅시에 fsck 명령으로 파일시스템에 대한 무결성 검사를 할 것인지에 대한 설정\n\n    \n      0 : 부팅 시 fsck 실행하지 않음\n      1 : 부팅 시 root 파일 시스템을 우선 체크\n      2 : 부팅 시 root 이외의 파일 시스템을 우선 체크\n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-4-1-v2.html\n\n\n  문서 최종 수정일 : 2021-07-06"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-load-balancer-application-lb": {
						"id": "2-networking-ncp-networking-load-balancer-application-lb",
						"title": "VPC 환경에서 Application Load Balancer 생성하기",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_load_balancer_application_lb/",
						"content": "개요\n네이버 클라우드 VPC 환경의 대표적인 Load Balancer인 Application Load Balancer 를 생성하는 가이드입니다.\nVPC와 Subnet을 생성하고, 테스트를 위한 서버 2대를 CentOS와 Ubuntu 각각 1대씩 준비해서 Application Load Balancer와 연결하고 접속해보는 과정까지 정리해보겠습니다.\n\nVPC 생성\nVPC 환경에서는 먼저 VPC를 먼저 생성해야 하며, 이미 만들어진 VPC가 있다면 그대로 이용하셔도 됩니다.\nVPC의 IP 주소 범위는 private 대역 (10.0.0.0/8, 172.160.0./12, 192.168.0.0/16) 내에서 /16 ~ /28 범위여야 합니다.\n여기서는 192.168.0.0/16 범위의 VPC를 생성하겠습니다.\n\n\n\nSubnet 생성\nLoad Balancer를 생성할 때 Server와는 다른 Subnet을 사용해야 정상 작동합니다.\n그래서 여기서도 Load Balancer용 Subnet과 테스트 Server용 Subnet을 각각 생성하도록 하겠습니다.\n\nLoad Balancer용 Subnet 생성\nLoad Balancer는 Private Subnet에 위치해야 하므로 192.168.1.0/24 IP 대역에 Internet Gateway 전용 여부 옵션은 N (Private)을 선택합니다.\n\n\n\nServer용 Subnet 생성\n일반 서버용 Subnet은 192.168.2.0/24 IP 대역에 Internet Gateway 전용 여부 옵션은 Y (Public)을 선택합니다.\n\n\n\n테스트용 Server 생성\n테스트를 위한 서버는 위에서 생성했던 192.168.2.0/24 IP 대역의 Subnet을 선택하고 Network Interface도 동일한 Subnet을 선택합니다.\nLoad Balancer를 테스트 하기 위한 서버이므로 2대를 생성하면서 1대는 CentOS, 나머지 1대는 Ubunt로 생성하겠습니다.\n\n\n\nTarget Group 생성\n[VPC] - [Load Balancer] - [Target Group]에서 Load Balancer가 바라보게 될 Target Group를 설정합니다.\n여기서는 HTTP 프로토콜과 80 포트를 선택하겠습니다.\n\n\n\n다음으로 Health Check 설정에서는 HTTP, 80포트, HEAD Method를 선택합니다.\n\n\n\n마지막으로 Target 즉, 대상이 되는 서버 2대 (lb-test-ubuntu, lb-test-centos)를 선택하고, 적용 Target쪽으로 이동시키는 버튼을 클릭합니다.\n\n\n\n대상 서버들이 적용 Target으로 설정된 모습입니다. 이후에는 전체 설정을 다시 확인하고 생성 완료를 하면 됩니다.\n\n\n\nLoad Balancer 생성\n네이버 클라우드 VPC 환경에서 제공하는 Load Balancer는 애플리케이션 로드밸런서, 네트워크 로드밸런서, 네트워크 프록시 로드밸런서 이렇게 3가지가 있습니다.\n그 중에서 가장 많이 사용하는 HTTP, HTTPS 트래픽을 사용하는 웹 애플리케이션용 Application Load Balancer를 생성하겠습니다.\n\n\n\nNetwork는 Public IP, Subnet은 앞에서 생성했던 192.168.1.0/24 대역의 Subnet을 선택합니다.\n\n\n\n리스너 설정에서 프로토콜은 HTTP, 포트는 80을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n\nTarget Group은 앞에서 생성했던 test-tg을 선택하면, 아래에 해당 Target Group의 설정이 표시됩니다.\n다음으로 전체 설정을 다시 확인하고 최종 생성하기 버튼을 클릭하면 Load Balancer가 생성됩니다.\n\n\n\nNetwork ACL 설정\nLoad Balancer가 정상 작동하기 위해서는 2가지 설정이 추가로 필요한데, 우선 Network ACL 설정에서 Load Balancer가 속한 Subnet 대역을 허용해 주어야 합니다.\n[VPC] - [Network ACL] - [ACL Rule]에서 [Rule 설정]에 있는 [Inbound 규칙]에 앞에서 생성했던 Load Balancer용 Subnet 대역인 192.168.1.0/24 대역의 80 포트를 허용으로 설정해 줍니다.\n\n\n\nACG 설정\n다음으로 [Server] - [ACG]에서 [Inbound 규칙]에 마찬가지로 Load Balancer용 Subnet 대역인 192.168.1.0/24 대역의 80 포트를 허용포트로 설정해 줍니다.\n\n\n\nServer 웹서버 설정\nApplication Load Balancer를 테스트 하기 위해서는 테스트 Server에 웹서버가 설정되어 있어야 하는데, 네이버 클라우드 VPC 환경에서는 LAMP, LEMP 등의 웹서버가 설정된 이미지를 제공하지 않습니다.\n그래서 기본 OS만 설치된 서버에 Apache 웹서버와 php를 설치하도록 하겠습니다. 설치 작업은 아래와 같이 Ubuntu와 CentOS 각각 스크립트를 만들어서 한번에 설치하는 방법을 사용했는데, 필요에 따라서는 하나씩 별도로 설치하셔도 됩니다.\n\nUbuntu에 Apache, PHP 설치하기 스크립트\nApache와 PHP를 설치하고 기본문서 index.html에 서버의 호스트명을 출력하는 스크립트를 적용합니다.\n\n사용한 OS는 Ubuntu 16.04 입니다.\n\n#!/bin/bash\n\napt-get update\napt-get install apache2 \napt-get install php\napt-get install libapache2-mod-php\n\nsystemctl start apache2\n\ncd /var/www/html\necho \"&lt;?php\" &gt; index.html\necho \"echo \\\"Your server name is \\\".(gethostname()).\\\"&lt;br&gt;\\\";\" &gt;&gt; index.html\necho \"?&gt;\" &gt;&gt; index.html\n\necho AddType application/x-httpd-php .php .php3 .php4 .php5 .html .htm .inc &gt;&gt; phpadd\ncat phpadd &gt;&gt; /etc/apache2/apache2.conf\n\nsystemctl restart apache2\nsystemctl enable apache2\nsystemctl status apache2\n\n\n\nCentOS에 Apache, PHP 설치하기 스크립트\n사용한 OS는 CentOS 7.3 입니다.\n\n#!/bin/bash\n\nyum install -y httpd php\n\nsystemctl start httpd\n\ncd /var/www/html\necho \"&lt;?php\" &gt; index.html\necho \"echo \\\"Your server name is \\\".(gethostname()).\\\"&lt;br&gt;\\\";\" &gt;&gt; index.html\necho \"?&gt;\" &gt;&gt; index.html\n\necho AddType application/x-httpd-php .php .php3 .php4 .php5 .html .htm .inc &gt;&gt; phpadd\ncat phpadd &gt;&gt; /etc/httpd/conf/httpd.conf\n\nsystemctl restart httpd\nsystemctl enable httpd\nsystemctl status httpd\n\n\n접속 테스트\n앞에서 생성했던 Load Balancer 정보에서 접속 정보용 주소를 확인하고 복사합니다.\n\n\n\n복사한 Load Balancer 주소를 웹브라우저에 입력하고 계속 새로 고침을 해보면 아래와 같이 CentOS 서버와 Ubuntu에 접속될 때 마다 해당 서버의 호스트명이 출력되면서 Load Balancer가 정상 작동하는 것을 확인할 수 있습니다.\n\n\n\n\n\n참고 URL\n\n  Application Load Balancer 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-loadbalancer-applicationlbconsole\n    \n  \n  Target Group 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-loadbalancer-targetgroupconsole\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-12-17"
					}
					
				
			
		
			
				
					,
					
					"6-media-ncp-media-video-player-sample": {
						"id": "6-media-ncp-media-video-player-sample",
						"title": "Video Player 구현하기 샘플 예제",
						"categories": "6.media",
						"url": " /6.media/ncp_media_video_player_sample/",
						"content": "개요\n네이버 클라우드 비디오 플레이어는 최신의 네이버 미디어 플레이어를 기반으로 개발된 클라우드 전용 상품으로 \n네이버 동영상 서비스에 적용되어 수 많은 성공사례를 가지고 있는 최신의 네이버 플레이어를 손쉽고 빠르게 고객의 미디어 서비스에 적용할 수 있습니다.\n\n플레이어 생성하기\n우선은 네이버 클라우드 콘솔에서 js 파일로 구성된 플레이어를 생성하는 과정부터 살펴보겠습니다.\n\n[네이버 클라우드 콘솔] - [Video Player]에서 [플레이어 생성] 버튼을 클릭합니다.\n\n\n\n플레이어 이름, 유-무료 상품(현재는 무료만 선택 가능), 플레이어 사이즈, 버전, 플레이어가 저장될 Object Storage 위치 등을 선택합니다.\n\n\n\n재생 속도 조절 등의 기능을 설정하고, 우클릭 메뉴 바로가기를 추가할 수도 있습니다.\n\n\n\n자동 재성이나 대역폭 등의 재생 관련 설정을 선택합니다.\n\n\n\n마지막으로 현재까지 선택한 설정을 확인하고, 플레이어 미리보기를 한 후에 [플레이어 생성] 버튼을 클릭합니다.\n\n\n\n생성된 플레이어 js 파일의 경로를 확인할 수 있습니다.\n\n\n\njs 파일이 저장된 Object Storage에서도 확인 가능합니다.\n\n\n\n플레이어 구현하기\n생성된 플레이어는 자바스크립트 js 파일이므로 html 파일을 만들어서 플레이어를 구현해야 합니다.\n\n플레이어 JavaScript 소스 예시\n\n  var player = new ncplayer('divVideoPlayer', {\n    playlist: \"http://example.com/myVideo.mp4\"\n  });\n\n  player.play();\n\n\n플레이어 html 소스 예시\n아래 예시에서는  컨트롤러 표시, 자동 재생 안함, 음소거, 가로 크기 1024로 옵션을 설정했습니다. 상세한 옵션을 아래쪽에서 다시 살펴보겠습니다.\n\n&lt;!doctype html&gt;\n&lt;html lang=\"kr\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Video Player Sample&lt;/title&gt;\n\n    &lt;script src=\"https://kr.object.ncloudstorage.com/플레이어 파일명.js\"&gt;&lt;/script&gt;\n  &lt;/head&gt;\n\n  &lt;body&gt;\n\n    &lt;div style=\"text-align:center\"&gt;\n      &lt;div id=\"divVideoPlayer\" name=\"divVideoPlayer\"&gt;&lt;/div&gt;\n    &lt;/div&gt;\n\n     &lt;script type=\"text/javascript\"&gt;\n\n      var player = new ncplayer('divVideoPlayer', {\n        controls: true,\n        autostart: false,\n        mute: true,\n        width: 1024,\n        playlist: [\n        {\n          file: 'https://kr.object.ncloudstorage.com/재생할 동영상 파일명.mp4',\n        },\n        ],\n      });\n\n      player.play();\n\n     &lt;/script&gt;\n\n   &lt;/body&gt;\n&lt;/html&gt;\n\n\n플레이어 구현 예시\n위 html 소스대로 플레이어를 구현해서 웹브라우져에서 확인해보면 다음과 같이 나타납니다.\n\n\n\n플레이어 상세 옵션\n플레이어 상세 옵션을 간단하게 정리해보겠습니다. 좀 더 자세한 설명은 아래 링크에 있는 네이버 클라우드 가이드 문서를 참고하시면 됩니다.\n\n\nvar player = new ncplayer('divVideoPlayer', {\n  controls: true,\n  autostart: false,\n  mute: true,\n  width: 1024,\n  playlist: [\n    { file: 'https://CDN도메인/example_video_01.mp4' },\n    { file: 'https://CDN도메인/example_video_02.mp4' },\n    { file: 'https://CDN도메인/example_video_03.mp4/index.m3u8' }\n  ],\n  });\n\n\n\n\n  \n    \n      PROPERTY\n      TYPE\n      DESCRIPTION\n      DEFAULT\n    \n  \n  \n    \n      playlist\n      string/array\n      재생하고자 하는 video 정보 (단일 경로 또는, 여러 경로를 전달)\n      -\n    \n    \n      autostart\n      boolean\n      player 시작 시, video를 자동으로 재생 (브라우저의 자동재생 정책을 따름)\n      false\n    \n    \n      mute\n      boolean\n      player 시작 시, video를 자동으로 음소거 상태로 설정\n      false\n    \n    \n      controls\n      boolean\n      player 제어를 위한 컨트롤의 표시 여부 결정\n      true\n    \n    \n      autoPause\n      boolean\n      창이 전환되거나 최소화되었을 때, 자동으로 player를 정지 상태로 만듦\n      false\n    \n    \n      aspectRatio\n      string\n      player의 가로X세로 비율 지정, “width:height” 형식으로 전달해야 합니다.\n      -\n    \n    \n      width\n      number\n      player의 가로 사이즈 고정\n      -\n    \n    \n      height\n      number\n      player의 세로 사이즈 고정\n      -\n    \n    \n      playbackRate\n      boolean\n      video 의 재생속도 조절, 1.0보다 낮으면 느려지고, 1.0보다 높으면 빠르게 재생\n      1.0\n    \n    \n      repeat\n      boolean\n      video의 반복 재생 여부 결정\n      false\n    \n    \n      about\n      object\n      마우스 우클릭 시 표시되는 바로가기 정보 수정\n      false\n    \n  \n\n\n참고 URL\n\n  Video Player 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/videoplayer-videoplayerguide\n    \n  \n  Video Player Demo 가이드\n    \n      https://guide.ncloud-docs.com/docs/videoplayer-videoplayerdemo\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-06-14"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-windows-server-image-copy-classic-to-vpc": {
						"id": "1-compute-ncp-server-windows-server-image-copy-classic-to-vpc",
						"title": "Classic 환경 Windows 서버 이미지를 VPC 환경으로 복제하는 방법",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_windows_server_image_copy_classic_to_vpc/",
						"content": "개요\n네이버 클라우드 Classic 환경의 Windows 서버 이미지를 VPC 환경으로 복제하려면 몇가지 사전 작업과 조건이 있습니다.  이 사전 작업과 조건을 차례대로 정리해보겠습니다.\n\nOS 조건 확인\nClassic 환경의 서버 이미지를 VPC 환경으로 복제하는 것이므로 VPC에서 지원하는 OS만 복제 가능합니다.\n즉, 현재 네이버 클라우드 VPC 환경에서 지원하는 Windows OS 버전은\nWindows Server 2016 (64-bit) English Edition 하나이기 때문에 2016 R2 등의 OS를 사용 중이라면 \nVPC에서 지원하지 않아 복제가 불가능하니 VPC에서 지원할 때까지 작업을 보류하셔야 합니다.\n\n\n(2021년 6월 1일 현재 VPC 환경에서 지원하는 Windows OS 버전)\n\n사전 작업 확인\n우선 사전 작업이 어떤 것이 있는지 확인해 보기 위해 Windows 서버 이미지를 하나 만들어서 상단에 있는 [VPC로 복제] 버튼을 클릭해 봅니다.\n\n안내 팝업에는 다음과 같은 작업이 필요하다고 적혀 있습니다.\n\n\n  백신 솔루션 확인 및 필요시 백신 삭제\n  백신 상태 확인 스크립트 실행\n  내 서버 이미지 다시 생성 후 VPC 복제 기능 사용\n\n\n\n\n백신 삭제\nWindows 서버에 설치된 백신 솔루션을 확인해서, ApexOne 또는 OfficeScan이라면 백신 삭제가 필요하며, 그 외 솔루션은 삭제하지 않아도 됩니다.\n\nApexOne 삭제방법\n\n  제어판 -&gt; 프로그램 추가제거로 이동 후 ‘Trend Micro Apex One Security Agent’를 선택하고, 삭제합니다.\n  C:\\Program Files (x86) 경로의 Trend Micro\\Security Agent 폴더를 삭제합니다.\n(삭제되지 않는 파일은 그대로 두셔도 됩니다)\n\n\nOfficeScan 삭제방법\n\n  제어판 -&gt; 프로그램 추가제거로 이동 후 ‘Trend Micro officescan Security Agent’를 선택하고, 삭제합니다.\n  C:\\Program Files (x86) 경로의 Trend Micro\\Security Agent 폴더를 삭제합니다.\n\n\n그 외 솔루션\n\n  백신 삭제 불필요\n\n\n\n\n\n\n\n\n백신상태 확인\n백신이 모두 정상적으로 제거되었는지 확인하는 툴을 실행합니다.\n\n백신상태 확인 Tool 다운로드\nWindows PowerShell을 열고, 다음의 명령어를 실행하면 바탕화면에 Tool이 다운로드 됩니다.\n\ncd c:\\users\\Administrator\\Desktop \nInvoke-WebRequest http://init.ncloud.com/vpcporting/real/ncp_vac_chk.exe -outfile ncp_vac_chk.exe\n\n\n\n백신상태 확인 Tool 실행\n바탕화면에 다운로드 된 ncp_vac_chk.exe 파일을 관리자 권한으로 실행합니다.\n\n\n\n백신상태 확인 체크 결과 확인\n백신상태 확인이 정상적으로 수행되면 바탕화면에 notifyFreeAntiVirusRemoved, result 파일 2개가 생성되며, 백신상태 확인이 비정상으로 수행되면 result 파일 1개만 생성이 됩니다.\n\nnotifyFreeAntiVirusRemoved 파일이 생성되지 않거나 해당 파일의 내용이 OK가 아닌 경우 백신상태 확인이 정상적으로 완료되지 못한 경우이므로 백신솔루션에 따라 필요시 백신이 잘 제거되었는지 다시 한번 더 체크 후 해당 Tool을 실행해야 합니다.\n\n백신상태 확인이 정상적으로 완료되지 않고 문제가 지속되면 result 파일을 첨부하여 네이버 클라우드 고객센터에 문의하셔야 합니다.\n\n\n\n서버 이미지 복제\n\n서버 이미지 재 생성\n위에서 백신상태 확인 체크가 정상적으로 완료되었다면, 서버 이미지를 다시 생성합니다.\n\n서버 이미지 VPC로 복제\n[콘솔] - [Classic] - [Server] - [Server Image]에서 새로 생성한 이미지를 선택하고 상단의 [VPC 로 복제] 버튼을 클릭합니다.\n위에서도 설명했듯이 현재는 Windows Server 2016 (64-bit) English Edition 버전만 지원합니다.\n\n\n\n복제되는 신규 서버 이미지 이름을 입력하고 [생성] 버튼을 클릭합니다.\n\n\n\n실제 VPC 환경에 복제 진행 중인 이미지가 표시되기까지는 다소 시간이 걸릴 수 있으니 잠시 기다리시면 확인하실 수 있습니다.\n\n\n\n복제된 서버 이미지 확인\n복제가 완료된 서버 이미지의 상세 정보를 살펴보면 Classic 복제 여부 항목이 Y로 표시되는 것을 확인할 수 있습니다.\n\n\n\n서버 생성\nClassic 환경에서 VPC 환경으로 복제된 서버 이미지로 새로운 서버가 생성되는지 확인해보겠습니다.\n이미지를 선택하고 [서버 생성] 버튼을 클릭해서 서버 생성화면에서 정보를 입력하고 서버를 생성합니다.\n\n\n\n정상적으로 생성된 서버를 확인할 수 있습니다.\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-5-1-v2\n\n\n  문서 최종 수정일 : 2021-06-01"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-ssh-security-setting": {
						"id": "1-compute-ncp-server-ssh-security-setting",
						"title": "리눅스서버 SSH 접속 보안 설정하기",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_ssh_security_setting/",
						"content": "개요\n리눅스 서버들은 서버에 접속할 때 SSH를 이용하게 되는데, 이때 root 계정에 대한 무작위 패스워드 입력 등의 해킹시도가 있을 수 있습니다.\n여기서는 이러한 해킹시도를 차단하기 위한 보안설정 중에서 root 계정과 관련한 보안설정 2가지를 정리해보겠습니다.\n\n설정 파일 위치\nroot 계정에 대한 보안 설정은 /etc/ssh/sshd_config 파일에 있습니다.\n\n~# vi /etc/ssh/sshd_config\n\n\nCentOS\n\n\nUbuntu\n\n\nroot 로그인 차단\n로그인 차단은 위 설정에서 PermitRootLogin 항목을 바꾸시면 됩니다.\nCentOS는 주석처리 되어 있으므로 주석을 해제하고 설정을 변경하시면 되고, Ubuntu는 주석이 해제된 상태이므로 설정값만 변경하시면 됩니다.\n\n\n  root 로그인을 차단하기 전에 다른 관리자 계정을 생성한 후에 차단 설정을 적용해야 합니다.\n\n\n# 기존 - CentOS\n#PermitRootLogin yes\n\n# 기존 - Ubuntu\nPermitRootLogin yes\n\n# 변경\nPermitRootLogin no\n\n\n\n기타 옵션\n# 패스워드 로그인은 차단하고 Key 파일을 이용한 로그인만 허용\nPermitRootLogin prohibit-password\n\n\n\n로그인 시도 횟수 제한\n이 옵션을 지정하게 되면 지정한 횟수 이상으로 로그인을 실패했을 때 접속이 강제 종료되는데, 기본값은 6회이니 적절하게 수정하시면 됩니다.\n\n# 기존\n#MaxAuthTries 6\n\n# 변경\nMaxAuthTries 3\n\n\n데몬 재시작\n설정을 수정하고 파일을 저장한 후에 sshd 데몬을 재시작합니다.\n\n~# systemctl restart sshd\n\n\n데몬 재시작 후 로그인을 시도해보면 로그인이 실패하는 것을 확인하실 수 있습니다.\n\n\n\nSSH 접속 로그 확인\nSSH로 접속을 하면 성공, 실패에 대한 로그가 모두 남게 되는데, 이 로그를 주기적으로 확인하는 것이 좋습니다.\n\n접속 실패 로그\n~# last -f /var/log/btmp\n\n# 또는\n~# lastb\n\n\n\n접속 성공 로그\n~# last -f /var/log/wtmp\n\n\n\n참고 URL\n\n  네이버 클라우드 리눅스서버 접속 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-compute-3-1-v2.html\n    \n  \n  네이버 클라우드 플랫폼을 활용한 보안 강화\n    \n      https://m.blog.naver.com/n_cloudplatform/221117956958\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-05-28"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-global-dns-guide": {
						"id": "2-networking-ncp-networking-global-dns-guide",
						"title": "Global DNS 사용 가이드 - 도메인 추가",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_global_dns_guide/",
						"content": "개요\nDNS 서버는 개인이 직접 운영하기 어려운데, 네이버 클라우드 Global DNS를 이용하면 도메인 설정 등을 쉽고 편하게 사용할 수 있습니다.\n\n도메인 추가\n네이버 클라우드는 도메인 구매/등록을 지원 하지 않습니다. 그러므로 가비아, 아이네임즈, 닷네임코리아 등 전문 도메인 등록 기관에서 도메인을 구입 하셔야 합니다.\n새로 구입한 도메인 혹은 기존 도메인을 [네이버 클라우드 콘솔] - [Networking] - [Global DNS] 메뉴에서 [도메인 추가] 버튼을 클릭해 도메인주소를 입력합니다.\n\n\n\n\n\n다음과 같이 생성된 도메인 정보에서 네임서버의 주소를 확인합니다.\n\n\n\n도메인을 구입한 등록기관 사이트에서 해당 도메인의 네임서버를 위에서 확인한 네이버 클라우드 Global DNS에서 제공하는 네임서버 정보로 등록합니다.\n\n\n\n레코드 추가\n레코드를 추가하려면 도메인 정보에서 [레코드 추가]를 클릭합니다.\n\n\n\n추가하려고 하는 레코드 즉, 호스트명과 IP 주소를 입력합니다,\n\n\n\n추가된 레코드를 도메인 정보에서 아래와 같이 확인한 후, [설정 적용] 버튼을 클릭합니다.\n\n\n\n[배포] 버튼을 클릭해 변경된 정보를 배포-적용합니다.\n\n\n\n네이버 클라우드 네임서버를 클라이언트의 DNS로 설정하지 않은 경우, 레코드의 추가/변경 내역이 반영되는데 전파시간이 소요될 수 있습니다.\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-networking-12-1\n\n\n  문서 최종 수정일 : 2021-05-27"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-server-image-share-classic": {
						"id": "1-compute-ncp-server-server-image-share-classic",
						"title": "Classic 환경에서 서버 이미지를 다른 계정에 공유하는 방법",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_server_image_share_classic/",
						"content": "개요\n네이버 클라우드 Classic 환경에서 내 서버 이미지를 다른 계정에 공유하는 방법입니다.\nLinux와 Windows OS별 차이는 없으며, 일단은 서버 이미지가 생성되어 있는 것을 가정해서 내용을 정리해보겠습니다.\n\n공유 권한 설정\n네이버 클라우드 콘솔 [Server] - [Server Image]에서 공유할 서버 이미지를 선택하고 상단 메뉴에 있는 [공유 권한 설정]을 클릭합니다.\n\n\n\n다음으로 서버 이미지를 공유할 계정 즉, 로그인 ID를 입력합니다.\n\n\n\n로그인 ID 입력 후 [권한 추가] 버튼을 클릭하고, [적용] 버튼을 클릭해 설정을 적용합니다.\n\n\n\n공유 권한 설정을 적용하면 서버 이미지 정보에 [공유 중]이라고 표시되고, [공유 받은 계정] 정보도 확인할 수 있습니다.\n\nLinux (CentOS, Ubuntu)\n\n\nWindows\n\n\n공유 상태 확인\n\n이제 공유 받은 계정으로 접속해보면 [Server Image]에 추가된 서버 이미지가 보이고, [공유 받음] 표시를 확인할 수 있습니다.\n\nLinux (CentOS, Ubuntu)\n\n\nWindows\n\n\n다음으로 공유 받은 서버 이미지를 선택하고, [서버 생성] 버튼을 클릭합니다.\n\n\n\n서버 생성 정보 입력 화면이 나타나면서 문제 없이 서버를 생성할 수 있다는 것을 알 수 있습니다.\n\n\n\n공유 권한 삭제\n\n이제 공유된 권한을 삭제해보겠습니다.\n처음 서버 이미지를 공유할 때 처럼 서버 이미지를 선택하고, [공유 권한 설정]을 클릭하고, [공유 받은 계정]을 삭제합니다.\n\n\n\n공유된 계정을 삭제하고, [적용] 버튼을 클릭해 변경될 설정을 적용합니다.\n\n\n\n아까 공유 받았던 계정으로 접속해 [Server Image]에 들어가보면 공유되었던 서버 이미지가 삭제된 것을 확인할 수 있습니다.\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-5-1-v2\n\n\n  문서 최종 수정일 : 2021-05-31"
					}
					
				
			
		
			
				
					,
					
					"9-application-20service-ncp-application-service-papago-korean-name-romanizer-php-sample": {
						"id": "9-application-20service-ncp-application-service-papago-korean-name-romanizer-php-sample",
						"title": "PHP로 Papago Korean Name Romanizer 서비스 이용하기 샘플 예제",
						"categories": "9.application service",
						"url": " /9.application%20service/ncp_application_service_papago_korean_name_romanizer_php_sample/",
						"content": "개요\nPapago Korean Name Romanizer는 한글로 된 이름을 로마자 표기로 변환해주는 서비스로, 현행 로마자 표기법을 따라 변환한 이름과 통계적으로 많이 사용되는 로마자 이름도 함께 제안 받을 수 있습니다.\nPapago Korean Name Romanizer는 OpenAPI 형태로 제공되며 여기서는 PHP로 호출하는 방식을 살펴볼텐데, 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\n이용 요금\nPapago Korean Name Romanizer는 무료로 제공되는 서비스이며, 일 25,000자, 월 750,000자 내에서 사용 가능하며 상향이 필요한 경우 고객지원으로 문의하면 됩니다.\n\nAPI 이용 신청\nPapago Korean Name Romanizer를 이용하기 위해서는 [네이버 클라우드 콘솔] - [AI·NAVER API] -  [Application]에서 등록을 해야 합니다.\n아래와 같이 NAVER 서비스에서 Papago Korean Name Romanizer를 선택하고, 이름과 사용할 서비스 환경을 입력하고 등록하면 됩니다.\nPapago Korean Name Romanizer는 웹페이지, 모바일앱 어디서든 사용 가능하며 URL이나 앱 패키지이름, Bundle ID 등을 입력하시면 됩니다.\n\n\n\nApplication 등록을 하고 나면 다음과 같은 화면을 볼 수 있는데 여기서 인증 정보를 확인해야 합니다.\n\n\n\n인증키 확인\nPapago Korean Name Romanizer API를 호출하려면 Client ID와 Client Secret 로 이루어진 Application Key를 사용해야 하는데 아래와 같이 [인증 정보] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n\nAPI 호출 샘플 코드\n\n&lt;?php\n\t\n$korean_name = \"변환할 한글 이름\";\t\n\t\n$client_id = \"Client ID\";\n$client_secret = \"Client Secret\";\n$enc_korean_name = urlencode($korean_name);\n$getvars = \"query=\".$enc_korean_name;\n$api_url = \"https://naveropenapi.apigw.ntruss.com/krdict/v1/romanization?\".$getvars;\n$is_post = false;\n\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $api_url);\ncurl_setopt($ch, CURLOPT_POST, $is_post);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n\n$headers = array();\n$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n\n$json_response = curl_exec ($ch);\n\n$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n\ncurl_close ($ch);\n\nif($status_code == 200){\n\t$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n\tif (count($rows_response[\"aResult\"]) &gt; 0){\n\t\t$rows_result = $rows_response[\"aResult\"][0];\n\t\t$sFirstName = $rows_result[\"sFirstName\"];\n\t\t$aItems = $rows_result[\"aItems\"];\n\t}else{\n\t\t$roman_name = \"변환할 수 없는 이름입니다\";\n\t}\n}else{\n\t$roman_name = \"Error 내용:\".$json_response;\n}\n\n?&gt;\n\n\n코드 상세 설명\n\nApplication Key\n$client_id = \"Client ID\";\n$client_secret = \"Client Secret\";\n\n네이버 클라우드 콘솔에서 Papago Korean Name Romanizer 서비스를 등록하고 인증 정보에서 확인한 [Client ID] 와 [Client Secret]를 가져와서 사용하면 됩니다.\n\n파라미터 설정\n$enc_korean_name = urlencode($korean_name);\n$getvars = \"query=\".$enc_korean_name;\n$is_post = false;\n\n변환할 한글 이름을 urlencode로 인코딩하고, GET 방식으로 호출하면서 넘겨줄 변수에 할당합니다.\n\nAPI URL\n$api_url = \"https://naveropenapi.apigw.ntruss.com/krdict/v1/romanization?\".$getvars;\n\n\nPapago Korean Name Romanizer의 API URL은 위와 같고, GET 방식으로 호출하므로 url 뒤에 파라미터를 붙여서 전송합니다.\n\nhttp 호출 헤더값 설정\n$headers = array();\n$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\n위에서 가져온 Application Key를 호출할 API에 헤더값으로 설정해서 호출하게 됩니다.\n\n결과값 반환\n$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\nif (count($rows_response[\"aResult\"]) &gt; 0){\n\t$rows_result = $rows_response[\"aResult\"][0];\n\t$sFirstName = $rows_result[\"sFirstName\"];\n\t$aItems = $rows_result[\"aItems\"];\n\n\tforeach ($aItems as $item){\n\t\t$roman_name = $item[\"name\"];\n\t\t$score = $item[\"score\"];\n\t}\n}else{\n\t$roman_name = \"변환할 수 없는 이름입니다\";\n}\n\nPapago Korean Name Romanizer에서 json형태로 반환된 값을 배열에 담아 사용하면 됩니다.\n반환되는 값은 한글 성과 변환된 로마자 이름과 빈도수가 담긴 배열입니다.\nPapago Korean Name Romanizer에서 변환할 수 없는 이름일 경우 상태코드는 정상이지만 배열에 정보가 없기 때문에 예외처리를 해주어야 합니다.\n\n사용 한도 및 알람 설정\nPapago Korean Name Romanizer 서비스는 과도한 사용을 방지하기 위해 일별 25,000자, 월별 750,000자의 제한이 있습니다.\n그리고 지정된 한도 내에서 일정한 사용을 초과하면 알람을 받도록 설정할 수 있습니다.\n아래처럼 Application 등록 화면에서 [한도 및 알람 설정] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ai-naver-papagokoreannameromanizer\n\n\n  “문서 최종 수정일 : 2021-05-24”"
					}
					
				
			
		
			
				
					,
					
					"9-application-20service-ncp-application-service-cloud-outbound-mailer-bulk-mail-send": {
						"id": "9-application-20service-ncp-application-service-cloud-outbound-mailer-bulk-mail-send",
						"title": "Cloud Outbound Mailer로 대량 메일 발송하는 방법",
						"categories": "9.application service",
						"url": " /9.application%20service/ncp_application_service_cloud_outbound_mailer_bulk_mail_send/",
						"content": "개요\n네이버 클라우드 서비스 중에서 각 종 공지나 이벤트, 마케팅으로 회원들에게 대량의 메일을 발송해야 할 때 사용할 수 있는 것이 Cloud Outbound Mailer 입니다.\n대량 메일을 발송하는 방법은 여러가지 있지만, 그 중에서도 가장 자주, 간편하게 사용하는 것이 Excel 등의 파일을 업로드 해서 발송하는 방법입니다.\n\n이용 신청\nCloud Outbound Mailer는 먼저 이용신청을 하셔야 합니다.\n[Console] - [Cloud Outbound Mailer] - [Mailing list] 에서 [이용 신청] 버튼을 클릭하시면 됩니다.\n\n\n\n다음으로 서비스 이용약관에 동의하시면 됩니다.\n\n\n\n메일 작성\n메일링 리스트 화면에서 발송하기 버튼을 클릭합니다.\n\n\n메일 작성-발송하기 화면입니다.\n이중에서 보내는 메일주소, 제목, 내용, 받는 사람은 필수 입력 사항입니다.\n\n\n\n[대량 발송용 입력양식 파일다운로드]와 [대량 발송용 파일 선택]은 [보내는 메일 주소]와 [제목], [내용] 을 입력해야 활성화 됩니다.\n\n\n\n대량메일 발송용 입력양식\nCloud Outbound Mailer에서 제공하는 대량메일 발송용 입력양식을 다운 받아서 보면, [수신자 Email 주소], [NAME] 이렇게 2가지 항목으로 구성되어 있습니다.\n\n\n\n그 외에도 필요한 항목들을 추가해서 사용할 수 있습니다. 여기서는 [GRADE], [GIFT\t] 항목을 추가해서 테스트 해보겠습니다. \n추가 항목의 이름은 어떤 것이든 상관없습니다. 실제 메일 내용에서 동일한 이름을 사용하기만 하면 문제 없습니다.\n\n\n\n보내는 이름, 보내는 메일주소, 제목 입력\n우선, 보내는 이름과 보내는 메일주소, 제목을 입력합니다.\n제목에는 대량 메일 수신자들의 이름이 들어가도록 위에서 확인한 입력 양식에 있던 이름에 해당하는 [NAME] 필드가 들어갈 수 있게 ${NAME} 코드를 입력합니다.\n\n\n\n내용 입력\n내용은 직접 입력해도 되고 별도로 제작된 html 파일을 이용할 수도 있는데 Cloud Outbound Mailer에서는 html 파일 업로드는 지원하지 않습니다.\n그러므로 html 소스를 직접 복사해서 화면에 입력해야 합니다.  다음과 같은 샘플용 html을 준비해서 &lt;body&gt;와 &lt;/body&gt;태그 사이에 있는 내용을 복사해서 에디터의 html모드에 붙여넣습니다.\n\n\n  스타일은 css 파일이나 style태그를 사용하지 말고 가급적 태그 안에 inline으로 적용하는 것이 좋습니다.\n메일 서비스 별로 head 태그만 없애는 곳도 있고, style태그를 모두 없애거나, body태그 안쪽의 내용만 남기고 모두 없애는 곳도 있기 때문에 inline 형식으로 적용하는 것이 가장 안전합니다.\n\n\n\n\n복사한 html을 Editor 모드로 바꾸면 다음과 같이 보입니다.\n여기서 위에서 준비한 입력양식 Excel 파일에 있던 ${NAME}, ${GRADE}, ${GIFT} 항목을 적절하게 배치해서 입력해두었습니다.\n\n\n\n대량메일 수신자 파일 등록, 확인 후 발송\n위에서 준비했던 대량메일 수신자 정보가 들어있는 Excel 파일을 등록하고 [확인 후 발송] 버튼을 클릭합니다.\n바로 발송을 해도 되지만 그것보다는 메일 내용이 제대로 표시되는지, 수신자 목록은 문제 없이 로딩되었는지 확인 한 후에 발송하는 것이 안전합니다.\n\n\n\n발송 준비\n확인 후 발송을 선택하면 이렇게 [발송 준비] 상태로 리스트에 나타납니다.\n이 상태에서 수신자와 메일 내용이 올바르게 설정되었는지 확인하기 위해 [수신자별 목록] 탭을 선택합니다.\n\n\n\n수신자별 목록\n수신자별 목록을 살펴보면 다음과 같이 나옵니다.  Excel 파일에 등록해 두었던 이름과 이메일 주소가 문제없이 나타납니다.\n\n\n\n메일 내용 확인\n수신자별 목록에서 하나를 선택하면 상세 내용이 나오는데, 그 중에서 아래쪽에 있는 [내용보기] 버튼을 클릭해서 메일 본문 내용도 문제가 없는지 확인합니다.\n\n\n\n내용 보기를 하시면 아래와 같이 Excel 파일에 등록해 두었던  [NAME], [GRADE], [GIFT] 항목들이 문제없이 설정되어 표시된 것을 확인할 수 있습니다.\n\n\n\n메일 발송\n이제 다시 [요청별 목록]으로 돌아와서 [즉시 발송] 버튼을 클릭해 메일을 발송합니다.\n\n\n\n메일 도착 확인\n실제 존재하는 메일 주소로 발송해보면 이렇게 메일이 잘 들어온 것을 확인할 수 있습니다.\n\n\n\n메일 발송 도메인\n메일 발송은 잘되었고, 도착도 잘했는데 궁금한 것이 한가지 생깁니다.\n과연 메일 발송 도메인은 어떤 것일까?  그래서 구글 계정으로 보낸 메일에서 발송 도메인을 확인해보았습니다.\n도메인은 email.ncloud.com 인 것을 확인할 수 있습니다.\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/email-email-1-2\n\n\n  “문서 최종 수정일 : 2021-05-13”"
					}
					
				
			
		
			
				
					,
					
					"9-application-20service-ncp-application-service-nshorturl-php-sample": {
						"id": "9-application-20service-ncp-application-service-nshorturl-php-sample",
						"title": "PHP로 nShortURL 서비스 이용하기 샘플 예제",
						"categories": "9.application service",
						"url": " /9.application%20service/ncp_application_service_nshorturl_php_sample/",
						"content": "개요\nSNS를 사용하거나 SMS를 보낼 때 길고 복잡한 URL은 무척 불편하기에 짧게 바꿔주는 서비스들이 인기를 얻었습니다.\n대표적으로 goo.gl, bit.ly 등이 있는데 현재 구글의 goo.gl는 서비스가 종료되었습니다.\n그래서 이를 대신해서 네이버 클라우드에 있는 길고 복잡한 URL을 간단하고 짧게 바꿔주는 API 서비스 nShortURL 서비스를 추천합니다.\nnShortURL은 OpenAPI 형태로 제공되는데 여기서는 PHP로 호출하는 방식을 살펴볼텐데, 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\n이용 요금\nnShortURL은 무료로 제공되는 서비스이며, 일 25,000건, 월 750,000건 내에서 사용 가능하며 상향이 필요한 경우 고객지원으로 문의하면 됩니다.\n\nAPI 이용 신청\nnShortURL을 이용하기 위해서는 [네이버 클라우드 콘솔] - [AI·NAVER API] -  [Application]에서 등록을 해야 합니다.\n아래와 같이 NAVER 서비스에서 nShortURL을 선택하고, 이름과 사용할 서비스 환경을 입력하고 등록하면 됩니다.\nnShortURL은 웹페이지, 모바일앱 어디서든 사용 가능하며 URL이나 앱 패키지이름, Bundle ID 등을 입력하시면 됩니다.\n\n\n\nApplication 등록을 하고 나면 다음과 같은 화면을 볼 수 있는데 여기서 인증 정보를 확인해야 합니다.\n\n\n\n인증키 확인\nnShortURL API를 호출하려면 Client ID와 Client Secret 로 이루어진 Application Key를 사용해야 하는데 아래와 같이 [인증 정보] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n\nAPI 호출 샘플 코드\n\n&lt;?php\n\t\n\t$long_url = \"변환할 URL\";\t\n\t\t\n\t$client_id = \"Client ID\";\n\t$client_secret = \"Client Secret\";\n\t$api_url = \"https://naveropenapi.apigw.ntruss.com/util/v1/shorturl\";\n\t$enc_url = urlencode($long_url);\n\t$postvars = \"url=\".$enc_url;\t\n\t$is_post = true;\n\n\t$ch = curl_init();\n\tcurl_setopt($ch, CURLOPT_URL, $api_url);\n\tcurl_setopt($ch, CURLOPT_POST, $is_post);\n\tcurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n\tcurl_setopt($ch, CURLOPT_POSTFIELDS, $postvars);\n\n\t$headers = array();\n\t$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n\t$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\n\tcurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n\n\t$json_response = curl_exec ($ch);\n\n\t$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n\n\tcurl_close ($ch);\n\n\tif($status_code == 200) \n\t{\n\t\t$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n\t\t$rows_result = $rows_response[\"result\"];\n\t\t$short_url = $rows_result[\"url\"];\n\t\t$hash_val = $rows_result[\"hash\"];\n\t\t$org_url = $rows_result[\"orgUrl\"];\n\t} \n\telse \n\t{\n\t\t$short_url = \"Error 내용:\".$json_response;\n\t}\n\n?&gt;\n\n\n코드 상세 설명\n\nApplication Key\n$client_id = \"Client ID\";\n$client_secret = \"Client Secret\";\n\n네이버 클라우드 콘솔에서 nShortURL 서비스를 등록하고 인증 정보에서 확인한 [Client ID] 와 [Client Secret]를 가져와서 사용하면 됩니다.\n\nAPI URL\n$api_url = \"https://naveropenapi.apigw.ntruss.com/util/v1/shorturl\";\n\n\nnShortURL의 API URL은 위와 같습니다.\n\n파라미터 설정\n$enc_url = urlencode($long_url);\n$postvars = \"url=\".$enc_url;\t\n$is_post = true;\n\n변환할 URL을 urlencode로 인코딩하고, POST 방식으로 호출하면서 넘겨줄 변수에 할당합니다.\n\nhttp 호출 헤더값 설정\n$headers = array();\n$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\n위에서 가져온 Application Key를 호출할 API에 헤더값으로 설정해서 호출하게 됩니다.\n\n결과값 반환\n$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n$rows_result = $rows_response[\"result\"];\n$short_url = $rows_result[\"url\"];\n$hash_val = $rows_result[\"hash\"];\n$org_url = $rows_result[\"orgUrl\"];\n\nnShortURL에서 json형태로 반환된 값을 배열에 담아 사용하면 됩니다.\n반환되는 값은 짧게 변환된 URL와 해시값, 그리고 원본 URL입니다.\n\n사용 한도 및 알람 설정\nnShortURL 서비스는 과도한 사용을 방지하기 위해 일별 25,000회, 월별 750,000회의 제한이 있습니다.\n그리고 지정된 한도 내에서 일정한 사용을 초과하면 알람을 받도록 설정할 수 있습니다.\n아래처럼 Application 등록 화면에서 [한도 및 알람 설정] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ai-naver-nshorturl\n\n\n  “문서 최종 수정일 : 2021-04-30”"
					}
					
				
			
		
			
				
					,
					
					"99-etc-etc-pdf-merge-php-sample": {
						"id": "99-etc-etc-pdf-merge-php-sample",
						"title": "Pdf 문서 합치기 PHP로 구현하는 방법",
						"categories": "99.ETC",
						"url": " /99.etc/etc_pdf_merge_php_sample/",
						"content": "개요\n요즘은 회사 업무에서 파일을 전달할 때 PDF 문서를 활용하는 경우가 매우 많습니다. \n그런데 이때 보내야 하는 PDF 문서가 여러개 일 경우 받는 쪽에서 각각의 파일을 일일이 열어봐야 해서 불편한 경우가 있습니다.\n이럴때 여러 PDF 문서를 합쳐서 하나의 문서로 만들어 보내면 편리한 경우에 사용할 수 있는 PDF 문서 합치기 - merge 기능을 PHP로 구현하는 방법입니다.\n\n라이브러리 설치\nPDF 문서를 합쳐 주는 기능을 가진 라이브러리는 [ php pdf merger ]라고 검색해보면 여러가지 버전이 존재하는데 여기서는 Jurosh 라는 사람이 만든 것을 사용하겠습니다.\n우선 composer 를 이용해서 라이브러리를 설치합니다.\n\ncomposer require jurosh/pdf-merge\n\n\n기본 사용법\n아래 기본 사용법은 라이브러리 개발자가 GitHub에 올려둔 가이드에 있는 사용법입니다.\n\n&lt;?php\n\n  require 'vendor/autoload.php';\n\n  // and now we can use library\n  $pdf = new \\Jurosh\\PDFMerge\\PDFMerger;\n\n  // add as many pdfs as you want\n  $pdf-&gt;addPDF('path/to/source/file.pdf', 'all', 'vertical')\n    -&gt;addPDF('path/to/source/file1.pdf', 'all')\n    -&gt;addPDF('path/to/source/file2.pdf', 'all', 'horizontal');\n\n  // call merge, output format `file`\n  $pdf-&gt;merge('file', 'path/to/export/dir/file.pdf');\n?&gt;\n\n\n응용 사용법\n여기서는 파일 업로드 웹페이지를 통해 업로드 된 여러 파일들을 합쳐서 다운로드 받는 방식으로 구현해보겠습니다.\n\n\n&lt;? php\n\n  require 'vendor/autoload.php';\n  \n  $pdf = new \\Jurosh\\PDFMerge\\PDFMerger;\n\n\n  $source_file_array = Array();\n  $source_filename_array = Array();\n\n  $source_file_array = $_FILES[\"pdf_file\"];\n  $source_filename_array = $source_file_array[\"name\"];\n  $upload_filename_array = $source_file_array[\"tmp_name\"];\n\n  $cnt_file = count($source_filename_array);\n\n  for ($i = 0; $i &lt; $cnt_file; $i++)\n  {\n    $pdf-&gt;addPDF($upload_filename_array[$i], 'all', 'vertical');    \n  }\n\n  $output_filename = $source_filename_array[0];\n\n  $pdf-&gt;merge('download', $output_filename);\n?&gt;\n\n\n업로드 된 파일명 배열에 저장\n\n&lt;? php\n\n  $source_file_array = $_FILES[\"pdf_file\"];\n  $source_filename_array = $source_file_array[\"name\"];\n  $upload_filename_array = $source_file_array[\"tmp_name\"];\n?&gt;\n\n\n합칠 파일들 리스트에 추가\n업로드 된 개수 만큼 파일들을 리스트에 추가합니다.\n$pdf-&gt;addPDF의 파라미터에는 옵션으로 페이지와 문서방향이 들어갑니다.\n$pdf-&gt;addPDF(파일경로, 페이지, 문서방향);\n\n\n&lt;? php\n\n  $cnt_file = count($source_filename_array);\n  for ($i = 0; $i &lt; $cnt_file; $i++)\n  {\n    $pdf-&gt;addPDF($upload_filename_array[$i], 'all', 'vertical');    \n  }\n\n  /* 사용 예시\n  $pdf-&gt;addPDF($upload_filename_array[$i], 'all', 'vertical');\n  $pdf-&gt;addPDF($upload_filename_array[$i], '1,3,6', 'horizontal');\n  $pdf-&gt;addPDF($upload_filename_array[$i], '12-16', 'vertical');\n  */\n?&gt;\n\n\n파일 합치기\n합치기 옵션은 [download], [browser], [file], [string] 이렇게 4가지가 있습니다.\n보통 로컬PC로 다운로드 받을 때는 [download], 서버에 저장할 때는 [file]를 선택하면 됩니다.\n\n&lt;? php\n\n  $pdf-&gt;merge('download', $output_filename);\n  $pdf-&gt;merge('browser', $output_filename);\n  $pdf-&gt;merge('file', $output_filename);\n  $pdf-&gt;merge('string', $output_filename);\n?&gt;\n\n\n한글 깨짐 해결\nPDF 파일을 합치면 문서 내의 텍스트는 한글이나 기타 UTF-8 문자들이 문제없이 잘나타납니다.\n그런데 파일명은 UTF-8이 지원되지 않아 한글이 깨지는 현상이 나타납니다.\n\n이를 해결하기 위해서는 여기서 사용한 pdf merger 소스 파일을 수정해야 합니다.\n소스파일 위치는 ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php 입니다.\n\nPDFMerger.php 파일에서 파일 합치기 함수 merge를 찾습니다.\n\n&lt;? php\n\n  /* ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php */\n  \n  /*== 기존 ==*/ \n  public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf') {\n\n    /* ====*/\n    /* 중략 */\n    /* ====*/\n\n    if ($mode == 'S') {\n        return $fpdi-&gt;Output($outputpath, 'S');\n    } else {\n        if ($fpdi-&gt;Output($outputpath, $mode) == '') {\n      return true;\n        } else {\n      throw new Exception(\"Error outputting PDF to '$outputmode'.\");\n      return false;\n        }\n    }\n  }\n\n  /*== 수정 ==*/ \n  public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf') {\n\n    /* ====*/\n    /* 중략 */\n    /* ====*/\n\n    if ($mode == 'S') {\n        return $fpdi-&gt;Output($outputpath, 'S', true);\n    } else {\n        if ($fpdi-&gt;Output($outputpath, $mode, true) == '') {\n      return true;\n        } else {\n      throw new Exception(\"Error outputting PDF to '$outputmode'.\");\n      return false;\n        }\n    }\n  }\n?&gt;\n\n\n\n위에서 바뀐 부분은 Output 함수의 파라미터 하나입니다.\n\n&lt;? php\n  // 기존\n  $fpdi-&gt;Output($outputpath, 'S');\n  $fpdi-&gt;Output($outputpath, $mode);\n  // 수정\n  $fpdi-&gt;Output($outputpath, 'S', true);\n  $fpdi-&gt;Output($outputpath, $mode, true);\n?&gt;\n\n\n\n왜 그런지 실제 Output 함수가 선언된 곳을 찾아가보겠습니다.\n파일 위치는 ./vendor/setasign/fpdf/fpdf.php 입니다.\n아래와 같이 Output 함수의 파라미터는 3개로 마지막이 UTF-8 여부를 설정하는 것이었습니다.\n그러므로 마지막 파라미터를 true 로 설정만 해도 한글, UTF-8 문제가 해결됩니다.\n\n\n&lt;? php\n\n  /* ./vendor/setasign/fpdf/fpdf.php */\n\n  function Output($dest='', $name='', $isUTF8=false)\n  {\n\t/* 중략 */\n  }\n?&gt;\n\n\n문서 속성 추가\n또 하나의 문제가 제목, 작성자, 주제 등의 문서 속성 정보가 추가되지 않는다는 점입니다.\n이 또한 파일 2개를 수정해야 합니다.\n\n문서 합치기 파일 (ex: pdf_merge.php)\n\n&lt;? php\n  // 문서 속성 정보를 추가합니다.\n  $author = \"써드아이시스템\";\n  $creator = \"써드아이시스템\";\n  $title = \"문서 제목\";\n  $subject = \"문서 주제\";\n  $keywords = \"키워드\";\n\n  // merge 함수에 문서 속성 옵션을 추가합니다.\n  $pdf-&gt;merge('download', $output_filename, $author, $creator, $title, $subject, $keywords);\n?&gt;\n\n\nmerge 함수 정의 파일 (PDFMerger.php)\n위치 : ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php\n\n\n&lt;? php\n\n  /* ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php */\n\n  // 파라미터 추가\n  public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf', $author = '3rdEYESYS', $creator = '3rdEYESYS', $title = 'title', $subject = 'subject', $keywords = 'keywords') {\n    \n    /* 중략 */\n\n    // 속성 항목 설정\n    $fpdi-&gt;SetAuthor($author, true);\n    $fpdi-&gt;setCreator($creator, true);\n    $fpdi-&gt;setTitle($title, true);\n    $fpdi-&gt;setSubject($subject, true);\n    $fpdi-&gt;setKeywords($keywords, true);\n  }\n?&gt;\n\n\n문서 속성을 저렇게 설정하면 되는 이유는 해당 함수가 정의된 곳을 찾아보면 알 수 있습니다.\n\n파일 위치는 ./vendor/setasign/fpdf/fpdf.php 입니다.\n\n\n&lt;? php\n\n  /* ./vendor/setasign/fpdf/fpdf.php */\n\n  function SetTitle($title, $isUTF8=false)\n  {\n    // Title of document\n    $this-&gt;metadata['Title'] = $isUTF8 ? $title : utf8_encode($title);\n  }\n\n  function SetAuthor($author, $isUTF8=false)\n  {\n    // Author of document\n    $this-&gt;metadata['Author'] = $isUTF8 ? $author : utf8_encode($author);\n  }\n\n  function SetSubject($subject, $isUTF8=false)\n  {\n    // Subject of document\n    $this-&gt;metadata['Subject'] = $isUTF8 ? $subject : utf8_encode($subject);\n  }\n\n  function SetKeywords($keywords, $isUTF8=false)\n  {\n    // Keywords of document\n    $this-&gt;metadata['Keywords'] = $isUTF8 ? $keywords : utf8_encode($keywords);\n  }\n\n  function SetCreator($creator, $isUTF8=false)\n  {\n    // Creator of document\n    $this-&gt;metadata['Creator'] = $isUTF8 ? $creator : utf8_encode($creator);\n  }\n?&gt;\n\n\n참고 URL\n\n  PDF Merge GitHub Source and Download\n    \n      https://github.com/jurosh/php-pdf-merge\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-05-03"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mysql-mariadb-replication": {
						"id": "5-database-ncp-database-mysql-mariadb-replication",
						"title": "MYSQL(MARIADB) replication 생성하기",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mysql_mariadb_replication/",
						"content": "선행조건\n\n\n  master, slave 장비의 mysql설치가 사전에 완료된 조건\n  mysql 버전 5.7이상 조건에서 작성됨\n  mysql 리플리케이션작업을 진행시 masterdb의 데이터베이스는 쓰기작업이 없는 서비스 미진행 상태이어야함.\n\n\nMASTER 장비 구성\n\nmy.cnf파일 내용 추가\n\n[mysqld]\nlog-bin=mysql-bin\nbinlog_format = mixed\n\n# 해당 ID값은 마스터장비만 1을 설정할수있음\nserver-id = 1 \n\n# 마스터 장비의 bin로그 특정일자(예시는10일) 이후 삭제\n# (해당 내역이없을 경우 지속적으로 기록되어 디스크 사용)\nexpire_logs_days = 10 \n\n\nmysql접속 후 리플리케이션을 진행할 계정 생성\n\nGRANT REPLICATION SLAVE ON *.* TO '리플리케이션계정명'@'%' IDENTIFIED BY '패스워드';\nFLUSH PRIVILEGES;\n\n\nSLAVE 장비 구성\n\nmy.cnf파일 내용 추가\n\n[mysqld]\nserver-id=2 #해당ID값은 1을 제외한 숫자지정\nslave-skip-errors = all  \n\n\n데이터베이스 사전 동기화작업\n\n\n  \n    master장비의 데이터베이스가 생성되어 있고 데이터가 있을 경우\n\n    A. master장비 데이터베이스 백업 진행\n    # 데이터베이스가 추가로 있다면 남은 데이터베이스도 백업\nmysqldump -u root -p --databases 데이터베이스명 &gt; 백업파일.sql \n    \n    \n B. slave장비 데이터베이스 복구 진행\n    create database 데이터베이스명; #mysql 접속 후 생성\nmysql -u root -p 데이터베이스명 &lt; 백업파일.sql  \n    \n    \n  \n  \n    master 장비의 데이터베이스가 없을 경우\n\n    A. 별도 작업 없으며, 데이터베이스만 생성되어 데이터가 없을경우도 slave장비에 동일한 데이터베이스 생성으로 마무리\n  \n\n\n리플리케이션 작업\n\n\n  \n    master 장비 mysql 접속 후 현재 로그파일번호와 포지션 넘버 확인\n\n    show master status;\nfile| Position #내역을 확인 후 별도 기입.\n    \n  \n  \n    slave 장비 mysql 접속 후 아래 명령어 실행 하여 리플리케이션 master정보 기입\n\n    CHANGE MASTER TO MASTER_HOST='마스터IP',MASTER_USER='생성한리플리케이션계정명',MASTER_PASSWORD='패스워드',MASTER_LOG_FILE='위에서확인된 file이름',MASTER_LOG_POS=위에서 확인된 포지션번호;\n    \n  \n  \n    slave 리플리케이션 시작및 확인\n\n    start slave;\nshow slave status\\G; #실행 후 에러가 없다면 정상.\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-04-13"
					}
					
				
			
		
			
				
					,
					
					"99-etc-etc-phpspreadsheet-sample-code": {
						"id": "99-etc-etc-phpspreadsheet-sample-code",
						"title": "PhpSpreadsheet 설정 샘플 코드",
						"categories": "99.ETC",
						"url": " /99.etc/etc_phpspreadsheet_sample_code/",
						"content": "개요\nPHP에서 Excel 문서를 읽거나 Excel 형태로 문서를 저장해야 할 때 주로 PhpSpreadsheet를 사용하게 됩니다. \n이전에는 PHPExcel이라는 이름이었으나 현재는 해당 버전의 개발-유지보수가 중단되고 새로운 프로젝트로 PhpSpreasheet라는 이름으로 업그레이드 되었습니다.\n또한 PhpSpreadsheet는 Excel 뿐만 아니라 PDF 형식으로도 파일을 저장할 수 있어서 많이 사용되고 있습니다. \n이번에는 이 PhpSpreadsheet로 문서를 저장할 때 사용하는 주요 소스 코드의 샘플을 정리해보겠습니다.\n\n클래스 로드\n\n\n&lt;?php\n\n\trequire 'vendor/autoload.php';\n\n\tuse PhpOffice\\PhpSpreadsheet\\IOFactory;\n\tuse PhpOffice\\PhpSpreadsheet\\Spreadsheet;\n\n\t$spreadsheet = new Spreadsheet();\n?&gt;\n\n\n기본 설정\n\n\n&lt;? php\n\n // 문서 가로,세로 방향 설정\t\n $spreadsheet-&gt;getActiveSheet()-&gt;getPageSetup()\n -&gt;setOrientation(\\PhpOffice\\PhpSpreadsheet\\Worksheet\\PageSetup::ORIENTATION_PORTRAIT);\n\n // 문서 사이즈 설정\n $spreadsheet-&gt;getActiveSheet()-&gt;getPageSetup()\n -&gt;setPaperSize(\\PhpOffice\\PhpSpreadsheet\\Worksheet\\PageSetup::PAPERSIZE_A4);\n\n // 문서 정보 설정\n $spreadsheet-&gt;getProperties()-&gt;setCreator(\"써드아이시스템\")\n -&gt;setLastModifiedBy(\"써드아이시스템\")\n -&gt;setTitle(\"문서 타이틀\")\n -&gt;setSubject(\"문서 제목\")\n -&gt;setDescription(\"문서 설명\")\n -&gt;setKeywords(\"키워드\")\n -&gt;setCategory(\"카테고리\");\n\n\n // 문서 좌우 여백 설정\n $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setTop(0.5);\t\n $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setBottom(0.25);\n $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setRight(0.75);\n $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setLeft(0.75);\n?&gt;\n\n\n셀 값 설정\n\n\n&lt;? php\t\n  $spreadsheet-&gt;setActiveSheetIndex(0)-&gt;setCellValue(\"C11\", $value);\n  $spreadsheet-&gt;setActiveSheetIndex(0)-&gt;setCellValue(\"B25\", \"셀 값 설정\\r\\n다음 줄\");\n?&gt;\n\n\n셀에 이미지 설정\n\n\n&lt;? php\n  $drawing_logo = new \\PhpOffice\\PhpSpreadsheet\\Worksheet\\Drawing();\t\n  $drawing_logo-&gt;setName('Logo');\n  $drawing_logo-&gt;setDescription('3rdEYESYS Logo');\n  $drawing_logo-&gt;setPath('/ncp/data/www/img/3rdeyesys_logo.png');\n  $drawing_logo-&gt;setCoordinates('A1');\n  $drawing_logo-&gt;setWidth(230);\n  $drawing_logo-&gt;getShadow()-&gt;setVisible(true);\n  $drawing_logo-&gt;setWorksheet($spreadsheet-&gt;getActiveSheet());\n?&gt;\n\n\n셀 병합\n\n\n&lt;? php\t\n  // 동일한 행에서 병합\n  $spreadsheet-&gt;getActiveSheet()-&gt;mergeCells(\"A1:D1\");\n\n  // 여러 행에서 병합\n  $spreadsheet-&gt;getActiveSheet()-&gt;mergeCells(\"G5:I7\");\n\n  // 변수 사용\n  for ($j = 52; $j &lt;= 57; $j++)\n  {\n    $spreadsheet-&gt;getActiveSheet()-&gt;mergeCells(\"B\".$j.\":C\".$j);\n  }\n?&gt;\n\n\n행 높이 설정\n\n&lt;?php\n\n  for ($j = 1; $j &lt;= 5; $j++)\n  {\n    $spreadsheet-&gt;getActiveSheet()-&gt;getRowDimension($j)-&gt;setRowHeight(12);\n  }\n\n  $spreadsheet-&gt;getActiveSheet()-&gt;getRowDimension(10)-&gt;setRowHeight(35);\n?&gt;\n\n\n열 너비 설정\n\n\n&lt;?php\n\n  // 특정 열 너비 설정\n  $spreadsheet-&gt;getActiveSheet()-&gt;getColumnDimension(\"A\")-&gt;setWidth(3);\n\n  // 범위 내 여러 열 너비 설정\n  foreach(range(\"B\",\"J\") as $columnID) \n  {\n    $spreadsheet-&gt;getActiveSheet()-&gt;getColumnDimension($columnID)-&gt;setWidth(15);\n  }\n?&gt;\n\n\n셀 스타일 지정\n\n\n&lt;?php\n\n  // 셀 스타일을 배열 형식으로 저장\n  // 순서대로 border, font, 배경색 지정하는 스타일\n  $styleArray_Cell = [\n    'borders' =&gt; [\n      'allBorders' =&gt; [\n        'borderStyle' =&gt; \\PhpOffice\\PhpSpreadsheet\\Style\\Border::BORDER_THIN,\n        'color' =&gt; ['argb' =&gt; 'FF20AFA5']\n      ]\n    ],\n    'font' =&gt; [\n      'bold' =&gt; true,\n      'size' =&gt; 9,\n      'color'    =&gt; ['argb' =&gt; 'FFFFFFFF'],\n    ],\n    'fill' =&gt;[\n      'fillType' =&gt; \\PhpOffice\\PhpSpreadsheet\\Style\\Fill::FILL_SOLID,\n      'color' =&gt; ['argb' =&gt; 'FF20AFA5']\n    ]\n  ];\n\n  // 특정 셀에 스타일 적용\n  $spreadsheet-&gt;getActiveSheet()\n  -&gt;getStyle(\"B40\")-&gt;applyFromArray($styleArray_Cell);\n  \n  // 특정 범위의 여러 셀에 스타일 동시 적용\n  $spreadsheet-&gt;getActiveSheet()\n  -&gt;getStyle(\"G45:G46\")-&gt;applyFromArray($styleArray_Cell);\n\n  // 특정 셀에 폰트 스타일 직접 적용\n  $spreadsheet-&gt;getActiveSheet()\n  -&gt;getStyle(\"B80\")-&gt;getFont()-&gt;setSize(13)-&gt;setBold(true);\n\t\n?&gt;\n\n\nPDF 로 저장\n\n\n&lt;?php\n  $spreadsheet-&gt;setActiveSheetIndex(0);\n\n  // Mpdf 클래스 별로 설치해야 함\n  IOFactory::registerWriter('Pdf', \\PhpOffice\\PhpSpreadsheet\\Writer\\Pdf\\Mpdf::class);\n\n  $out_put_file_full_name = \"sample.pdf\";\n\n  // Redirect output to a client’s web browser (PDF)\n  header('Content-Type: application/pdf; charset=utf-8' );\n  header('Content-Disposition: attachment;filename=\"'.$out_put_file_full_name.'\"');\n  header('Cache-Control: max-age=0');\n\n  $writer = IOFactory::createWriter($spreadsheet, 'Pdf');\n  $writer-&gt;save('php://output');\n  exit;\n?&gt;\n\nPhpSpreadsheet를 사용해서 pdf 파일을 저장하려면 Mpdf 를 추가로 설치해야 합니다. \n이와 관련된 내용은 다음 문서에서 다시 정리하겠습니다.\n\nExcel로 저장\n\n\n&lt;?php\n  $spreadsheet-&gt;setActiveSheetIndex(0);\n\n  // Redirect output to a client’s web browser (Excel2007)\n  $out_put_file_full_name = \"sample.xlsx\";\n\n  header('Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet');\n  header('Content-Disposition: attachment;filename=\"'.$out_put_file_full_name.'\"');\n  header('Cache-Control: max-age=0');\n\n  // If you're serving to IE over SSL, then the following may be needed\n  header ('Expires: Mon, 26 Jul 2022 05:00:00 GMT'); // Date in the past\n  header ('Last-Modified: '.gmdate('D, d M Y H:i:s').' GMT'); // always modified\n  header ('Cache-Control: cache, must-revalidate'); // HTTP/1.1\n  header ('Pragma: public'); // HTTP/1.0\n\n  $writer = IOFactory::createWriter($spreadsheet, 'Xlsx');\t\n  $writer-&gt;save('php://output');\n  exit;\n?&gt;\n\n\n참고 URL\n\n  PhpSpreadsheet Documentation\n    \n      https://phpspreadsheet.readthedocs.io/\n    \n  \n  PhpSpreadsheet GitHub Source and Download\n    \n      https://github.com/PHPOffice/PhpSpreadsheet\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-04-14"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-object-storage-transfer-to-archive-storage": {
						"id": "4-storage-ncp-storage-object-storage-transfer-to-archive-storage",
						"title": "Object Storage 데이터를 Archive Storage로 자동으로 이동시키는 방법",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_object_storage_transfer_to_archive_storage/",
						"content": "개요\n네이버 클라우드 Object Storage는 일반 디스크인 Block Storage나 NAS에 비해 가격도 1/2 ~ 1/4정도이면서도 안정적이기 때문에 데이터 저장 특히 백업 용도로 많이 사용합니다.\n그럼에도 불구하고 많이 양의 데이터가 저장되면 비용에 대한 부담이 생길 수 밖에 없는데, 이럴 때 Archive Storage를 이용하면 Object Storage의 1/5정도로 비용이 줄어들기에 매우 효과적입니다.\n그래서 이번에는 Object Storage에 있는 데이터를 Archive Storage로 이동시키는 즉, 이관하는 방법에 대해 정리해보겠습니다.\n\n스토리지 가격 비교\n위 개요에서도 간단하게 설명했지만, Archive Storage는 Object Storage에 비해 비용이 1/5 정도입니다.\n이 두가지 뿐만 아니라 여러 스토리지들의 가격과 용도에 대한 비교는 아래 문서에서 확인할 수 있습니다.\n\nhttps://docs.3rdeyesys.com/4.storage/ncp_storage_compare/\n\n스토리지 용도 구분\nObject Storage와 Archive Storage 2가지 스토리지 모두 데이터를 백업하는 용도로 많이 사용됩니다.\n비슷하기는 하지만 전혀 다르기도 한 2가지 스토리지에 대한 용도를 간단하게 구분해보겠습니다.\n\nObject Storage\n\n  데이터 저장, 삭제가 수시로 이루어지는 경우\n  저장된 데이터에 대한 조회가 빈번한 경우\n  앱을 사용하는 일반 유저들이 앱을 통해 데이터에 접근하는 경우\n  네이버 클라우드의 다른 서비스에서 데이터를 저장, 조회해야 하는 경우\n\n\nArchive Storage\n\n  저장된 데이터에 대한 조회가 거의 없는 경우\n  당장 사용할 일은 없으나 오랜 기간 데이터를 저장해야 하는 경우\n  매우 저렴한 비용으로 데이터를 보관하고 싶은 경우\n\n\n데이터 이관\nObject Storage에 있는 데이터를 자동으로 Archive Storage로 이관하는 방법은 수명주기 관리(LifeCycle Mangement)를 이용하면 됩니다.\n[ 네이버 클라우드 콘솔 - Object Storage - Lifecycle Management - 수명주기 정책 추가 ] 기능을 이용하시면 설정할 수 있습니다.\n\n\n\n수명주기 정책 추가\n수명주기 정책 추가 화면에서 정책 유형은 [이관] 또는 [이관 후 삭제], 관리대상은 Object Storage에 있는 대상 버킷, 이동 위치는 Archive Storage에 있는 버킷을 선택하시면 됩니다.\n이렇게 설정하시면 대상 버킷에 있는 데이터 중에서 이름 규칙에 해당하는 데이터가 Archive Storage로 이동하게 됩니다.\n\n\n\n정책\n정책 유형은 다음의 3가지가 있습니다.\n\n  만료 삭제 : 설정된 기간이 지난 파일을 삭제\n  이관 : 설정된 기간이 지난 파일을 Archive Storage로 이동\n  이관 후 삭제 : 설정된 기간이 지난 파일을 Archive Storage로 이동한 후 Object Storage에서 삭제\n\n\n그리고 이동 시점은 파일이 Object Storage에 저장-생성된 후 경과한 일자를 기준으로 하며 1일 ~ 3,650일 사이의 값을 입력합니다.\n\n\n\n관리대상 (Source)\n관리대상의 버킷(Bucket)을 선택하고 Object 이름의 규칙을 접두어 방식으로 입력합니다.\n\n\n\n이동위치 (Target)\n이동할 위치는 Archive Storage로 고정이며, Archive Storage의 컨테이너(버킷)을 선택하고 세부경로 즉, 폴더를 입력합니다.\n세부경로에 아무것도 입력하지 않으면 Source 즉, Object Storage의 위치, 폴더 구조 그대로 이동됩니다.\n\n\n\n정책 실행 시간\nLifecycle Management의 수명주기 정책 실행시간은 아래와 같습니다.\n\n  01:00~02:00,  07:00~08:00, 13:00~14:00, 19:00~20:00\n (※ 파일용량이 클 경우 일부 변동될 수 있음)\n\n\n예시) 정책 유형(만료 삭제)﻿, 이동 시점(생성 후 1일)로 정책을 생성하고 대상 파일이 15시에 업로드 되었다면 정책실행은 익일 19~20시 사이에 이관 완료\n\n관리대상 이름 규칙\n관리대상인 Object를 이관하는 이름 규칙은 접두어 방식인데 자세한 규칙 설명은 다음 문서를 참고 하시면 됩니다.\n\nhttps://docs.3rdeyesys.com/4.storage/ncp_storage_object_storage_lifecycle_management/\n\n참고 URL\n\n  Object Storage 가이드\n    \n      https://guide.ncloud-docs.com/docs/storage-storage-6-1\n    \n  \n  CentOS에서 mysql DB를 Object Storage로 자동 백업하기\n    \n      /5.database/ncp_database_mysql_object_storage_auto_backup_centos/\n    \n  \n\n\n\n  문서 최종 수정일 : 2021-04-12"
					}
					
				
			
		
			
				
					,
					
					"8-api-ncp-api-call-csharp-sample": {
						"id": "8-api-ncp-api-call-csharp-sample",
						"title": "C#으로 네이버 클라우드 API를 호출하는 샘플 예제",
						"categories": "8.API",
						"url": " /8.api/ncp_api_call_csharp_sample/",
						"content": "개요\n네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 C#으로 호출하는 샘플 예제중에서 핵심인 인증을 위한 암호화 문자열 생성 코드를 정리해보겠습니다.\n\n암호화 샘플 코드\n\npublic string unixTimeStamp;\npublic string ncpAccessKey = \"네이버 클라우드 AccessKey\";\npublic string ncpSecretKey = \"네이버 클라우드 SecretKey\";\t\npublic string apiCallMethod = \"GET\";\npublic string apiServer = \"https://billingapi.apigw.ntruss.com\";\npublic string apiUrl = \"네이버 클라우드 API URL\";\n\npublic string MakeSignature()\n{\n\tstring msgSignature;\n\tstring space = \" \";\n\tstring newLine = \"\\n\";\n\t\n\t// 13자리 유닉스 타임스탬프 설정\n\tDateTime now = DateTime.Now;\n\tDateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0);\n\tdouble totalMilliSeconds = now.Subtract(unixOriginalTime).TotalMilliseconds;\n\tunixTimeStamp = Math.Round(totalMilliSeconds).ToString();\n\n\t// hmac으로 암호화할 문자열 설정\n\tstring message = new StringBuilder()\n\t\t.Append(apiCallMethod)\n\t\t.Append(space)\n\t\t.Append(apiUrl)\n\t\t.Append(newLine)\n\t\t.Append(unixTimeStamp)\n\t\t.Append(newLine)\n\t\t.Append(ncpAccessKey)\n\t\t.ToString();\n\n\t// hmac_sha256 암호화\n\tbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\n\tbyte[] bytes = Encoding.UTF8.GetBytes(message);\n\tusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\n\t{\n\t\tbyte[] hash = sha256.ComputeHash(bytes);\n\t\tmsgSignature = Convert.ToBase64String(hash);\n\t}\n\treturn msgSignature;\n}\n\n\n코드 상세 설명\n\n네이버 클라우드 인증키\npublic string ncpAccessKey = \"네이버 클라우드 AccessKey\";\npublic string ncpSecretKey = \"네이버 클라우드 SecretKey\";\t\n\n\n네이버 클라우드 인증키는 네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n\n\n유닉스 타임스탬프\nDateTime now = DateTime.Now;\nDateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0);\ndouble totalMilliSeconds = now.Subtract(unixOriginalTime).TotalMilliseconds;\nunixTimeStamp = Math.Round(totalMilliSeconds).ToString();\n\n네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요하므로 TotalMilliseconds 값을 가져와서 소수점 아래는 반올림해서 정수값만 취합니다.\n여기서 전달하는 타임스탬프값이 네이버 클라우드 API Gateway의 시간과 5분 이상 차이가 나면 인증 실패가 됩니다.\n그런데 API Gateway는 UTC 기준으로 설정되어 있기 때문에 C#으로 만든 애플리케이션을 로컬PC등의 UTC+9 시간으로 설정된 곳에서 1970년 1월 1일 00시 기준으로 계산하면 9시간의 시간차가 발생해 인증이 실패하게 됩니다.\n정리하면 다음과 같습니다.\n\n  API Gateway 타임스탬프 : UTC 현재시간 - 1970년 1월 1일 00시\n  로컬PC 타임스탬프 : UTC+9 현재시간 - 1970년 1월 1일 09시\n\n\n즉, 로컬PC 등은 API Gateway보다 9시간 빠르기 때문에 동일한 타임스탬프 값을 얻으려면 1970년 1월 1일 09시 기준으로 계산해야 한다는 것입니다.\n그래서 위의 코드에서 DateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0); 이렇게 적용했습니다.\n\nhmac으로 암호화할 문자열 설정\npublic string apiCallMethod = \"GET\";\n\nstring space = \" \";\nstring newLine = \"\\n\";\n\n암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\n\nstring message = new StringBuilder()\n\t.Append(apiCallMethod)\n\t.Append(space)\n\t.Append(apiUrl)\n\t.Append(newLine)\n\t.Append(unixTimeStamp)\n\t.Append(newLine)\n\t.Append(ncpAccessKey)\n\t.ToString();\n\n네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\n\nAPI URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다.\nhttps://api.ncloud-docs.com/docs/ko/home/\n\nhmac_sha256 방식으로 암호화\nbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\nbyte[] bytes = Encoding.UTF8.GetBytes(message);\nusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\n{\n\tbyte[] hash = sha256.ComputeHash(bytes);\n\tmsgSignature = Convert.ToBase64String(hash);\n}\n\nhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\n\n응답 예시\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;getProductPriceListResponse&gt;\n  &lt;requestId&gt;9a6b9f7c-f688-4cec-841f-634d355cef1e&lt;/requestId&gt;\n  &lt;returnCode&gt;0&lt;/returnCode&gt;\n  &lt;returnMessage&gt;success&lt;/returnMessage&gt;\n  &lt;totalRows&gt;2&lt;/totalRows&gt;\n  &lt;productPriceList&gt;\n    &lt;productPrice&gt;\n      &lt;productItemKind&gt;\n        &lt;code&gt;VSVR&lt;/code&gt;\n        &lt;codeName&gt;Server (VPC)&lt;/codeName&gt;\n      &lt;/productItemKind&gt;\n      &lt;productItemKindDetail&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productItemKindDetail&gt;\n     ''' 중략 '''\n      &lt;softwareType/&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productTypeDetail/&gt;\n      &lt;gpuCount&gt;0&lt;/gpuCount&gt;\n      &lt;cpuCount&gt;24&lt;/cpuCount&gt;\n      &lt;memorySize&gt;137438953472&lt;/memorySize&gt;\n      &lt;baseBlockStorageSize&gt;4123168604160&lt;/baseBlockStorageSize&gt;\n      &lt;dbKind/&gt;\n      &lt;osInfomation/&gt;\n      &lt;platformType/&gt;\n      &lt;osType/&gt;\n      &lt;platformCategoryCode/&gt;\n      &lt;diskType&gt;\n        &lt;code&gt;LOCAL&lt;/code&gt;\n        &lt;codeName&gt;Local storage&lt;/codeName&gt;\n      &lt;/diskType&gt;\n      &lt;diskDetailType&gt;\n        &lt;code&gt;SSD&lt;/code&gt;\n        &lt;codeName&gt;SSD&lt;/codeName&gt;\n      &lt;/diskDetailType&gt;\n      &lt;generationCode&gt;G1&lt;/generationCode&gt;     \n    ''' 중략 '''\n  &lt;/productPriceList&gt;\n&lt;/getProductPriceListResponse&gt;\n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ko/home/\n\n\n  “문서 최종 수정일 : 2021-04-07”"
					}
					
				
			
		
			
				
					,
					
					"8-api-ncp-api-call-php-sample": {
						"id": "8-api-ncp-api-call-php-sample",
						"title": "PHP로 네이버 클라우드 API를 호출하는 샘플 예제",
						"categories": "8.API",
						"url": " /8.api/ncp_api_call_php_sample/",
						"content": "개요\n네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 PHP로 호출하는 샘플 예제를 정리해봅니다.\n네이버 클라우드 API는 RESTful API 방식으로 제공되며, XML와 JSON 형식으로 응답합니다\n우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\nAPI 호출 샘플 코드\n\n&lt;?php\n\t\n\t// 기본 데이터 설정\n\t$unixtimestamp =  round(microtime(true) * 1000);\n\n\t$ncp_accesskey = \"네이버 클라우드 AccessKey\";\n\t$ncp_secretkey = \"네이버 클라우드 SecretKey\";\t\n\n\t$api_server = \"https://billingapi.apigw.ntruss.com\";\n\n\t// API URL 예시 : 상품별 가격 리스트 호출 api\n\t$api_url = \"/billing/v1/product/getProductPriceList\";\n\t$api_url = $api_url.\"?regionCode=KR&amp;productItemKindCode=VSVR\";\n\n\t$apicall_method = \"GET\";\n\t$space = \" \";\n\t$new_line = \"\\n\";\n\n\t$is_post = false;\n\n\t// hmac으로 암호화할 문자열 설정\n\t$message = \n\t\t$apicall_method\n\t\t.$space\n\t\t.$api_url\n\t\t.$new_line\n\t\t.$unixtimestamp\n\t\t.$new_line\n\t\t.$ncp_accesskey;\t\n\t\n\t// hmac_sha256 암호화\n\t$msg_signature = hash_hmac(\"sha256\", $message, $ncp_secretkey, true);\n\t$msg_signature = base64_encode($msg_signature);\n\n\t// http 호출 헤더값 설정\n\t$http_header = array();\n\t$http_header[0] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\n\t$http_header[1] = \"x-ncp-iam-access-key:\".$ncp_accesskey.\"\";\n\t$http_header[2] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\n\n\t// api 호출\n\t$ch = curl_init();\n\tcurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n\tcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n\tcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n\tcurl_setopt($ch, CURLOPT_POST, $is_post);\n\tcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n\n\t$response = curl_exec($ch);\n\n\tcurl_close($ch);\n\n?&gt;\n\n\n코드 상세 설명\n\n유닉스 타임 스탬프\n$unixtimestamp =  round(microtime(true) * 1000);\n\n네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요합니다.\nPHP에서 일반적으로 사용하는 time()함수는 10자리 형식이기 때문에 여기서는 microtime()을 사용합니다.\nmicrotime(true)은 float 형식의 값을 리턴하므로 1000을 곱하고 정수로 반올림합니다.\n\n$val1 = time();\n$val2 = microtime(true);\n$val3 = round(microtime(true) * 1000);\n\n/*\n$val1 : 1617699570\n$val2 : 1617699570.1146\n$val3 : 1617699570115\n*/\n\n\n네이버 클라우드 인증키\n$ncp_accesskey = \"네이버 클라우드 AccessKey\";\n$ncp_secretkey = \"네이버 클라우드 SecretKey\";\t\n\n\n네이버 클라우드 인증키는 네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n\nhmac으로 암호화할 문자열 설정\n$apicall_method = \"GET\";\n$space = \" \";\n$new_line = \"\\n\";\n\n암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\n\n$message = \n\t$apicall_method\n\t.$space\n\t.$api_url\n\t.$new_line\n\t.$unixtimestamp\n\t.$new_line\n\t.$ncp_accesskey;\t\n\n네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\n\nAPI URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다.\nhttps://api.ncloud-docs.com/docs/ko/home/\n\nhmac_sha256 방식으로 암호화\n$msg_signature = hash_hmac(\"sha256\", $message, $ncp_secretkey, true));\n$msg_signature = base64_encode($msg_signature);\n\nhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 $message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\n\nhttp 호출 헤더값 설정\n$http_header = array();\n$http_header[0] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\n$http_header[1] = \"x-ncp-iam-access-key:\".$ncp_accesskey.\"\";\n$http_header[2] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\n\nAPI를 호출할 때는 http 헤더값에 다음 3가지를 추가해서 호출합니다.\n\n  유닉스 타임스탬프\n  네이버 클라우드 API AccessKey\n  hmac_256 으로 암호화한 문자열\n\n\n여기서 전송하는 타임스탬프는 위에서 $message를 암호화할 때 사용한 타임스탬프와 동일한 값이어야 합니다.\n\napi 호출\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\ncurl_setopt($ch, CURLOPT_POST, $is_post);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n\n$response = curl_exec($ch);\n\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\n리턴값은 호출하는 용도별로 json 또는 xml 형태로 반환됩니다.\n\n응답 예시\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;getProductPriceListResponse&gt;\n  &lt;requestId&gt;9a6b9f7c-f688-4cec-841f-634d355cef1e&lt;/requestId&gt;\n  &lt;returnCode&gt;0&lt;/returnCode&gt;\n  &lt;returnMessage&gt;success&lt;/returnMessage&gt;\n  &lt;totalRows&gt;2&lt;/totalRows&gt;\n  &lt;productPriceList&gt;\n    &lt;productPrice&gt;\n      &lt;productItemKind&gt;\n        &lt;code&gt;VSVR&lt;/code&gt;\n        &lt;codeName&gt;Server (VPC)&lt;/codeName&gt;\n      &lt;/productItemKind&gt;\n      &lt;productItemKindDetail&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productItemKindDetail&gt;\n     ''' 중략 '''\n      &lt;softwareType/&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productTypeDetail/&gt;\n      &lt;gpuCount&gt;0&lt;/gpuCount&gt;\n      &lt;cpuCount&gt;24&lt;/cpuCount&gt;\n      &lt;memorySize&gt;137438953472&lt;/memorySize&gt;\n      &lt;baseBlockStorageSize&gt;4123168604160&lt;/baseBlockStorageSize&gt;\n      &lt;dbKind/&gt;\n      &lt;osInfomation/&gt;\n      &lt;platformType/&gt;\n      &lt;osType/&gt;\n      &lt;platformCategoryCode/&gt;\n      &lt;diskType&gt;\n        &lt;code&gt;LOCAL&lt;/code&gt;\n        &lt;codeName&gt;Local storage&lt;/codeName&gt;\n      &lt;/diskType&gt;\n      &lt;diskDetailType&gt;\n        &lt;code&gt;SSD&lt;/code&gt;\n        &lt;codeName&gt;SSD&lt;/codeName&gt;\n      &lt;/diskDetailType&gt;\n      &lt;generationCode&gt;G1&lt;/generationCode&gt;     \n    ''' 중략 '''\n  &lt;/productPriceList&gt;\n&lt;/getProductPriceListResponse&gt;\n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ko/home/\n\n\n  “문서 최종 수정일 : 2021-04-07”"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-cloud-functions-php-smtp-via-gmail-with-phpmailer": {
						"id": "1-compute-ncp-server-cloud-functions-php-smtp-via-gmail-with-phpmailer",
						"title": "Cloud Functions에서 PHPMailer를 사용하여 gmail을 통해 SMTP로 메일 발송하는 방법",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_cloud_functions_php_smtp_via_gmail_with_phpmailer/",
						"content": "개요\n네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어중에서 PHP를 이용하여 SMTP로 메일을 발송하는 방법을 소개하려고 합니다.\n메일 발송을 위한 솔루션은 PHPMailer를 이용하고, 발송 서버는 gmail을 이용하는 과정을 정리해보겠습니다.\n\nPHPMailer 다운로드\nPHP에서 SMTP를 이용한 메일을 발송하려고 할 때 흔히 사용하는 것이 PHPMailer입니다.\nPHPMailer는 GitHub에 있는 사이트로 가서 Code를 선택하고 Download ZIP을 클릭하면 다운받을 수 있습니다.\n일반적인 Linux서버에서 사용하는 경우라면 composer를 이용해서 설치하면 되겠지만 Cloud Functions에는 zip 파일로 소스코드를 업로드 해야 하기에 다운로드 받겠습니다.\n\nhttps://github.com/PHPMailer/PHPMailer\n\n\n\n다운받은 zip파일을 압축해제하면 아래와 같은 파일과 폴더를 확인할 수 있는데 여기서는 src, language 두 폴더만 사용합니다.\n\n\n\n메일발송 코드 작성\nPHPMailer에서 제공하는 샘플코드를 참고해서 꼭 필요한 코드만 적었습니다. 파일은 index.php로 저장합니다.\n\n추가로 필요한 코드가 있으면 아래 링크에 있는 PHPMailer 샘플코드를 참고하시면 되겠습니다.\n\nhttps://github.com/PHPMailer/PHPMailer/blob/master/examples/gmail.phps\n\n&lt;?php\n\n\tuse PHPMailer\\PHPMailer\\PHPMailer;\n\tuse PHPMailer\\PHPMailer\\SMTP;\n\tuse PHPMailer\\PHPMailer\\Exception;\n\n\trequire 'src/Exception.php';\n\trequire 'src/PHPMailer.php';\n\trequire 'src/SMTP.php';\n\n\tfunction main(array $args) : array\n\t{\n\t\t$gmail_user_name = 'gmail 계정';\n\t\t$gmail_app_password = '앱 비밀번호';\n\n\t\t$from_name = '발신자 이름';\t\n\t\t$from_email = '발신자 메일주소';\n\t\t\n\t\t$to_name = $args[\"to_name\"] ?? $from_name;  //수신자 이름\n\t\t$to_email = $args[\"to_email\"] ?? $from_email;  //수신자 메일주소\n\t\t\n\t\t$result = \"\";\n\t\t$result_msg = \"\";\n\n\t\ttry \n\t\t{\n\t\t\t$mail = new PHPMailer();\n\n\t\t\t$mail-&gt;isSMTP();\n\n\t\t\t$mail-&gt;SMTPDebug = SMTP::DEBUG_SERVER;\n\t\t\t$mail-&gt;Host = 'smtp.gmail.com';\n\t\t\t$mail-&gt;Port = 587;\n\t\t\t$mail-&gt;SMTPSecure = PHPMailer::ENCRYPTION_STARTTLS;\n\t\t\t$mail-&gt;SMTPAuth = true;\n\t\t\t\n\t\t\t$mail-&gt;setLanguage(\"ko\", \"language/\");\n\t\t\t$mail-&gt;CharSet = PHPMailer::CHARSET_UTF8;\n\n\t\t\t$mail-&gt;Username = $gmail_user_name;\n\t\t\t$mail-&gt;Password = $gmail_app_password;\n\n\t\t\t$mail-&gt;setFrom($from_email, $from_name);\n\t\t\t$mail-&gt;addAddress($to_email, $to_name);\n\t\t\t$mail-&gt;Subject = 'PHPMailer GMail SMTP test';\n\t\t\t$mail-&gt;Body = 'Cloud Functions에서 PHPMailer로 발송한 메일';\n\n\t\t\tif (!$mail-&gt;send()) \n\t\t\t{\t\t\t\t\t\n\t\t\t\t$result = \"fail\";\n\t\t\t\t$result_msg = $mail-&gt;ErrorInfo;\t\t\n\t\t\t} \n\t\t\telse \n\t\t\t{\n\t\t\t\t$result = \"success\";\n\t\t\t\t$result_msg = 'Message sent!';\t\t\t\t\t\n\t\t\t}\n\t\t}\n\t\tcatch(Exception $e)\n\t\t{\n\t\t\t$result = \"error\";\n\t\t\t$result_msg = $e-&gt;getMessage();\n\t\t}\n\n\t\treturn [$result =&gt; $result_msg];\n\t}\n?&gt;\n\n\n\n  보안 이슈 : 위 소스코드에서 알아보기 쉽게 password 라는 변수명을 사용하기는 했지만, \n여러 상황에서 해킹 관련 이슈(예: grep 명령어를 사용해 password 정보가 포함된 파일 검색)가 발생할 수 있으니 실제 서비스에서는 password 라는 단어 대신에 다른 단어를 사용하기를 추천 드립니다. \n$gmail_app_password 뿐만 아니라 $mail-&gt;Password 가 포함된 PHPMailer.php 소스도 함께 수정하시면 더욱 안전할 수 있습니다.\n\n\n\n앱 비밀번호\n위 소스코드에서 gmail에 로그인할 계정과 비밀번호를 적는 부분에서 앱 비밀번호를 관심있게 보셔야 합니다.\n\n$gmail_user_name = 'gmail 계정';\n$gmail_app_password = '앱 비밀번호';\n\n외부앱이나 서버에서 gmail 즉 google 계정에 로그인 인증을 하려면 2단계 인증을 설정하고, 앱 비밀번호를 생성해서 사용해야 합니다. \n예전에는 보안 수준이 낮은 앱의 액세스 허용 옵션으로 가능했었지만, 지금은 그렇게 하면 인증이 실패하는 경우가 많습니다. \n앱 비밀번호 설정하는 방법은 아래 링크를 참고하시면 되겠습니다.\n\nhttps://docs.3rdeyesys.com/99.etc/etc_smtp_auth_to_google_gmail_account/\n\nCloud Functions 함수와 파라미터\n이번 메일 발송 기능 함수는 메일 수신자 이름과 메일 주소를 json 형식의 파라미터로 전달 받고, 결과를 json 형식으로 리턴하는 구조로 되어 있습니다. \n아래와 같이 만약 파라미터가 없을 경우에는 발신자 이름과 메일주소와 동일한 기본값으로 설정했습니다.\n\nfunction main(array $args) : array\n{\n\t$to_name = $args[\"to_name\"] ?? $from_name;  //수신자 이름\n\t$to_email = $args[\"to_email\"] ?? $from_email;  //수신자 메일주소\n\n\treturn [$result =&gt; $result_msg];\n}\n\n\n디버깅 레벨 설정\n메일 발송 코드가 실행되는 과정에 여러 오류가 발생할 수 있는데, 오류가 발생했을 때 오류 메시지를 확인할 수 있도록 디버깅 레벨을 다음 코드로 설정하고 있습니다.\n테스트가 끝나고 실제 서비스에 사용할 때는 DEBUG_OFF 옵션으로 변경하시기 바랍니다.\n\n$mail-&gt;SMTPDebug = SMTP::DEBUG_SERVER;\n\n//SMTP::DEBUG_OFF = off (for production use)\n//SMTP::DEBUG_CLIENT = client messages\n//SMTP::DEBUG_SERVER = client and server messages\n//SMTP::DEBUG_CONNECTION =  As DEBUG_SERVER plus connection status\n//SMTP::DEBUG_LOWLEVEL = Low-level data output, all messages\n\n\n언어와 CharSet 설정\n코드가 실행되면서 나타날 수 있는 각 종 오류메시지를 표시할 언어와 메일 내용의 CharSet을 설정하는 코드입니다.\n\n$mail-&gt;setLanguage(\"ko\", \"language/\");\n$mail-&gt;CharSet = PHPMailer::CHARSET_UTF8;\n\n\n소스코드 Zip 파일로 압축\n위에서 작성한 소스코드를 index.php로 저장하고 클래스 파일들이 들어있는 src 폴더와 언어 파일이 들어있는 laguage 파일과 함께 zip 파일로 압축합니다.\n\n\n\n\n\nCF 이용신청\n네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\n\n\n\nCF Action 생성\n\n액션 생성\n버튼을 선택해 액션을 생성합니다.\n\n\n\n트리거 선택\n액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n\n\n\n이름 입력\n액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n\n\n\n소스코드 언어 선택\n소스코드 언어 중에서 php는 7.1, 7.3이 있는데 둘 중에 편하신대로 선택하시면 됩니다.\n\n\n\n소스코드 업로드\n소스코드 타입은 코드 직접 입력과 파일 업로드가 가능한데, 앞에서 만든 소스코드를 선택하고 업로드 합니다.\n\n\n\n\n소스코드가 업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\n\n\n\nVPC 연결 정보 선택\nVPC 환경에서는 연결할 VPC와 Subnet을 선택해야 합니다. Classic 환경에서는 다음 단계인 [옵션 설정]으로 바로 이동하시면 됩니다.\n\n\n\nVPC 생성\n혹시 VPC를 생성하지 않았거나 새로운 VPC에서 실행하려고 할 경우에는 VPC생성 버튼을 클릭해서 새 창에서 VPC를 생성합니다.\nVPC는 논리적으로 격리된 네트워크 공간을 뜻하며, IP 주소 범위는, private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n\nhttps://console.ncloud.com/vpc-network/vpc\n\n\n\nSubnet 생성\n사용할 수 있는 Subnet이 없거나 새로 생성할 경우 Subnet 생성 버튼을 클릭합니다.\n이름은 알아보기 쉽게 [ cf-phpmailer-smtp-subnet ]으로 입력했습니다.\nSubnet의 IP 주소 범위는 VPC 주소 범위 이하로만 지정이 가능하며, private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n위에서 VPC IP주소 범위가 [ 192.168.0.0/16 ]이었기에 Subnet IP주소 범위는 [ 192.168.0.0/24 ]로 설정했습니다.\n\n여기서 중요한 것이 [Ineteget Gateway 전용여부] 항목입니다. \nCloud Functions는 Private Subnet에서만 작동하므로 N (Private)을 선택하셔야 합니다.\n용도는 일반으로 선택하시면 됩니다.\n\nhttps://console.ncloud.com/vpc-network/subnet\n\n\n\nNAT Gateway 생성\n위에서 생성한 Subnet이 Private이기 때문에 Cloud Functions으로 메일을 발송 즉, 외부와 통신을 하기 위해서는 NAT Gateway를 만들고 적용해주어야 합니다.\n이름은 [ cf-phpmailer-smtp-natgateway ]로 입력했습니다.\n\nhttps://console.ncloud.com/vpc-network/natgw\n\n\n\nRoute Table 설정\n이제 Cloud Functions이 속한 Subnet이 NAT Gateway를 거쳐서 외부로 나갈 수 있도록 Route Table을 설정합니다.\nVPC를 만들때 자동으로 생성된 2개의 Route Table중에서 private table을 선택하고 연관 Subnet 탭을 보시면 위에서 생성했던 [ cf-phpmailer-smtp-subnet ]을 확인할 수 있습니다.\n\nhttps://console.ncloud.com/vpc-network/routeTable\n\n\n\n이제 Routes 생성 버튼을 클릭하고 설정 값들을 입력, 선택하고 생성 버튼을 클릭합니다.\n\n  Destination : 0.0.0.0/0 입력\n  Target Type : NATGW 선택\n  Target Name : cf-phpmailer-smtp-natgateway 선택\n\n\n\n\n생성 버튼을 클릭하고 나면 설정이 추가된 것을 확인할 수 있습니다. 이제 확인 버튼을 클릭해서 창을 닫습니다.\n\n\n창을 닫고 나면 설정이 추가된 것을 Routes 탭에서 확인할 수 있습니다.\n\n\nVPC관련 설정이 끝났으면 이전 창으로 돌아가서 다음 단계인 [ 옵션 설정 ]을 확인하시면 됩니다.\n\n옵션 설정\n실행할 Main 함수의 이름은 main으로 그대로 두시고, 액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n\n\n\n생성 완료\n디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\n\n\n\nCF Action 실행\n이제 생성된 액션을 실행해보겠습니다.\n액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n\n\n\n\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고,\n오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n\n\n\n\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다.  파라미터는 json 형태로 입력하면 됩니다.\n왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n\n\n\n\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n\n\n\n발송메일 확인\n메일함에서 확인해보면 이렇게 메일이 무사히 도착한 것을 확인할 수 있습니다.\n\n\n\n오류 메시지\n위에서 앱 비밀번호를 사용해야 한다고 했는데 혹시 앱 비밀번호를 사용하지 않았을 경우 다음과 같은 오류 메시지가 나타나는 경우가 있습니다.\n\nThe SMTP server requires a secure connection or the client was not authenticated.\nThe server response was: 5.7.0 Authentication Required.\n\n\n이 문제, 인증 오류 메시지를 해결하려면 아래 내용대로 설정을 하시면 해결됩니다.\n\nhttps://docs.3rdeyesys.com/99.etc/etc_smtp_auth_to_google_gmail_account/\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-15-2-6.html\n\n\n  문서 최종 수정일 : 2021-03-22"
					}
					
				
			
		
			
				
					,
					
					"99-etc-etc-smtp-auth-to-google-gmail-account": {
						"id": "99-etc-etc-smtp-auth-to-google-gmail-account",
						"title": "Gmail을 이용하여 smtp 메일 발송할 때 인증오류 해결 방법",
						"categories": "99.ETC",
						"url": " /99.etc/etc_smtp_auth_to_google_gmail_account/",
						"content": "개요\n웹서버나 애플리케이션 등에서 gmail 계정을 이용해서 smtp로 메일을 발송하는 경우가 있습니다.\n관리자의 안내 메일이나 소수회원을 위한 다량메일 발송등을 하는 것이 그런 경우인데\n예전에는 보안 수준이 낮은 앱의 액세스 허용 옵션으로 가능했었지만, 최근에는 이 설정으로도 해결되지 않는 경우가 많습니다.\n\n이럴 때 확실하게 인증할 수 있는 방법이 구글계정 2단계 인증 사용과 앱 비밀번호 설정입니다.\n\n인증 오류 메시지\n위에서 이야기한 2단계 인증과 앱 비밀번호를 사용하지 않고 smtp로 구글계정에 로그인 하려고 하면 다음과 같은 오류 메시지가 나타나는 경우가 있습니다.\n\nThe SMTP server requires a secure connection or the client was not authenticated.\nThe server response was: 5.7.0 Authentication Required.\n\n\n이 문제, 인증 오류 메시지를 해결하려면 아래 내용대로 설정을 하시면 해결됩니다.\n\n2단계 인증\n2단계 인증이란 구글계정에 로그인 할 때 아이디와 비밀번호 외에 추가로 인증 절차를 거쳐 로그인을 인증하는 것을 말합니다.\n2단계 인증 방법에는 다음과 같은 종류가 있습니다.\n\n\n  Google 메시지\n  앱 비밀번호\n  백업 코드\n  백업 전화\n  휴대전화 내장 보안 키\n\n\n인증 설정하기\n우선 구글계정으로 로그인해서 계정-보안 메뉴로 이동합니다.\n보안 메뉴에서 [Google에 로그인]이라는 곳에 보면 [2단계 인증] 메뉴가 있습니다. \n현재는 사용 안함으로 설정되어 있는데 클릭해서 설정을 시작합니다.\n\nhttps://myaccount.google.com/security\n\n\n\n2단계 인증에 대한 기본적인 안내와 함께 설정이 시작됩니다.\n\n\n\n2단계 로그인할 때 메시지를 받을 기기가 나타납니다. 또는 보안 키 장치나 다른 방법을 옵션으로 선택할 수 있습니다.\n\n\n\n로그인을 하고 나면 관련 메시지가 앞 단계에서 선택한 장치에 도착합니다. 저는 휴대폰을 선택했기에 Gmail 앱을 확인해보겠습니다.\n\n\n\n이렇게 휴대폰의 Gmail 앱을 열면 안내 메시지가 도착해있고, [예] 버튼을 선택하면 됩니다.\n\n\n\n휴대폰에서 [예]를 선택하면 설정화면이 자동으로 다음으로 넘어와 있습니다.\n여기서는 백업 옵션에 대한 방법을 선택합니다. 저는 문자 메시지를 선택했습니다.\n\n\n\n잠시 후에 휴대폰 문자메시지로 [국외발신] G-254796(이)가 Google 인증코드입니다. 라는 메시지가 도착합니다.\n이 중에서 뒤에 있는 6자리 숫자 코드를 입력하면 됩니다.\n\n\n\n이제 마지막으로 2단계 인증을 사용할 것인지 최종 확인을 합니다. [사용 설정] 버튼을 클릭하시면 2단계 인증이 적용됩니다.\n\n\n\n적용된 2단계 인증에 대한 안내화면입니다. Google 메시지가 2단계 인증 기본값으로 설정되어 있고, 그 외에 음성 또는 문자 메시지도 이용 가능하다는 내용입니다.\n이제 위쪽에 있는 뒤로 돌아가기 버튼을 클릭해서 메인화면으로 돌아갑니다.\n\n\n\n메인화면으로 돌아가면 2단계 인증이 사용으로 설정된 것을 확인할 수 있고, 그 아래에 앱 비밀번호 항목이 새로 생긴 것을 알 수 있습니다.\n\n\n\n앱 비밀번호 설정\n앱 비밀번호 설정을 시작하면 어떤 앱에서 사용할 것인지, 기기는 어떤 것인지 선택하는 화면이 나옵니다.\n메일, 캘린더, 연락처, Youtube 등이 있는데 저희는 Smtp를 할 것이기 때문에 기타(맞춤 이름)을 선택합니다.\n\n\n\n기타를 선택하면 기기선택은 필요없기 때문에 앱 이름만 원하는대로 입력합니다. 여기서는 Smtp Client라고 입력하고 생성 버튼을 클릭합니다.\n\n\n\n드디어 16자리 앱 비밀번호가 생성되었습니다.  이 번호를 반드시 복사해서 따로 저장을 하고 확인 버튼을 클릭합니다.\n\n\n\n앱 비밀번호 화면에서는 현재 생성된 비밀번호를 삭제하거나 추가 할 수 있습니다.\n\n\n\n다시 계정 보안 메인 화면으로 돌아오면 앱 비밀번호 1개가 설정되었다는 것을 확인할 수 있습니다.\n\n\n\n앱 비밀번호 적용\n그러면 smtp 소스코드에서 어떻게 앱 비밀번호를 적용하는지 확인해보겠습니다.\n\nPHP\n$mail = new PHPMailer();\n$mail-&gt;IsSMTP();\n$mail-&gt;SMTPAuth = true;\n$mail-&gt;SMTPSecure = \"tls\";\n$mail-&gt;Host = \"smtp.gmail.com\";\n$mail-&gt;Port = 587;\n$mail-&gt;Username = \"Gmail 계정\";\n$mail-&gt;Password = \"앱 비밀번호\";\n\n\n.Net C#\nSmtpClient client = new SmtpClient(\"smtp.gmail.com\", 587);\nclient.UseDefaultCredentials = false;\nclient.EnableSsl = true;\nclient.DeliveryMethod = SmtpDeliveryMethod.Network;\nclient.Credentials = new System.Net.NetworkCredential(\"Gmail 계정\", \"앱 비밀번호\");\n\n\n이렇게 기존에 gmail 계정 비밀번호를 입력하던 곳에 앱 비밀번호를 입력하면 문제없이 잘 접속됩니다.\n\n기타 사항\n앱 비밀번호는 PC에서 Outlook으로 gmail을 연동할 때 등 여러 경우에 아래와 같이 설정해서 사용할 수 있습니다.\n\n\n\n그리고 2단계 인증을 사용하게 되면 기존의 “보안 수준이 낮은 앱의 액세스” 설정을 사용할 수 없습니다.\n\n\n\n\n  문서 최종 수정일 : 2021-03-16"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-cloud-functions-dotnet-csharp-vs": {
						"id": "1-compute-ncp-server-cloud-functions-dotnet-csharp-vs",
						"title": "Cloud Functions Action을 .Net (C#)을 사용하여 Visual Studio에서 만드는 방법",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_cloud_functions_dotnet_csharp_vs/",
						"content": "개요\n네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어로는 Node.js, Python, Java, Swift, PHP, .Net, Go Language 등이 있는데\n다른 언어들은 네이버 클라우드 콘솔에서 직접 코드를 입력하면 되지만, Java는 로컬에서 작업 후 jar 파일로 .Net은 zip 파일로 압축해서 따로 등록해야 합니다.\n여기서는 Visual Studio에서 .Net 그 중에서도 C#으로 Action을 만들고 zip 파일로 압축 후에 콘솔에 등록하고 테스트 하는 과정까지 정리해보겠습니다.\n\n.Net 설치\n네이버 클라우드 Cloud Functions는 .Net Standard 2.0 규격을 요구하는데, 이 규격을 지원하는 버전을 설치하려면 .Net 5.0 또는 .Net Core 2.1 이상을 설치하면 됩니다.\n가장 간단한 방법은 Visual Studio를 설치하는 방법이고 그 외에는 .Net 또는 .Net Core SDK만 별도로 설치하는 방법이 있습니다.\n여기서는 Visual Studio를 이용할 것이기 때문에 Visual Studio를 설치하면 됩니다.\n\n\n  Visual Studio 무료버전 : https://visualstudio.microsoft.com/ko/free-developer-offers/\n  .Net, .Net Core SDK : https://dotnet.microsoft.com/download\n\n\n프로젝트 생성\n\n프로젝트 템플릿 선택\nVisual Studio에서 제공하는 템플릿 중에서 C# Class library를 선택하니다.\n\n\n\n프로젝트 구성\n프로젝트 이름과 저장 위치 등을 입력합니다. \n여기서는 CloudFunctionsTestVisualStudio 라는 이름으로 시작합니다.\n\n\n\n대상 프레임워크 지정\n대상 프레임워크는 .NET Standard 2.0으로 지정합니다.\n\n\n\n프로젝트 생성 후에 CloudFunctionsTestVisualStudio.csproj 파일을 열어보면 TargetFramework 값이 netstandard2.0으로 되어 있는 것을 확인할 수 있습니다.\n\n\n\njson 패키지 설치\n네이버 클라우드 Cloud Functions은 json 형식으로 파라미터를 입력받고 결과를 출력하기 때문에 NuGet 패키지 관리자를 이용해서 json 패키지를 설치합니다.\n\n프로젝트 선택하고 마우스 오른쪽 버튼을 클릭해서 NuGet 패키지 관리 메뉴를 선택합니다.\n\n\n\nNuGet 패키지 관리자 화면에서 json을 검색하고 Newtonsoft.Json 패키지를 선택, 설치를 합니다.\n\n\n\n\n\n패키지 설치가 완료된 상태입니다.\n\n\n\nHello.cs 작성\n이제 name이라는 파라미터를 json 형태로 받아서 출력해주는 Hello.cs 스크립트를 작성합니다.\n\nusing System;\nusing Newtonsoft.Json.Linq;\n\nnamespace CloudFunctionsTestConsole\n{\n    public class Hello\n    {\n        public JObject Main(JObject args)\n        {\n            string name = \"no name\";\n            if (args.ContainsKey(\"name\")) {\n                name = args[\"name\"].ToString();\n            }\n            JObject message = new JObject();\n            message.Add(\"greeting\", new JValue($\"Hello, {name}!\"));\n            return (message);\n        }\n    }\n}\n\n\n\n\n프로젝트 게시\n이제 위에서 작성한 스크립트를 게시하고, zip 파일로 압축합니다.\n여기서 만든 zip 파일을 네이버 클라우드 콘솔에서 등록하게 됩니다.\n\n[빌드]-[게시] 메뉴를 선택합니다.\n\n\n게시 대상은 폴더를 선택합니다.\n\n\n\n\n게시할 준비가 되었고 게시를 시작합니다.\n\n\n게시가 완료되었습니다.\n\n\n게시된 폴더에 가보면 .nupkg 파일이 생성되는데 저희는 이것을 이용하지 않고 상위 폴더에 있는 dll 파일을 사용합니다.\n\n\n\npublish 상위 폴더에 가면 .deps.json, .dll, .pdb 이렇게 3개 파일이 생성되어 있는 것을 확인할 수 있는데 Cloud Functions에서는 이 파일을 사용합니다.\n\n\n\n파일 압축\n탐색기에서 3개의 파일을 선택하고 압축합니다.\n\n\n\n\n\nCF 이용신청\n네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\n\n\n\nCF Action 생성\n\n액션 생성\n버튼을 선택해 액션을 생성합니다.\n\n\n\n트리거 선택\n액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n\n\n\n이름 입력\n액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n\n\n\n소스코드 언어 선택\n소스코드 언어 중에서 저희는 dotnet:2.2를 선택합니다.\n\n\n\n소스코드 업로드\n소스코드 타입은 코드와 파일이 있지만, java와 .Net은 파일 업로드만 가능합니다.\n앞에서 만든 소스코드를 선택하고 업로드 합니다.\n\n\n\n\n소스코드가업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\n\n\n\nVPC 연결 정보 선택\nVPC 환경에서는 연결할 VPC와 Subnet을 선택해야 합니다. Classic 환경에서는 다음 단계로 바로 이동하시면 됩니다.\n\n\n\n옵션 설정\n실행할 Main 함수의 이름을 {Assembly}::{Class Full Name}::{Method} 형태의 풀네임으로 입력합니다. \n위에서 만든 Hello.cs에서는 CloudFunctionsTestVisualStudio::CloudFunctionsTestVisualStudio.Hello::Main 으로 입력합니다.\n\n액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n\n\n\n\n입력할 Main 함수 이름을 어떻게 적으면 되는지 한번 더 살펴보겠습니다.\n아래 소스코드 화면에서 보시면 namespace, class, Main 이렇게 이름이 적혀 있는 곳에서\n{ 1 }::{ 1 }.{ 2 }::{ 3 } 이렇게 연결해서 적으면 CloudFunctionsTestVisualStudio::CloudFunctionsTestVisualStudio.Hello::Main 이렇게 완성이 되고\n이 이름을 Main 함수 이름 칸에 입력하시면 됩니다.\n\n\n\n생성 완료\n디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\n\n\n\nCF Action 실행\n이제 생성된 액션을 실행해보겠습니다.\n액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n\n\n\n\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고,\n오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n\n\n\n\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다.  파라미터는 json 형태로 입력하면 됩니다.\n왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n\n\n\n\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n\n\n\n오류 메시지\n위의 순서대로 진행을 하면 문제 없이 사용 가능한데, 이미 다른 방법으로 진행해보면서 오류 메시지를 경험하는 경우도 있을 듯하여 가장 많이 겪게 되는 오류 상황 2가지를 정리해보겠습니다.\n\nMain 함수 이름 입력 오류\n위에서 설명한 액션 Main 함수 이름을 올바르게 입력하지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\n\"error\" : \"main required format is \\\"Assembly::Type::Function\\\".\"\n\n\n\n\n상단에 설명한 [CF Action 생성] - [옵션 설정]에서 Main 함수 입력하는 부분을 참고하셔서 정확하게 입력하시면 문제가 해결됩니다.\n\n.Net 대상 프레임워크 오류\n네이버 클라우드 Cloud Functions은 .Net Standard 2.0 규약을 지원하고 있습니다.\n그런데 이 대상 프레임워크가 맞지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\n\"error\" : \"Unable to locate requested type (\\\"CloudFunctionsTestVisualStudio.Hello\\\").\"\n\n\n\n\n위 [프로젝트 생성]에서 설명한 것처럼 프로젝트 생성할 때 대상 프레임워크를 .NET Standard 2.0으로 지정해야 합니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-15-2-6.html\n\n\n  문서 최종 수정일 : 2021-03-12"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-object-storage-s3-client-cyberduck": {
						"id": "4-storage-ncp-storage-object-storage-s3-client-cyberduck",
						"title": "Object Storage 접속용 Windows, MacOS Client Tool - Cyberduck",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_object_storage_s3_client_cyberduck/",
						"content": "개요\n네이버 클라우드 Object Storage에 접속해서 파일을 업로드, 다운로드 등의 관리를 할 수 있는 클라이언트 툴중에서 이번에는 Cyberduck이라는 무료 제품을 소개하려고 합니다.\nObject Storage는 AWS S3와 호환되기 때문에 S3를 지원하는 Cyberduck도 사용할 수 있는데 Cyberduck은 S3뿐만 아니라 \nFTP, SFTP, WebDAV, Amazon S3, OpenStack Swift, Backblaze B2, Microsoft Azure &amp; OneDrive, Google Drive, Dropbox 등에도 접속 가능합니다.\n\n설치파일 다운로드\nCyberduck은 윈도우용과 macOS용 프로그램을 제공하고 있어, 원하는 제품을 다운 받으면 됩니다.\n\nhttps://cyberduck.io/download/\n\n\n\n설치\n설치할 디렉토리를 선택하고, Cyberduck을 설치합니다.\n\n\n\n접속정보 확인\nCyberduck을 실행하고 새 연결을 메뉴를 선택하면 스토리지에 접속 정보를 입력하는 창이 나타납니다.\n여기서 필요한 정보는 서버 접속용 Endpoint URL, API 인증키 (접근 키 ID, Secret Access Key)가 필요한데, 관련된 정보는 아래쪽에서 다시 확인해보겠습니다.\n\n\n\nAPI 인증키 생성\nCyberduck으로 Object Storage에 접속하기 위해서는 API 인증키가 필요합니다. \nAPI 인증키는 네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져와야 하며, 아직 만들어진 Key가 없다면 새로 만들어야 합니다.\n\nhttps://www.ncloud.com/mypage/manage/authkey\n\n\n\n스토리지 접속\nObject Storage에 접속하기 위해 위에서 확인한 API 인증키를 이용하여 다음의 정보를 입력해야 합니다.\n\n# 서버: kr.object.ncloudstorage.com\n# 접근 키 ID: 네이버 클라우드 Access Key ID\n# Secret Access Key: 네이버 클라우드 Secret Key\n\n# 다른 해외 리전의 Object Storage 서버 주소는 다음과 같습니다.\n# 미국: us.objectstorage.ncloud.com\n# 싱가포르: sg.objectstorage.ncloud.com\n# 일본: jp.objectstorage.ncloud.com\n# 독일: de.objectstorage.ncloud.com\n\n\n\n\nObject Storage에 접속하면 이미 생성된 Bucket이 있을 경우 아래와 같이 Bucket 리스트가 나타납니다.\n\n\n\n업로드\nObject Storage에 파일을 업로드 하기 위해서는 먼저 Bucket이 생성되어 있어야 합니다.\n\nBucket (버킷) 생성\n이미 Bucket을 만들었다면 그대로 사용하시면 되고, 새로 만드실 경우에는 [파일]-[새 폴더] 메뉴를 이용하시면 됩니다.\n\n\n\n\n\n파일 업로드\n업로드할 대상 Bucket을 선택하고 마우스 오른쪽 버튼을 클릭하면 업로드 메뉴를 확인할 수 있습니다.\n\n\n\n파일 선택창에서 원하는 파일을 선택하면 되고, 파일이 여러개일 경우 다중 선택도 가능합니다.\n\n\n\n전송결과 화면\n\n\n업로드 완료 화면\n\n\n권한설정\nObject Storage에 업로드한 파일을 외부에서 접근해야 하는 경우에는 파일에 대한 권한을 변경해야 합니다.\n\n권한을 변경할 파일을 선택하고 마우스 오른쪽 버튼을 클릭하면 [정보] 메뉴를 확인할 수 있습니다.\n\n\n\n파일정보 팝업창에서 [권한] 메뉴를 선택하시면 왼쪽 아래에서 권한 설정 기능에서 [모두]를 선택합니다.\n\n\n\n[모두]에 대한 권한을 READ로 선택합니다.\n\n\n\n여러 파일의 권한을 동시에 변경할 경우 해당 파일들을 전부 선택하고 권한을 변경할 수도 있습니다.\n\n\n\n다운로드\nObject Storage에 저장된 파일을 로컬로 다운로드 받을 경우에는 대상 파일을 선택하고 마우스 오른쪽 버튼을 클릭하여 [지정된 위치로 내려받기] 메뉴를 선택합니다.\n\n\n\n다운로드 받을 폴더를 선택합니다.\n\n\n다운로드가 완료되었습니다.\n\n\n동기화\n이번에는 업로드, 다운로드가 아닌, 로컬 폴더와 Object Storage에 있는 Bucket을 서로 동기화 하는 기능에 대해 확인해보겠습니다.\n\n동기화할 Bucket을 선택하고 마우스 오른쪽 버튼을 클릭해 동기화 메뉴를 선택합니다.\n\n\n\n다음으로 동기화할 로컬 폴더를 선택합니다.\n\n\n\n이제 동기화를 시작할 준비가 되었습니다. 동기화 창에서 [계속] 버튼을 클릭해 동기화를 시작합니다.\n\n\n\n동기화가 완료되었지만 화면에서는 즉시 반영이 되지 않습니다. Bucket을 선택하고 마우스 오른쪽 버튼을 선택해 [다시보기] 메뉴를 선택하면 새로 고침이 되면서 동기화된 파일을 확인할 수 있습니다.\n\n\n\n삭제\nBucket이나 파일을 삭제할 경우에는 대상 파일 등을 선택하고 마우스 오른쪽 버튼을 클릭해 [삭제] 메뉴를 선택합니다.\n\n\n\n삭제 기능은 한번 더 정말 삭제할 것인지 확인하는 단계가 있습니다.\n\n\n\n환경설정\nCyberduck의 환경설정에서 중요한 것들을 살펴 보겠습니다.\n\n위쪽 메뉴에서 [편집]-[환경설정]을 선택합니다.\n\n\n\n환경설정 중에서 우선 [전송]-[일반]에 들어가시면 다운로드와 업로드에 대한 설정을 할 수 있습니다.\n여기서는 기본 다운로드 폴더를 설정할 수 있고, 업로드할 때 파일명이 겹칠 경우 덮어쓸 것인지, 물어보기 할 것인지 설정할 수 있습니다.\n\n\n\n[전송]-[권한] 설정에서는 업로드 되는 파일의 기본 권한을 원하는 설정으로 변경할 수 있습니다.\n\n\n\n[전송]-[필터] 설정에서는 다운로드와 업로드 할 때 특정 형식이나 확장자의 파일을 건너띄기 할 수 있는 정규식 기반의 설정을 제공합니다.\n\n\n\n[대역폭] 설정에서는 업로드와 다운로드할 때의 네트워크의 대역폭을 설정할 수 있습니다.\n\n\n\n평가\n마지막으로 Cyberduck 클라이언트 툴의 장점과 단점을 정리해보겠습니다.\n\n장점\n\n  무료제품으로 상업적인 용도로도 사용 가능하다.\n  S3와 그 호환 스토리지 뿐만 아니라 FTP, Dropbox, Google Drive 등 다양한 방식의 접속을 지원한다.\n  메뉴가 한글화 되어 있다.\n\n\n단점\n\n  인터페이스가 탐색기 형식이 아니라서 업로드, 다운로드할 때 불편하다.\n  제공되는 접속용 프로필이 다양하지 않아서 서버 정보를 일일이 입력해야 한다.\n  스토리지 &lt;–&gt; 스토리지 방식의 파일 전송을 지원하지 않는다.\n\n\n\n  문서 최종 수정일 : 2021-03-11"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-cloud-functions-dotnet-csharp-cmd": {
						"id": "1-compute-ncp-server-cloud-functions-dotnet-csharp-cmd",
						"title": "Cloud Functions Action을 .Net (C#)을 사용하여 윈도우 명령프롬프트(cmd)에서 만드는 방법",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_cloud_functions_dotnet_csharp_cmd/",
						"content": "개요\n네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어로는 Node.js, Python, Java, Swift, PHP, .Net, Go Language 등이 있는데\n다른 언어들은 네이버 클라우드 콘솔에서 직접 코드를 입력하면 되지만, Java는 로컬에서 작업 후 jar 파일로 .Net은 zip 파일로 압축해서 따로 등록해야 합니다.\n여기서는 윈도우 명령프롬프트(cmd)에서 .Net 그 중에서도 C#으로 Action을 만들고 zip 파일로 압축 후에 콘솔에 등록하고 테스트 하는 과정까지 정리해보겠습니다.\n\n.Net 설치\n네이버 클라우드 Cloud Functions는 .Net Standard 2.0 규격을 요구하는데, 이 규격을 지원하는 버전을 설치하려면 .Net 5.0 또는 .Net Core 2.1 이상을 설치하면 됩니다.\n가장 간단한 방법은 Visual Studio를 설치하는 방법이고 그 외에는 .Net 또는 .Net Core SDK만 별도로 설치하는 방법이 있습니다.\n\n\n  Visual Studio 무료버전 : https://visualstudio.microsoft.com/ko/free-developer-offers/\n  .Net, .Net Core SDK : https://dotnet.microsoft.com/download\n\n\n프로젝트 생성\nCloudFunctionsTestConsole 라는 이름의 Class Library 프로젝트를 생성하면서 언어는 C#, 타겟 프레임워크는 .Net Standard 2.0으로 지정하는 명령어입니다.\n다음으로 생성된 프로젝트 폴더로 이동해서 Newtonsoft.Json이라는 Json 패키지를 설치합니다.\n\n:: 프로젝트 생성\nD:\\&gt;dotnet new classlib -n CloudFunctionsTestConsole -lang \"C#\" -f netstandard2.0\n\n:: 폴더 이동\nD:\\&gt;cd CloudFunctionsTestConsole\n\n:: Json 패키지 설치\nD:\\CloudFunctionsTestConsole&gt;dotnet add package Newtonsoft.Json\n\n\n실제 명령프롬프트(cmd)에서 위 명령을 실행해본 화면은 다음과 같습니다.\n\n\n\nHello.cs 작성\n이제 name이라는 파라미터를 json 형태로 받아서 출력해주는 Hello.cs 스크립트를 작성합니다.\n\nusing System;\nusing Newtonsoft.Json.Linq;\n\nnamespace CloudFunctionsTestConsole\n{\n    public class Hello\n    {\n        public JObject Main(JObject args)\n        {\n            string name = \"no name\";\n            if (args.ContainsKey(\"name\")) {\n                name = args[\"name\"].ToString();\n            }\n            JObject message = new JObject();\n            message.Add(\"greeting\", new JValue($\"Hello, {name}!\"));\n            return (message);\n        }\n    }\n}\n\n\n\n\n프로젝트 게시\n이제 위에서 작성한 스크립트를 publish폴더로 게시하고, zip 파일로 압축합니다.\n여기서 만든 zip 파일을 네이버 클라우드 콘솔에서 등록하게 됩니다.\n\n:: 프로젝트 게시\nD:\\CloudFunctionsTestConsole&gt;dotnet publish -c Release -o publish\n\n:: 폴더 이동\nD:\\CloudFunctionsTestConsole&gt;cd publish\n\n:: 파일 압축\nD:\\CloudFunctionsTestConsole\\publish&gt;zip -r -0 CloudFunctionsTestConsole.zip *\n\n:: zip 명령이 실행되지 않을 경우 아래와 같이 윈도우 탐색기에서 직접 압축해도 됩니다.\n\n\n\n\n\n  zip 명령이 실행되지 않을 경우 아래와 같이 윈도우 탐색기에서 직접 압축해도 됩니다.\n\n\n\n\n\n\nCF 이용신청\n네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\n\n\n\nCF Action 생성\n\n액션 생성\n버튼을 선택해 액션을 생성합니다.\n\n\n\n트리거 선택\n액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n\n\n\n이름 입력\n액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n\n\n\n소스코드 언어 선택\n소스코드 언어 중에서 저희는 dotnet:2.2를 선택합니다.\n\n\n\n소스코드 업로드\n소스코드 타입은 코드와 파일이 있지만, java와 .Net은 파일 업로드만 가능합니다.\n앞에서 만든 소스코드를 선택하고 업로드 합니다.\n\n\n\n\n소스코드가업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\n\n\n\nVPC 연결 정보 선택\nVPC 환경에서는 연결할 VPC와 Subnet을 선택해야 합니다. Classic 환경에서는 다음 단계로 바로 이동하시면 됩니다.\n\n\n\n옵션 설정\n실행할 Main 함수의 이름을 {Assembly}::{Class Full Name}::{Method} 형태의 풀네임으로 입력합니다. \n위에서 만든 Hello.cs에서는 CloudFunctionsTestConsole::CloudFunctionsTestConsole.Hello::Main 으로 입력합니다.\n\n액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n\n\n\n\n입력할 Main 함수 이름을 어떻게 적으면 되는지 한번 더 살펴보겠습니다.\n아래 소스코드 화면에서 보시면 namespace, class, Main 이렇게 이름이 적혀 있는 곳에서\n{ 1 }::{ 1 }.{ 2 }::{ 3 } 이렇게 연결해서 적으면 CloudFunctionsTestConsole::CloudFunctionsTestConsole.Hello::Main 이렇게 완성이 되고\n이 이름을 Main 함수 이름 칸에 입력하시면 됩니다.\n\n\n\n생성 완료\n디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\n\n\n\nCF Action 실행\n이제 생성된 액션을 실행해보겠습니다.\n액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n\n\n\n\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고,\n오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n\n\n\n\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다.  파라미터는 json 형태로 입력하면 됩니다.\n왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n\n\n\n\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n\n\n\n오류 메시지\n위의 순서대로 진행을 하면 문제 없이 사용 가능한데, 이미 다른 방법으로 진행해보면서 오류 메시지를 경험하는 경우도 있을 듯하여 가장 많이 겪게 되는 오류 상황 2가지를 정리해보겠습니다.\n\nMain 함수 이름 입력 오류\n위에서 설명한 액션 Main 함수 이름을 올바르게 입력하지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\n\"error\" : \"main required format is \\\"Assembly::Type::Function\\\".\"\n\n\n\n\n상단에 설명한 [CF Action 생성] - [옵션 설정]에서 Main 함수 입력하는 부분을 참고하셔서 정확하게 입력하시면 문제가 해결됩니다.\n\n.Net 대상 프레임워크 오류\n네이버 클라우드 Cloud Functions은 .Net Standard 2.0 규약을 지원하고 있습니다.\n그런데 이 대상 프레임워크가 맞지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\n\"error\" : \"Unable to locate requested type (\\\"CloudFunctionsTestConsole.Hello\\\").\"\n\n\n\n\n위 [프로젝트 생성]에서 설명한 것처럼 프로젝트 생성할 때 -f netstandard2.0 옵션을 반드시 넣어주셔어야 합니다.\n\n:: 프로젝트 생성\nD:\\&gt;dotnet new classlib -n CloudFunctionsTestConsole -lang \"C#\" -f netstandard2.0\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-15-2-6.html\n\n\n  문서 최종 수정일 : 2021-03-09"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mysql-mariadb-config-bind-address": {
						"id": "5-database-ncp-database-mysql-mariadb-config-bind-address",
						"title": "mysql, mariadb 외부접속을 위한 환경설정 bind-address 위치",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mysql_mariadb_config_bind_address/",
						"content": "개요\n네이버 클라우드 DB중에서 mysql과 mariadb를 외부에서 접속하기 위해서는 여러 설정이 필요한데 그 중에서 bind-address 설정 항목이 어느 파일에 위치하고 있는지 정리해보겠습니다.\nOS중에서 CentOS는 기본 설정이 허용이지만, Ubuntu는 기본 설정이 localhost 만 접속 가능하도록 되어 있기 때문에 외부 접속을 허용해주기 위해서는 bind-address 설정을 수정해야 합니다.\n그래서 여기서는 Ubuntu에 대해서 살펴보겠습니다.\n\nmysql 5.6\nmysql 5.6에서는 bind-address 설정이 /etc/mysql/my.cnf 파일에 있습니다.\nOS는 Ubuntu 14.04만 제공됩니다.\n\n\n\nmysql 5.7\nmysql 5.7에서는 bind-address 설정이 /etc/mysql/mysql.conf.d/mysqld.cnf 파일에 있습니다.\nOS는 Ubuntu 14.04와 16.04 두 버전이 있는데 모두 동일합니다.\n\n\n\n\nmariaDB\nmariaDB는 10.2 버전만 있으며 bind-address 설정이 /etc/mysql/my.cnf 파일에 있습니다.\nOS는 Ubuntu 16.04만 제공됩니다.\n\n\n\n기타 - mariaDB CentOS\n그 외에 mysql의 경우 CentOS는 개요에서 말씀드렸듯이 기본적으로 외부 접속을 차단하는 bind-address 항목이 존재하지 않는데\nmariaDB의 경우 외부 접속을 차단하지는 않지만, bind-address 항목이 주석처리된 상태로 포함되어 있습니다.\n혹시나 차단하고 싶을 경우 사용하기 쉽게 미리 준비해둔 것으로 보입니다.\n주석처리된 bind-address의 위치는 /etc/my.cnf.d/server.cnf 입니다.\n\n\n\n참고 URL\n\n  Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n  CentOS에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n\n\n\n  문서 최종 수정일 : 2021-02-24"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mysql-mariadb-config-my-cnf": {
						"id": "5-database-ncp-database-mysql-mariadb-config-my-cnf",
						"title": "mysql, mariadb 환경설정 파일 my.cnf 위치",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mysql_mariadb_config_my_cnf/",
						"content": "개요\n네이버 클라우드 DB중에서 mysql과 mariadb의 환경설정 파일인 my.cnf 파일이 OS 별로 어떤 경로에 위치하고 있는지 정리해보겠습니다.\n\nCentOS\nCentOS에서는 my.cnf 파일이 /etc/ 바로 밑에 위치합니다.\n/etc/my.cnf\n\n\nmysql\n\n\nmariadb\n\n\nUbuntu\nUbuntu에서는 my.cnf 파일이 /etc/mysql 밑에 위치합니다.\n/etc/mysql/my.cnf\n\n\nmysql\n\n\nmariadb\n\n\n참고 URL\n\n  https://guide.ncloud-docs.com/docs/database-database-1-1.html\n  https://guide.ncloud-docs.com/docs/database-database-7-1.html\n\n\n\n  문서 최종 수정일 : 2021-02-22"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mariadb-access-from-remote-ubuntu": {
						"id": "5-database-ncp-database-mariadb-access-from-remote-ubuntu",
						"title": "Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mariadb_access_from_remote_ubuntu/",
						"content": "개요\n네이버 클라우드 Ubuntu에서 mariaDB 외부접속을 허용하고, mariaDB용 클라이언트 HeidiSQL을 이용해서 원격접속하는 방법을 정리해보겠습니다.\n여기서 원격접속이라 함은 SSH의 Tunnels를 이용하지 않고, 외부 클라이언트 등을 이용한 직접 접속을 뜻합니다.\n\n계정 비밀번호 생성\n여기서는 네이버 클라우드에서 서버를 생성했을 때 자동으로 설정되는 root 계정을 이용한 방법을 정리하게 됩니다. \n네이버 클라우드에서는 처음 mariaDB를 설치하면 root 계정에 비밀번호가 설정되어 있지 않습니다.\n\n# mariadb 실행\n~# mysql\n\n# 비밀번호 설정\nMariaDB [(None)]&gt; set password=password('비밀번호');\n\n\n계정 권한 부여\n외부에서 해당 계정(여기서는 root)으로 접속할 수 있도록 계정에 권한을 부여하는 쿼리입니다.\nMariaDB [(None)]&gt; GRANT ALL PRIVILEGES ON *.* to 'root'@'%' IDENTIFIED BY '비밀번호';\n\n\n환경설정 파일 수정\nmariaDB의 환경설정 파일 위치는 /etc/mysql/my.cnf 입니다.\nCentOS와 달리 Ubuntu에서 mariaDB는 기본적으로 외부 IP에 대한 접속이 차단되어 있고, 127.0.0.1 즉, localhost만 접속이 허용되어 있는 상태입니다.\n~# vi /etc/mysql/my.cnf\n\n\n아래는 환경 설정 파일의 일부입니다.\n# MariaDB database server configuration file.\n#\n# 중략 #\n\n[mysqld]\n#\n# * Basic Settings\n#\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\n#\n# Instead of skip-networking the default is now to listen only on\n# localhost which is more compatible and is not less secure.\nbind-address            = 127.0.0.1\n#\n\n\n위 환경설정 파일중에서 bind-address 항목을 주석처리하면 외부에서 접속이 가능합니다.\n# bind-address            = 127.0.0.1\n\n# 다른 방법\nbind-address            = 0.0.0.0\n\n# 특정 IP만 허용\nbind-address            = 허용할 IP 리스트\nbind-address            = 192.168.1.1,10.0.0.1\n\n\nDB 재시작\n~# systemctl restart mysql.service\n\n\nACG 포트 추가\n네이버 클라우드 ACG에 mariaDB가 사용하는 포트 3306을 추가해줍니다.\n\n\n\nHeidiSQL 다운로드\nmariaDB용 클라이언트 중에서 대표적인 HeidiSQL을 사용합니다.\n\n다운로드 경로 : https://www.heidisql.com/download.php\n\n\n\nHeidiSQL 설정\nHeidiSQL를 실행하면 DB접속을 위한 세션관리자가 먼저 나타납니다.\n왼쪽 하단의 [신규] 버튼을 누르고 서버 IP, 사용자, 암호를 입력하고 열기 버튼을 누르면 DB에 접속할 수 있습니다.\n\n\n\nDB 접속\nmariaDB 접속에 성공하면 아래와 같은 화면을 볼 수 있습니다.\n\n\n\n참고 URL\n\n  CentOS에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n  https://guide.ncloud-docs.com/docs/database-database-7-1.html\n\n\n\n  문서 최종 수정일 : 2021-02-19"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mariadb-access-from-remote-centos": {
						"id": "5-database-ncp-database-mariadb-access-from-remote-centos",
						"title": "CentOS에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mariadb_access_from_remote_centos/",
						"content": "개요\n네이버 클라우드 CentOS에서 mariaDB 외부접속을 허용하고, mariaDB용 클라이언트 HeidiSQL을 이용해서 원격접속하는 방법을 정리해보겠습니다.\n여기서 원격접속이라 함은 SSH의 Tunnels를 이용하지 않고, 외부 클라이언트 등을 이용한 직접 접속을 뜻합니다.\nCentOS는 Ubuntu와 달리 mariaDB 환경설정 파일 my.cnf에서 외부 IP에서 접근이 막혀 있지 않기에 환경설정 파일은 수정하지 않습니다.\n\n계정 비밀번호 생성\n여기서는 네이버 클라우드에서 서버를 생성했을 때 자동으로 설정되는 root 계정을 이용한 방법을 정리하게 됩니다. \n네이버 클라우드에서는 처음 mariaDB를 설치하면 root 계정에 비밀번호가 설정되어 있지 않습니다.\n\n# mariadb 실행\n~# mysql\n\n# 비밀번호 설정\nMariaDB [(None)]&gt; set password=password('비밀번호');\n\n\n계정 권한 부여\n외부에서 해당 계정(여기서는 root)으로 접속할 수 있도록 계정에 권한을 부여하는 쿼리입니다.\nMariaDB [(None)]&gt; GRANT ALL PRIVILEGES ON *.* to 'root'@'%' IDENTIFIED BY '비밀번호';\n\n\nACG 포트 추가\n네이버 클라우드 ACG에 mariaDB가 사용하는 포트 3306을 추가해줍니다.\n\n\n\nHeidiSQL 다운로드\nmariaDB용 클라이언트 중에서 대표적인 HeidiSQL을 사용합니다.\n\n다운로드 경로 : https://www.heidisql.com/download.php\n\n\n\nHeidiSQL 설정\nHeidiSQL를 실행하면 DB접속을 위한 세션관리자가 먼저 나타납니다.\n왼쪽 하단의 [신규] 버튼을 누르고 서버 IP, 사용자, 암호를 입력하고 열기 버튼을 누르면 DB에 접속할 수 있습니다.\n\n\n\nDB 접속\nmariaDB 접속에 성공하면 아래와 같은 화면을 볼 수 있습니다.\n\n\n\n참고 URL\n\n  Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n  https://guide.ncloud-docs.com/docs/database-database-7-1.html\n\n\n\n  문서 최종 수정일 : 2021-02-19"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-object-storage-s3-client-s3browser": {
						"id": "4-storage-ncp-storage-object-storage-s3-client-s3browser",
						"title": "Object Storage 접속용 Windows Client Tool - S3 Browser",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_object_storage_s3_client_s3browser/",
						"content": "개요\n네이버 클라우드의 Object Storage에 접속, 관리하는 방법은 aws cli 등 여러가지 있지만 Windows PC에서 간편하게 접속해서 관리할 수 있는 클라이언트 툴이 몇개 있습니다.\n그 중에서 이번에는 S3 Browser의 사용법에 대해 간단히 정리해보겠습니다.\n\nS3 Browser\nS3 Browser는 Amazon S3 and Amazon CloudFront를 위한 클라이언트입니다\n이 버전은 무료버전이기는 하지만, 정확히는 personal use only, non-commecial use only라고 명시되어 있습니다.\n그래서 라이선스와 관계없이 사용 가능하고, 더 많은 기능이 포함된 유료 버전도 있습니다.\n\n상세한 정보와 다운로드는 아래 링크에서 확인하시면 됩니다.\n\nhttps://s3browser.com/\n\n사용법\n\n프로그램을 다운 받아서 설치하고, 실행을 하면 여러 종류의 스토리지 중에서 원하는 것을 선택하게 됩니다.\n이 클라이언트는 AWS S3를 위한 것으로 CloudBerry Explorer와는 다르게 AWS의 다양한 S3 서비스들만 접속이 가능한데, 이용 가능한 스토리지 리스트는 마지막에서 정리해보겠습니다.\n\n\n\nAccount Type은  S3 Compatible Storage를 선택하면 됩니다.\n\n  Account name: 여기는 알아보기 쉬운 이름을 적으면 됩니다. 예를 들어 Naver Cloud\n  REST Endpoint: 여기는 네이버 클라우드의 endpoint-url을 적습니다. https://kr.object.ncloudstorage.com\n  Access Key ID: 여기는 Access Key ID\n  Secret Access Key: 여기는 Secret Key\n\n\n\n\n\n  네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n계정 정보를 입력하고 접속을 하면 버킷 리스트가 나타나고 원하는 버킷을 선택해서 들어가면 다음처럼 파일들을 확인할 수 있습니다.\n\n\n\nObject Storage에 있는 파일을 로컬PC로 가져오려면 원하는 파일을 선택하고 마우스 오른쪽 버튼을 눌러서 Download 명령을 선택하면 됩니다.\n\n\n\n그 외 여러 가지 기능들이 있는데 그리 어려운 기능은 아니므로 직접 사용해보시면 금방 알 수 있습니다.\n\n마지막으로 S3 Browser로 접속 가능한 S3 리스트를 확인해보겠습니다.\n\n\n\n\n  Amazon S3 Storage\n  S3 Compatible Storage\n  Amazon S3 in China\n  Amazon S3 GovCloud Storage\n  Amazon S3 GovCloud Storage (FIPS 140-2)\n  Amazon S3 via EC2 IAM Role\n  Amazon S3 via AssumeRole\n  Amazon S3 (Credentials from Environment Variables)\n  Amazon S3 (Credentials from AWS Config or Credential file)\n\n\nCloudBerry Explorer\n또 다른 클라이언트인 CloudBerry Explorer입니다. 자세한  내용은 아래 링크에서 확인 가능합니다.\n\nObject Storage 접속용 Windows Client Tool - CloudBerry Explorer\n\n\n  문서 최종 수정일 : 2021-02-02"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-object-storage-s3-client-cloudberry-explorer": {
						"id": "4-storage-ncp-storage-object-storage-s3-client-cloudberry-explorer",
						"title": "Object Storage 접속용 Windows Client Tool - CloudBerry Explorer",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_object_storage_s3_client_cloudberry_explorer/",
						"content": "개요\n네이버 클라우드의 Object Storage에 접속, 관리하는 방법은 aws cli 등 여러가지 있지만 Windows PC에서 간편하게 접속해서 관리할 수 있는 클라이언트 툴이 몇개 있습니다.\n그 중에서 가장 많이 사용되는 것이 바로 CloudBerry Explorer 인데, 사용법에 대해 간단히 정리해보겠습니다.\n\nCloudBerry Explorer\nCloudBerry Explorer의 정식 명칭은 CloudBerry Explorer Freeware for Amazon S3입니다.\n이 버전은 무료버전이며 더 많은 기능이 포함된 유료 버전도 있습니다. \n그리고 Amazon S3 뿐만 아니라 Microsoft Azur, Google Cloud 등을 위한 버전도 따로 있습니다.\n\n상세한 정보와 다운로드는 아래 링크에서 확인하시면 됩니다.\n\nhttps://www.msp360.com/explorer/windows.aspx\n\n사용법\n\n프로그램을 다운 받아서 설치하고, 실행을 하면 여러 종류의 스토리지 중에서 원하는 것을 선택하게 됩니다.\n이 클라이언트는 AWS S3를 위한 것이지만, 많은 스토리지들이 S3와 호환되는 구조로 만들어졌기 때문에 공통으로 사용 가능합니다. \n이용 가능한 스토리지 리스트는 마지막에서 정리해보겠습니다.\n\n\n\n여기에 아직 네이버 클라우드는 리스트에 없기 때문에 저희는 S3 Compatible을 선택하면 됩니다.\n\n  Display name: 여기는 알아보기 쉬운 이름을 적으면 됩니다. 예를 들어 Naver Cloud\n  Service point: 여기는 네이버 클라우드의 endpoint-url을 적습니다. https://kr.object.ncloudstorage.com\n  Access key: 여기는 Access Key ID\n  Secret key: 여기는 Secret Key\n\n\n\n\n\n  네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n계정 정보를 입력하고 접속을 하면 왼쪽에 로컬PC 폴더가, 오른쪽에 버킷 리스트가 나타나고 원하는 버킷을 선택해서 들어가면 다음처럼 파일들을 확인할 수 있습니다.\n\n\n\nObject Storage에 있는 파일을 로컬PC로 가져오려면 원하는 파일을 선택하고 마우스 오른쪽 버튼을 눌러서 Copy 명령을 선택하면 됩니다.\n\n\n\n그 외 여러 가지 기능들이 있는데 그리 어려운 기능은 아니므로 직접 사용해보시면 금방 알 수 있습니다.\n\n마지막으로 CloudBerry Explorer Freeware for Amazon S3로 접속 가능한 클라우드 스토리지 리스트를 확인해보겠습니다.\n\n\n\n\n  Amazon S3\n  Amazon S3 (China)\n  Amazon Glacier\n  Amazon Glacier (China)\n  Amazon Cloud Drive\n  Alibaba\n  S3 Compatible\n  Akaza\n  Aruba Cloud\n  Backblaze B3\n  Caringo\n  CenturyLink\n  Cisco\n  Cloudian\n  Connectria\n  Constant\n  DDN\n  dinCloud\n  DreamObjects\n  Dunkel\n  Easy Storage\n  Exoscale\n  GreenQloud\n  HGST\n  Hitachi\n  HostEurope\n  IDC Frontier\n  LeoNovus (S3)\n  Mandic\n  NetApp\n  NiftyCloud\n  Numergy\n  QNAP\n  Revera\n  Scality\n  Seeweb\n  SwiftStack (S3)\n  ThinkOn\n  Tiscali\n  Verizon\n  vCloud Air (EMC)\n  Walrus\n  Zettagrid\n  Wasabi\n\n\nS3 Browser\n또 다른 클라이언트인 S3 Browser입니다. 자세한  내용은 아래 링크에서 확인 가능합니다.\n\nObject Storage 접속용 Windows Client Tool - S3 Browser\n\n\n  문서 최종 수정일 : 2021-02-02"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-object-storage-required-service": {
						"id": "4-storage-ncp-storage-object-storage-required-service",
						"title": "Object Storage와 연동이 필수인 서비스",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_object_storage_required_service/",
						"content": "개요\n네이버 클라우드의 수 많은 서비스들 중에는 Object Storage가 설정, 준비되어 있어야 하는 서비스들, 즉, Object Storage와 연동이 필수인 서비스들이 여럿 있습니다.\n어떤 서비스들이 이에 해당하는지 정리해보겠습니다.\n\n연동 필수 서비스\nObject Storage와 연동이 필수인 서비스들에는 AI-Application Service와 Media 관련 서비스들이 많습니다.\n\n\n  CLOVA Speech\n  CLOVA Dubbing\n  VOD Transcoder\n  VOD Station\n  Video Player\n  Image Optimizer\n  SourceBuild\n  Cloud Hadoop\n  Data Analytics Service\n\n\n\n\n\n\n연동 선택 서비스\nObject Storage와 반드시 연동해야 하는 것은 아니지만, Object Storage를 이용하면 훨씬 편하고, 빠르고 안정적으로 서비스 가능한 경우도 있습니다.\n\n\n  CDN+\n  Global CDN\n\n\n\n  문서 최종 수정일 : 2021-02-16"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-pip-python-install-centos6": {
						"id": "1-compute-ncp-server-pip-python-install-centos6",
						"title": "CentOS6에서 pip - Python 설치하기",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_pip_python_install_centos6/",
						"content": "개요\n2020년 12월 01일부로 CentOS6의 기술지원이 공식 종료되었습니다.\nyum을 이용한 패키지 설치, 업데이트 등을 할 수 없는 상황이기에 pip, Python등의 설치가 원활하지 않습니다.\n그래서 pip설치에 필요한 CentOS6.x의 yum 명령을 수행하려면 \n먼저 아래의 가이드대로 Repository mirror를 변경하는 Script를 다운받아 설치해야 그 다음 단계를 진행할 수 있습니다.\n\n목적\n지원이 종료된 CentOS6에서 굳이 pip를 설치하려고 하는 이유는 DB 백업 파일을 aws cli를 이용해서 Object Storage에 저장하기 위해서 입니다.\n매 일정 시간에 DB나 소스 파일을 백업하고 백업된 파일을 Object Storage에 백업-동기화 하는 작업을 aws cli를 이용해서 처리하게 됩니다.\n\nRepository 변경\n이 Repository 변경 스트립트는 네이버 클라우드에서 공식 제공하는 스크립트입니다.\n~# wget http://repo.ncloud.com/etc/patch/Add-CentOS-Vault-Repo.sh\n~# bash Add-CentOS-Vault-Repo.sh\n~# yum install zsh\n\n\n필요 패키지들 설치\n~# yum -y groupinstall 'Development Tools'\n~# yum -y install openssl-devel* ncurses-devel* zlib*.x86_64\n~# yum update curl nss\n\n\nPython 설치\nCentOS6에는 Python 2.6이 설치되어 있습니다.\n하지만, 위에서 설명한 대로 CentOS 6에 대한 지원이 종료되면서 일반적인 방법으로는 pip를 설치할 수 없습니다.\n몇가지 상황을 테스트 해본 결과 Python 2.7과 Python 3.5에서는 pip를 설치할 수 있는 방법을 찾았고, 그래서 여기서는 Python 3.5.10을 설치하겠습니다.\n\n# Python 3.5 설치 압축파일 다운로드\n~# wget https://www.python.org/ftp/python/3.5.10/Python-3.5.10.tgz\n\n# Python 설치파일 압축해제 후 설치\n~# tar vxzf Python-3.5.10.tgz\n~# cd Python-3.5.10\n~# ./configure\n~# make\n~# make install\n\n# Python 설치 확인\n~# which python3\n\n# Python 버전 확인\n~# python3 -V\n\n\nPIP 설치\npip설치 파일도 위에서 설치한 Python 버전에 맞는 설치파일을 다운받아서 설치해야 문제없이 설치됩니다.\n현재까지 문제 없는 것으로 확인된 버전은 2.7과 3.5 입니다.\n~# curl -O https://bootstrap.pypa.io/3.5/get-pip.py\n~# python3 get-pip.py\n\n\n이후에 aws cli설치나 Object Storage 백업과 관련된 내용은 다음 문서를 참고하시기 바랍니다.\nCentOS에서 mysql DB를 Object Storage로 자동 백업하기\n\n설치 오류 상황과 해결 방법\npip를 설치하는 과정에 발생하는 몇가지 오류 상황과 그에 따른 해결방법을 정리해보겠습니다.\n\n\n  curl: (35) SSL connect error\npip 설치파일을 다운 받기 위해 curl을 실행할 때 발생하는 오류 메시지로 위쪽에서 필요 패키지들 설치할 때 있었던 다음 명령을 실행하면 해결됩니다.\n\n\n~# yum update curl nss\n\n\n\n  SyntaxError: invalid syntax\npip를 설치할 때 Python 버전이 일치하지 않는 등의 이유로 발생하는 문제입니다.\n위에서 설명했던 대로 Python 버전과 일치하는 pip 설치 파일을 다운 받으면 됩니다.\n\n\n# 오류가 발생하는 경로\n~# curl -O https://bootstrap.pypa.io/get-pip.py\n\n# 해결방법 : 경로 중간에 Python 버전을 추가\n~# curl -O https://bootstrap.pypa.io/{Python 버전}/get-pip.py\n\n# 오류 없는 버전 예시\n~# curl -O https://bootstrap.pypa.io/2.7/get-pip.py\n~# curl -O https://bootstrap.pypa.io/3.5/get-pip.py\n\n\n\n  문서 최종 수정일 : 2021-01-27"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-object-storage-aws-cli-connect": {
						"id": "4-storage-ncp-storage-object-storage-aws-cli-connect",
						"title": "AWS CLI를 이용한 Object Storage 접속 방법",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_object_storage_aws_cli_connect/",
						"content": "개요\n네이버 클라우드 Object Storage는 AWS의 스토리지 서비스 S3와 호환이 되도록 설계되어 있습니다.\n그래서 Object Storage에 접속, 관리할 때 AWS의 CLI(Command Line Interface)를 사용할 수 있는데 이번에 설치와 사용방법에 대해 정리해보겠습니다.\n\npip 설치\naws cli를 설치하려면 pip가 먼저 설치되어 있어야 합니다.\n설치 방법은 CentOS와 Ubuntu가 다르니 각각의 OS에 맞게 설치하시면 됩니다.\n혹시 이미 pip가 설치되어 있다면 아래에 있는 AWS CLI설치로 바로 이동하시면 되겠습니다.\n# CentOS\n~# yum -y install python-pip\n\n# Ubuntu\n~# apt-get install python-pip\n\n\n  CentOS 6.x 버전은 기술지원 종료로 인해 위 방법대로 설치가 되지 않습니다. 다음 경로에 나온 방법대로 설치하면 됩니다.\nCentOS6에서 pip - Python 설치하기\n\n\nAWS CLI 설치\n네이버 클라우드의 설명에 따르면 aws cli 1.16이후 버전은 일부 기능을 사용할 수 없어서 1.15버전을 사용한다고 합니다.\n~# pip install awscli==1.15.85\n\n\nAPI 인증키 생성\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n\nAWS CLI 환경 설정\n이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목은 입력하지 않으셔도 됩니다.\n~# aws configure\n\nAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\nAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\nDefault region name [None]: [Enter]\nDefault output format [None]: [Enter]\n\n\nObject Storage 접속\n이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# s3 ls 명령으로 Object Storage에 존재하는 버킷 리스트를 조회합니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\n\n# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어입니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\n\n\n참고 URL\nhttps://cli.ncloud-docs.com/docs/guide-objectstorage\n\n\n  문서 최종 수정일 : 2021-01-22"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mysql-object-storage-auto-backup-ubuntu": {
						"id": "5-database-ncp-database-mysql-object-storage-auto-backup-ubuntu",
						"title": "Ubuntu에서 mysql DB를 Object Storage로 자동 백업하기",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mysql_object_storage_auto_backup_ubuntu/",
						"content": "개요\n네이버 클라우드 Ubuntu에서 설치형 mysql  DB를 매일 일정한 시간에 Object Storage로 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n순서는 로컬에 백업 파일 생성 후에 Object Storage로 저장하는 단계로 진행됩니다.\n\n백업 폴더 생성\n~# mkdir /data_backup\n~# mkdir /data_backup/db\n\n\nmysql DB 로컬 백업 스크립트 작성\n우선은 mysql DB를 로컬에 백업 받는 스크립트를 작성합니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 백업 파일을 202001224505 와 같은 형식으로 저장하고, 생성된지 7일이 지난 백업 파일을 삭제하는 코드입니다.\n\n\n# 백업 스크립트에 실행 권한을 부여합니다.\n~# chmod 755 /bin/db_backup.sh\n\n\npip 설치\naws cli를 설치하려면 pip가 먼저 설치되어 있어야 합니다.\n혹시 이미 pip가 설치되어 있다면 아래에 있는 AWS CLI설치로 바로 이동하시면 되겠습니다.\n~# apt-get install python-pip\n\n\nAWS CLI 설치\n네이버 클라우드의 설명에 따르면 aws cli 1.16이후 버전은 일부 기능을 사용할 수 없어서 1.15버전을 사용한다고 합니다.\n~# pip install awscli==1.15.85\n\n\nAPI 인증키 생성\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n\nAWS CLI 환경 설정\n이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목을 입력하지 않으셔도 됩니다.\n~# aws configure\n\nAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\nAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\nDefault region name [None]: [Enter]\nDefault output format [None]: [Enter]\n\n\nObject Storage Bucket 생성\nObject Storage에 data-back-up Bucket을 생성하고 그 아래에 db 폴더를 생성합니다.\n\n\n\nObject Storage 접속 테스트\n이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# s3 ls 명령으로 Object Storage에 존재하는 버킷 리스트를 조회합니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\n\n2021-01-21 15:34:07 data-back-up\n\n\nmysql DB 백업 스크립트 수정\n이제 위 단계에서 만들었던 DB 로컬 백업 스크립트에 DB백업 파일을 Object Storage로 백업-동기화 하는 명령을 추가하겠습니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 여기서부터 추가되는 명령입니다.\n# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어입니다.\n# aws 명령어를 crontab에서 실행하기 위해 aws 파일의 전체 경로를 적어줍니다\n/usr/local/bin/aws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\n\n\n  여기서 db 폴더만 백업-동기화를 하는 것이 아닌 상위 폴더인 /data_backup/ 폴더부터 백업-동기화를 한 이유는 이후에 db 말고도 개발소스 파일 등도 압축해서 백업하기 위해서입니다.\n\n\n스케쥴링을 위한 crontab 설정\n이제 마지막으로 완성된 스크립트를 일정한 시간, 여기서는 매일 새벽 6시에 실행되도록 설정합니다.\n~# crontab -e\n\n# 매일 새벽 6시에 백업이 진행되는 코드입니다.\n00 06 * * * /bin/db_backup.sh &gt; /dev/null 2&gt;&amp;1\n\n\n  crontab에 &gt; /dev/null 2&gt;&amp;1를 추가하지 않으면 /var/log/syslog 파일에 (CRON) info (No MTA installed, discarding output) 라는 오류 메시지가 계속 쌓입니다. \npostfix를 설치하면 해결된다는 이야기도 있는데 굳이 필요하지 않은 것을 설치하기 보다는 필요하지 않은 오류 메시지는 없애는 것이 나을 듯합니다.\n\n\n백업 결과 확인\n백업이 진행되고 나면 아래와 같이 db 백업 파일이 Object Storage에 저장된 것을 확인할 수 있습니다.\n스샷에서는 빠른 확인을 위해 새벽 6시가 아닌 5분 단위로 백업한 내역입니다.\n\n\n참고 URL\n\n  mysql DB 자동백업 방법\n    \n      /5.database/ncp_database_mysql_auto_backup/\n    \n  \n  AWS CLI를 이용한 Object Storage 접속 방법\n    \n      /4.storage/ncp_storage_object_storage_aws_cli_connect/\n    \n  \n\n\n\n  문서 최종 수정일 : 문서 최종 수정일 : 2021-06-11"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mysql-object-storage-auto-backup-centos": {
						"id": "5-database-ncp-database-mysql-object-storage-auto-backup-centos",
						"title": "CentOS에서 mysql DB를 Object Storage로 자동 백업하기",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mysql_object_storage_auto_backup_centos/",
						"content": "개요\n네이버 클라우드 CentOS에서 설치형 mysql  DB를 매일 일정한 시간에 Object Storage로 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n순서는 로컬에 백업 파일 생성 후에 Object Storage로 저장하는 단계로 진행됩니다.\n\n백업 폴더 생성\n~# mkdir /data_backup\n~# mkdir /data_backup/db\n\n\nmysql DB 로컬 백업 스크립트 작성\n우선은 mysql DB를 로컬에 백업 받는 스크립트를 작성합니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 백업 파일을 202001224505 와 같은 형식으로 저장하고, 생성된지 7일이 지난 백업 파일을 삭제하는 코드입니다.\n\n\n# 백업 스크립트에 실행 권한을 부여합니다.\n~# chmod 755 /bin/db_backup.sh\n\n\npip 설치\naws cli를 설치하려면 pip가 먼저 설치되어 있어야 합니다.\n혹시 이미 pip가 설치되어 있다면 아래에 있는 AWS CLI설치로 바로 이동하시면 되겠습니다.\n~# yum -y install python-pip\n\n\n  CentOS 6.x 버전은 기술지원 종료로 인해 위 방법대로 설치가 되지 않습니다. 다음 경로에 나온 방법대로 설치하면 됩니다.\nCentOS6에서 pip - Python 설치하기\n\n\nAWS CLI 설치\n네이버 클라우드의 설명에 따르면 aws cli 1.16이후 버전은 일부 기능을 사용할 수 없어서 1.15버전을 사용한다고 합니다.\n~# pip install awscli==1.15.85\n\n\nAPI 인증키 생성\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n\nAWS CLI 환경 설정\n이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목을 입력하지 않으셔도 됩니다.\n~# aws configure\n\nAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\nAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\nDefault region name [None]: [Enter]\nDefault output format [None]: [Enter]\n\n\nObject Storage Bucket 생성\nObject Storage에 data-back-up Bucket을 생성하고 그 아래에 db 폴더를 생성합니다.\n\n\n\nObject Storage 접속 테스트\n이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# s3 ls 명령으로 Object Storage에 존재하는 버킷 리스트를 조회합니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\n\n2021-01-21 15:34:07 data-back-up\n\n\nmysql DB 백업 스크립트 수정\n이제 위 단계에서 만들었던 DB 로컬 백업 스크립트에 DB백업 파일을 Object Storage로 백업-동기화 하는 명령을 추가하겠습니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어입니다.\naws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\n\n\n  여기서 db 폴더만 백업-동기화를 하는 것이 아닌 상위 폴더인 /data_backup/ 폴더부터 백업-동기화를 한 이유는 이후에 db 말고도 개발소스 파일 등도 압축해서 백업하기 위해서입니다.\n\n\n스케쥴링을 위한 crontab 설정\n이제 마지막으로 완성된 스크립트를 일정한 시간, 여기서는 매일 새벽 6시에 실행되도록 설정합니다.\n~# crontab -e\n\n# 매일 새벽 6시에 백업이 진행되는 코드입니다.\n00 06 * * * /bin/db_backup.sh\n\n\n백업 결과 확인\n백업이 진행되고 나면 아래와 같이 db 백업 파일이 Object Storage에 저장된 것을 확인할 수 있습니다.\n스샷에서는 빠른 확인을 위해 새벽 6시가 아닌 5분 단위로 백업한 내역입니다.\n\n\n참고 URL\n\n  mysql DB 자동백업 방법\n    \n      /5.database/ncp_database_mysql_auto_backup/\n    \n  \n  AWS CLI를 이용한 Object Storage 접속 방법\n    \n      /4.storage/ncp_storage_object_storage_aws_cli_connect/\n    \n  \n\n\n\n  문서 최종 수정일 : 문서 최종 수정일 : 2021-06-11"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-mysql-auto-backup": {
						"id": "5-database-ncp-database-mysql-auto-backup",
						"title": "mysql DB 자동백업 방법",
						"categories": "5.database",
						"url": " /5.database/ncp_database_mysql_auto_backup/",
						"content": "개요\n매일 일정한 시간에 mysql DB를 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n\n백업 폴더 생성\n루트에 /data_backup 폴더를 만들고 그 아래에 db 폴더를 생성합니다.\n~# mkdir /data_backup\n~# mkdir /data_backup/db\n\n\nmysql DB 백업 스크립트 작성\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# DATE=$(date +%Y%m%d%H%M%S)는 백업할 파일명을 \n# 202001224505 와 같은 형식으로 저장할 수 있게 날짜를 변수로 담습니다.  \n# find $BACKUP_DIR -ctime +7 -exec rm -f {} \\;  \n# 여기서 -ctime +7은 7일이 지난 백업 파일을 찾아서 삭제하기 위한 코드입니다.  \n\n# 추가로 분 단위로 설정하려고 할 때는 아래와 같이 \n# -cmin +10 처럼 작성하면 10분이 지난 파일을 찾아서 삭제하게 됩니다.\n# find $BACKUP_DIR -cmin +10 -exec rm -f {} \\;\n\n\n\n# 백업 스크립트에 실행 권한을 부여합니다.\n~# chmod 755 /bin/db_backup.sh\n\n\n스케쥴링을 위한 crontab 설정\n~# crontab -e\n\n# 매일 새벽 6시에 백업이 진행됩니다.\n00 06 * * * /bin/db_backup.sh\n\n\n그 외 시간 설정 방법\n# 30분 마다 실행\n*/30 * * * * /bin/db_backup.sh\n\n# 매주 일요일 새벽 6시에 실행\n0 06 * * 0 /bin/db_backup.sh\n\n# 매월 1일 새벽 6시에 실행\n0 06 1 * * /bin/db_backup.sh\n\n# 매년 12월 31일 새벽 6시에 실행\n0 06 31 12 * /bin/db_backup.sh\n\n\n참고 URL\nhttps://www.ncloud.com/product/database\n\n\n  문서 최종 수정일 : 2021-06-11"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-object-storage-lifecycle-management": {
						"id": "4-storage-ncp-storage-object-storage-lifecycle-management",
						"title": "Object Storage Lifecycle Management 관리대상 설정 방법",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_object_storage_lifecycle_management/",
						"content": "개요\n네이버 클라우드 Object Storage에 저장된 Object 즉, 파일들의 Lifecycle(수명주기)를 설정할 때 관리대상이 되는 Object를 결정하는 규칙에 대해 정리해보겠습니다.\n\nLifecycle Management (수명주기) 정책 설정\n수명주기 정책 설정은 크게 정책, 관리대상, 이동위치 3가지 항목으로 구성됩니다.\n\n정책\n정책 유형은 다음의 3가지가 있습니다.\n\n  만료 삭제 : 설정된 기간이 지난 파일을 삭제\n  이관 : 설정된 기간이 지난 파일을 Archive Storage로 이동\n  이관 후 삭제 : 설정된 기간이 지난 파일을 Archive Storage로 이동한 후 Object Storage에서 삭제\n\n\n그리고 이동 시점은 파일이 Object Storage에 저장-생성된 후 경과한 일자를 기준으로 하며 1일 ~ 3,650일 사이의 값을 입력합니다.\n\n\n\n관리대상 (Source)\n관리대상의 버킷(Bucket)을 선택하고 Object 이름의 규칙을 접두어 방식으로 입력합니다.\n\n\n\n이동위치 (Target)\n이동할 위치는 Archive Storage로 고정이며, Archive Storage의 컨테이너(버킷)을 선택하고 세부경로 즉, 폴더를 입력합니다.\n세부경로에 아무것도 입력하지 않으면 Source 즉, Object Storage의 위치, 폴더 구조 그대로 이동됩니다.\n\n\n\n관리대상(Source) Object 이름 규칙\n\n  네이버 클라우드에서 채택하고 있는 규칙은 접두어 방식입니다.\n예를 들어 규칙을 ncp라고 설정하면 이름이 ncp로 시작되는 모든 파일과 폴더가 대상이 됩니다.\n하지만, 접두어 규칙이기 때문에 img_ncp_01.png 처럼 파일명 중간이나 끝에 ncp가  들어간 파일과 폴더는 대상이 아닙니다.\n\n\nObject 이름 규칙의 특수 문자 사용\n\n  &lt; &gt; : “ \\ | ? * % 는 사용할수 없습니다\n  ”/”는 첫 글자에 사용할 수 없습니다.\n  ”//”처럼 “/”는 연속해서 사용할 수 없습니다.\n\n\n적용 예시\n아래 스샷처럼 폴더와 파일이 저장되어 있다고 가정하고 예를 들어보겠습니다.\n다른 항목들은 동일하고, 관리대상(Source) Object 이름 규칙에 따라 어떤 결과가 나오지는 확인해보겠습니다.\n물론 아래의 예시들에서 공통적으로 위에서 지정한 수명주기 날짜에 해당하는 파일들만 이동하게 됩니다.\n\n\n\n- 3rdeyesys\n\t- img_01.png\n\t- screenshot_01.png\n- 3rdeyesys_img\n\t- img_02.png\n- ncp\n\t- \n- 3rdeyesys_biz.png\n- ncp_server_acg_classic.png\n- ncp_server_acg_vpc_inbound.png\n- vpc_acg_nacl_ncp.png\n\n\n이렇게 3rdeyesys, 3rdeyesys_img 2개의 폴더에는 각각 파일이 존재하고, ncp 폴더에는 아무것도 없습니다.  그리고 4개 파일이 루트에 저장되어 있습니다.\n\nObject 이름 규칙(접두어) : 3rdeyesys\n이 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n즉, 3rdeyesys로 시작하는 파일과 폴더 아래에 있는 파일까지 모두 이동하게 됩니다.\n- 3rdeyesys\n\t- img_01.png\n\t- screenshot_01.png\n- 3rdeyesys_img\n\t- img_02.png\n- 3rdeyesys_biz.png\n\n\nObject 이름 규칙(접두어) : ncp\n이 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n위의 경우와 다르게 ncp 폴더는 이동하지 않는데 그 이유는 ncp 폴더 아래에 아무 파일도 없기 때문에 이동할 파일이 없어 폴더도 이동하지 않습니다.\n\n- ncp_server_acg_classic.png\n- ncp_server_acg_vpc_inbound.png\n\n마찬가지로 ncp 폴더 아래에 파일이 존재하더라도 위에서 지정한 수명주기 날짜에 해당하는 파일이 없는 경우에도 ncp 폴더는 이동하지 않습니다.\n또한 접두어 방식이기 때문에 파일명 중간에 ncp가 들어간 vpc_acg_nacl_ncp.png 파일은 해당되지 않아서 이동하지 않습니다.\n\nObject 이름 규칙(접두어) : 3rdeyesys/\n이렇게 뒤에 “/”를 입력하여 폴더라고 명시한 경우에 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n\n- 3rdeyesys\n\t- img_01.png\n\t- screenshot_01.png\n\n즉, 끝에 “/”를 입력했기 때문에 3rdeyesys로 시작하는 폴더만 대상이 되어 다른 파일은 이동하지 않습니다.\n\nObject 이름 규칙(접두어) : 3rdeyesys/img\n이렇게 폴더와 파일명 접두어까지 함께 입력한 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n\n- 3rdeyesys\n\t- img_01.png\n\n즉, 3rdeyesys 폴더 아래에 있는 파일들 중에서 img로 시작하는 이름을 가진 파일만 이동하게 됩니다.\n\nObject 이름 규칙(접두어) : 아무것도 입력하지 않았을 때\n아무것도 입력하지 않았을 때는 모든 파일과 폴더 아래에 있는 파일들이 이동하게 됩니다.\n물론 마찬가지로 수명주기 날짜에 해당하는 파일만 이동하게되고, 폴더 아래에 해당하는 파일이 없을 경우 해동 폴더는 이동하지 않습니다.\n\n정책 실행 시간\nLifecycle Management(수명주기) 정책 실행시간은 아래와 같습니다.\n\n\n  01:00~02:00,  07:00~08:00, 13:00~14:00, 19:00~20:00\n (※ 파일용량이 클 경우 일부 변동될 수 있음)\n\n\n예시) 정책 유형(이관), 이동 시점(생성 후 1일)로 정책을 생성하고, 대상 파일이 15시에 업로드 되었다면 다음 날 19~20시 사이에 이관 완료.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/storage-storage-6-1.html\n\n\n  문서 최종 수정일 : 2021-06-02"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-autoscaling-event-setting": {
						"id": "1-compute-ncp-server-autoscaling-event-setting",
						"title": "AutoScaling 이벤트 설정하는 방법",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_autoscaling_event_setting/",
						"content": "개요\n네이버 클라우드에서 AutoScaling을 설정할 때 중요한 것이 이벤트 설정입니다.\n예를 들어 CPU 사용률이 70%가 넘는 상태가 1분 이상 지속되면 서버를 늘리는 작업이 진행되도록 설정한다고 할 때, CPU가 70% 이상인 상태가 1분 이상 지속되는 이벤트가 발생하는지 체크하는 것을 말합니다.\n현재 네이버 클라우드 Console에서는 AutoScaling 그룹을 생성한 후에 바로 이 이벤트 설정을 하는 방법에 대한 메뉴나 링크가 없어서 그에 대한 내용을 정리해보겠습니다.\n\nAutoScaling Group 생성\nAutoScaling 이벤트를 설정하려면 우선 AutoScaling Group을 생성해야 합니다.\nConsole - Auto Scaling - Auto Scaling Group 메뉴에서 설정할 수 있습니다.\nAutoScaling Group을 설정한 후에는 AutoScaling Group Event를 설정해야 하니 해당 기능이 있는 메뉴로 이동할 수 있도록 버튼이나 링크가 생겼으면 합니다.\n\n\n\nAutoScaling Group Event 설정\nAutoScaling의 그룹 이벤트를 설정하는 곳은 Monitoring 메뉴에 있습니다.\nCPU 사용량 등의 서버 상태를 확인해야 하는 것이다 보니 Console - Monitoring - Group Event Setting 메뉴에서 관련된 이벤트 설정을 할 수 있습니다.\n아래 스샷에서 확인할 수 있듯이 앞에서 생성한 AutoScaling Group이 나타납니다. 만약 AutoScaling Group을 생성하지 않았다면 여기서는 아무런 설정도 할 수 없습니다.\n혹시 AutoScaling Group이 생성되지 않은 상태에서 이 메뉴에 들어오는 경우에는 AutoScaling Group 생성 페이지로 이동하는 버튼이나 링크가 추가되길 바랍니다.\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/management-management-1-1.html\n\n\n  문서 최종 수정일 : 2021-01-19"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-service-port-info": {
						"id": "2-networking-ncp-networking-service-port-info",
						"title": "주요 서비스 포트(Port) 정보",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_service_port_info/",
						"content": "포트(Port) 정보\n네이버 클라우드 주요 서비스들에서 사용하는 포트(Port) 정보를 정리해보았습니다.\n네이버 클라우드에서 사용하는 포트이므로 일부 서비스의 경우 일반적으로 사용되는 포트와 조금 다른 경우도 있을 수 있습니다.\n\n\n  22 : SSH\n  80 : http\n  443 : https\n  1433 : mssql\n  3000 : Node.js Express\n  3306 : mysql\n  3389 : 윈도 원격데스크톱\n  5432 : PostgreSQL\n  5672 : RabbitMQ\n  5985 : Packer\n  6379 : Redis\n  8001 : CUBRID\n  8080 : Ambari\n  8081 : Hue\n  8388 : Shadowsocks 서버\n  9736 : Jeus WebAdmin\n  10090 : Pinpoint 서버\n  11313 : Hugo 서버\n  15672 : RabbitMQ Management UI\n  18080 : Tomcat, Jenkins\n  18088 : Superset\n  18888 : TensorFlow Jupyter Notebook\n  18889 : TensorBoard\n  27017 : MongoDB\n  50070 : HDFS NameNode\n\n\n\n  문서 최종 수정일 : 2021-01-14"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-load-balancer-acg": {
						"id": "2-networking-ncp-networking-load-balancer-acg",
						"title": "Classic Load Balancer 운영을 위한 ACG 설정 방법",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_load_balancer_acg/",
						"content": "개요\nLoad Balancer가 정상적으로 동작하기 위해서는 Load Balancer –&gt; Server의 지정된 포트로 접근할 수 있어야 합니다.\n그러기 위해서는 Server의 ACG에 Load Balancer가 접근할 수 있도록 권한을 설정해주어야 하는데, 여기서는 네이버 클라우드의 Classic Load Balancer를 운영할 때 ACG 설정을 어떻게 하는가에 대한 내용을 정리해보겠습니다.\n\n서버연결 실패 상황\n서버 등록하고 Load Balancer의 다른 설정들을 모두 올바르게 했는데도 아래와 같이 서버연결 상태가 실패로 나타나고 Load Balancer는 동작이 정지되는 경우가 있습니다.\n이런 경우가 바로 ACG에 Load Balancer의 접근 권한을 설정하지 않았을 때 입니다.\n\n\n\nACG 권한 설정\nACG에 Load Balancer가 접근할 수 있도록 권한을 설정하려면 접근소스에 아래와 같이 입력합니다.\n접근소스 : ncloud-load-balancer\n\n\n그 외에 프로토콜과 허용포트도 지정된 정보를 입력하고 추가를 하면 됩니다.\n\n\n\n\n서버연결 성공\nACG에 접근권한을 설정하고 나서 잠시 기다리면 Load Balancer가 서버에 접근시도를 하고 정상 접근이 되면서 서버연결 상태가 성공으로 바뀌고 Load Balancer도 정상 작동하게 됩니다.\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-loadbalancer-classiclbconsole.html\n\n\n  문서 최종 수정일 : 2021-01-14"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-storage-add-detail-process": {
						"id": "1-compute-ncp-server-storage-add-detail-process",
						"title": "Linux 스토리지(디스크) 추가 상세 가이드",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_storage_add_detail_process/",
						"content": "개요\n네이버 클라우드에서 리눅스 서버에 디스크를 추가하는 것은 스토리지 즉, Block Storage를 생성해서 서버에 연결하는 작업이 필요합니다.\n\n전체 과정 요약\n\n~# fdisk -l\n\n~# fdisk /dev/xvdb\n\n~# mkfs.xfs /dev/xvdb1\n\n  - CentOS 5.x: mkfs.ext3 /dev/xvdb1\n  - CentOS 6.x: mkfs.ext4 /dev/xvdb1\n  - CentOS 7.x: mkfs.xfs /dev/xvdb1\n  - Ubuntu : mkfs.ext4 /dev/xvdb1\n\n~# mkdir /mnt/data\n\n~# mount /dev/xvdb1 /mnt/data\n\n~# df -k\n\n~# vi /etc/fstab\n### =============================\nUUID=1fd5s61f5d-*** 중략 ***-f84ew13 /mnt/data xfs defaults 1 2\n\n# 또는\n/dev/xvdb1 /mnt/data ext4 defaults 1 2\n### =============================\n...\n\n\n\n스토리지 생성, 할당\n우선은 네이버 클라우드 콘솔 [Server] - [Server]에서 해당 서버를 선택하고 \n[서버 관리 및 설정 변경] - [스토리지 생성]을 선택하거나\n[Server] - [Storage]에서 [스토리지 생성]을 클릭합니다.\n\n\n\n\n\n다음으로 [스토리지 생성] 화면에서 스토리지 종류, 이름, 적용서버, 크기 (최소 10GB, 최대 2000GB) 등을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n\n앞에서 설정한 스토리지 정보를 다시 살펴보고 이상이 없으면 [확인] 버튼을 클릭합니다.\n\n\n\n추가된 스토리지는 [Server] - [Server] 리스트에서 해당 서버를 클릭해 상세정보에서 확인하거나\n[Server] - [Storage] 리스트에서 연결정보까지 포함해서 확인할 수 있습니다.\n\n\n\n\n\n스토리지 할당 확인\n네이버 클라우드 콘솔에서 할당한 스토리지를 확인하기 위해 putty를 실행해 서버에 접속합니다.\n이후 과정은 모두 서버에 접속한 상태에서 진행하게 됩니다.\n\nfdisk -l 명령어를 실행해보면 아래 화면처럼 /dev/xvdb 디스크가 할당된 것을 확인할 수 있습니다.\n\n~# fdisk -l\n\n\n\n\n디스크 파티션\n다음 명령어를 입력해 할당된 디스크에 파티션을 생성합니다.\n파티션 설정에는 기본인 MBR 방식과 2TB 이상의 디스크를 인식하기 위해 사용하는 GPT 방식이 있는데, 네이버 클라우드는 최대 2,000GB까지만 지원하므로 여기서는 기본방식인 MBR을 사용하겠습니다.\n~# fdisk /dev/xvdb\n\n\n파티션 생성\n파티션을 생성할 때는 여러 단계의 옵션이 있습니다. 일반적으로는 아래와 같은 단계로 진행하면 됩니다.\n\n\n  파티션을 새로 생성하기 위해 ‘n’을 입력\n\n\n\n\n\n  생성할 파티션 타입에 따라 primary type이면 ‘p’, extended type이면 ‘e’를 입력.\n(primary type으로 생성하는 것이 일반적이며, primary 영역의 파티션이 부족할 경우 추가로 extended type으로 생성)\n\n\n\n\n\n  생성할 파티션 번호와 cylinder 영역을 입력 (일반적으로 추가할 disk 전체를 mount하게 되고, 이 경우 default값을 그대로 사용하므로 Enter 입력)\n\n\n\n\n\n  ‘w’를 입력해 해당 구성을 적용. 파티션 생성 완료.\n\n\n\n\n마지막으로 fdisk -l 명령어로 생성된 파티션을 다시 확인합니다.\n디스크가 /dev/xvdb1 장치로 인식된 것을 확인할 수 있습니다.\n\n\n\n디스크 포맷\n다음으로 파티션이 생성된 디스크를 포맷하면 되는데, OS별로 명령어가 다르므로 확인 후에 실행해야 합니다.\n여기서는 CentOS 7.x 기준으로 mkfs.xfs 명령어를 사용했습니다.\n\n~# mkfs.xfs /dev/xvdb1\n\n- CentOS 5.x: mkfs.ext3 /dev/xvdb1\n- CentOS 6.x: mkfs.ext4 /dev/xvdb1\n- CentOS 7.x: mkfs.xfs /dev/xvdb1\n- Ubuntu : mkfs.ext4 /dev/xvdb1\n\n\n디스크 마운트\n다음으로 디스크를 마운트할 포인트 즉, 디렉토리를 원하는 이름으로 생성하고 마운트를 합니다.\n아래에 있는 마운트 경로 (/mnt/data)는 예시입니다. 원하는 경로를 직접 설정하시면 됩니다.\n\n~# mkdir /mnt/data\n~# mount /dev/xvdb1 /mnt/data\n\n\n\n\n마운트된 내역을 확인합니다.\n~# df -k\n\n\n\n마운트 정보 등록\n마운트 정보는 설정에 저장하지 않으면 서버가 리부팅될 때 사라지기 때문에 fstab에 저장합니다.\n마운트 정보를 등록할 때 장치명을 사용하는 방법과 장치의 UUID를 사용하는 방법이 있는데, 경우에 따라서는 장치명이 변경될 수도 있어, 이를 대비해 가능하면 UUID로 등록합니다.\n\nUUID 확인\nUUID를 확인하려면 blkid 명령어를 사용합니다.\n여기서 확인한 UUID를 별도로 복사해두었다가 fstab에 입력하게 됩니다.\n~# blkid /dev/xvdb1\n\n\n\nvi로 /etc/fstab 파일을 열면 다음과 같습니다.\n서버 생성과 함께 장착된 기본 디스크도 UUID로 입력된 것을 확인할 수 있습니다.\n~# vi /etc/fstab\n\n\n\n앞에서 확인하고 복사해둔 추가 디스크의 UUID와 기타 정보를 입력합니다.\n입력을 완료한 후 fstab 파일을 저장하고 빠져 나옵니다.\n(fstab에 입력할때 사용하는 디스크 정보 옵션에 대한 정리는 아래에서 다시 확인할 수 있습니다.)\n\n### /etc/fstab\n\nUUID=29f58417-*** 중략 ***38d0f /mnt/data xfs defaults 1 2\n\n# 또는\n/dev/xvdb1 /mnt/data ext4 defaults 1 2\n\n\n\n\nfstab 설정 상세정보\n\n/etc/fstab은 부팅 단계에서 마운트되어야 할 볼륨 정보들이 저장되는 곳입니다.\n(OS 이미지에 따라 파일 시스템이 다르기 때문에 주의해야 합니다.)\n\n파일의 각 항목이 의미하는 바는 아래와 같으며 각 항목은 Tab 또는 Space Bar로 구분합니다.\n\n(장치명) (마운트 포인트) (파일시스템 종류) (옵션) (dump 설정) (fsck 설정)\n\n\n  \n    장치명: 장치명은 장치의 UUID를 사용하거나 /dev/xvdb1와 같은 장치이름을 사용합니다.\n  \n  \n    마운트 포인트: 볼륨을 마운트하고자 하는 위치입니다. 예시에서는 /mnt/data 디렉토리에 마운트했습니다.\n  \n  \n    파일시스템 종류: OS별로 기본 파일시스템이 다르므로 알맞게 입력합니다.\n\n    \n      CentOS 5.x : ext3\n      CentOS 6.x : ext4\n      CentOS 7.x : xfs\n      Ubuntu Server / Desktop : ext4\n    \n  \n  \n    옵션: 예시에서는 default 옵션을 사용하였으며, 해당 옵션에는 rw, nouser, auto, exec, suid 속성이 포함됩니다.\n각 속성의 내용은 다음과 같습니다. (필요한 옵션만 사용할 시, 각 옵션을 쉼표(,)로 구분하여 작성해주시면 됩니다.)\n\n    \n      auto : 부팅 시 자동 마운트\n      rw : 읽기, 쓰기 모두 가능하도록 마운트\n      nouser : root 계정만 마운트 가능\n      exec : 파일 실행을 허용\n      suid : SetUID와 SetGID를 허용\n    \n  \n  \n    dump 설정: dump 명령으로 백업을 할 것인지에 대한 설정\n\n    \n      0: dump되지 않는 파일 시스템\n      1: dump 가능한 파일 시스템\n    \n  \n  \n    fsck 설정: 부팅시에 fsck 명령으로 파일시스템에 대한 무결성 검사를 할 것인지에 대한 설정\n\n    \n      0 : 부팅 시 fsck 실행하지 않음\n      1 : 부팅 시 root 파일 시스템을 우선 체크\n      2 : 부팅 시 root 이외의 파일 시스템을 우선 체크\n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-4-1-v2.html\n\n\n  문서 최종 수정일 : 2021-06-04"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-vpc-create": {
						"id": "1-compute-ncp-server-vpc-create",
						"title": "VPC 환경에서 서버 생성",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_vpc_create/",
						"content": "개요\n네이버 클라우드 VPC환경에서 서버를 생성하는 순서를 정리해보겠습니다.\n아래 순서는 굳이 기억하지 않아도 필요한 부분은 그때그때  안내가 잘 되어 있기 때문에 별 문제는 없지만 그래도 어떤 것들이 필요한 가에 대해 어느 정도 알아둘 필요는 있어 보입니다.\n\nVPC 생성\nVPC (Virtual Private Cloud) 즉, 클라우드 상에서 논리적으로 격리된 고객 전용 네트워크 공간을 먼저 생성하고 해당 공간에 서버를 생성하게 됩니다.\nVPC는 고객의 계정마다 최대 3개를 생성할 수 있으며, 각 VPC는 최대 넷마스크 0.0.255.255/16 (IP 65,536개) 크기의 네트워크 주소 공간을 제공합니다.\n\n\n  VPC 이름 입력\n  IP 주소 범위 입력\n\n\n\n  VPC의 IP 주소 범위는, private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /16~/28 범위\n\n\n\n\nSubnet 생성\n\n  Subnet 이름 입력\n  VPC 선택\n  IP 주소 범위 입력\n  Zone 선택\n  Network ACL 선택\n  Internet Gateway 전용여부 선택 (Public or Private)\n\n\n\n\n서버 설정\n\n  VPC 선택\n  Subnet 선택\n  스토리지 종류 선택\n  서버 세대 선택\n  서버 타입 선택\n  요금제 선택\n  서버 개수 입력\n  서버 이름 입력\n  Network Interface 추가\n  물리 배치 그룹 여부 선택\n  반납 보호 여부 선택\n\n\n\n\n인증키 설정\n\n\n네트워크 접근 설정 (ACL)\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-1-1-v2.html\n\n\n  문서 최종 수정일 : 2021-01-12"
					}
					
				
			
		
			
				
					,
					
					"99-etc-etc-jekyll-install": {
						"id": "99-etc-etc-jekyll-install",
						"title": "jekyll 설치(윈도 10) with base-theme",
						"categories": "99.ETC",
						"url": " /99.etc/etc_jekyll_install/",
						"content": "설치 전체과정 요약\n\n\n  Ruby 설치\n  ridk 설치\n  gem 업데이트\n  jekyll, Bundler 설치\n\n\nRuby 설치\n일반적으로 jekyll를 사용한다면 최신 버전을 사용하면 되겠지만 여기서는 base-theme를 기반으로 하기 때문에 호환에 잘되는 2.5를 설치합니다.\n\nRuby Installer 다운로드 경로\nhttps://rubyinstaller.org/downloads/\n\n위 사이트에서 rubyinstaller-devkit-2.5.8-2-x64 를 다운 받아 설치하면 됩니다.\n\nRuby 설치가 끝나면서 완료화면에 Run ‘ridk install’ to setup MSYS2 and development toolchain. 이라는 옵션이 나타납니다.\n반드시 선택하고 완료를 하시기 바랍니다.\n\n\n\nridk 설치\n앞단계인 Ruby 설치 완료에서 ridk install을 선택했다면 ridk 설치 커맨드 창이 나타납니다.\n(혹시 선택하지 않았다면 커맨드 창을 열어서 ridk install 을 입력하면 됩니다)\n이때 설치 옵션을 선택할 수 있는데 1,2,3 을 선택하고 Enter 키를 입력하면 설치가 진행됩니다.\n\n\n\ngem 업데이트\n\ngem update\n\n\nJekyll, Bundler 설치\n\ngem install jekyll bundler\n\n\nbase-theme 설치\nbase-theme는 jekyll의 여러 테마 중에서 CloudCannon에서 제작한 테마입니다.\n\n\n\n다운로드 경로\nhttps://github.com/CloudCannon/base-jekyll-template\n\n위 다운로드 경로에서 소스를 직접 다운 받거나 GitHub Desktop을 이용해서 가져오면 됩니다.\n\n블로그 실행, 접속\n작업하면서 결과물을 확인할 때는 다음과 같은 명령어로 입력하고 브라우져에서 http://127.0.0.1:4000/ 로 접속하시면 되니다.\n\nbundle exec jekyll serve\n\n\n사이트 빌드\n작업이 끝난 결과물을 실제 서버나 gitHub에 업로드, 배포할 경우에는 다음 명령어로 빌드 한 후에 _site에 생성된 html 등을 사용하시면 됩니다.\n\nbundle exec jekyll build\n\n\n추가 패키지 설치\n혹시 블로그 실행, 접속에서 오류가 발생하면 나타나는 메시지를 보고 처리를 해주면 됩니다.\n혹시 필요한 gem이 설치되지 않았을 경우에는 다음과 같이 설치해주면 됩니다.\n\ngem install public_suffix -v 3.0.1\n\n\n기본 블로그 생성\n위에서 소개한 것처럼 테마를 사용하는 것이 아닌 기본 설정만의 블로그를 새로 만들려면 다음과 같이 입력하면 됩니다.\n\njekyll new PATH\n\n기본 블로그를 만들고 접속하면 다음과 같은 화면이 나타납니다.\n\n\n\n\n  “문서 최종 수정일 : 2021-01-05”"
					}
					
				
			
		
			
				
					,
					
					"99-etc-etc-jekyll-customizing": {
						"id": "99-etc-etc-jekyll-customizing",
						"title": "jekyll base-theme 커스터마이징",
						"categories": "99.ETC",
						"url": " /99.etc/etc_jekyll_customizing/",
						"content": "폰트 교체\nbase-theme는 기본 폰트가 Merriweather로 되어 있습니다.\n영어 표기에는 적당하지만, 한글 표기에는 좋지 않아 나눔고딕 폰트로 변경하였습니다.\n\n그리고 폰트 파일을 별도로 추가하기 보다는 구글에서 제공하는 폰트 경로를 설정하는 방식으로 교체했습니다.\n구글에서 제공하는 폰트 리스트와 적용 방법은 아래 사이트에서 확인 가능합니다.\nhttps://fonts.google.com/\n\nhtml 수정\n\n파일 위치 : \\_layouts\\default.html\n&lt;link rel=\"preconnect\" href=\"https://fonts.gstatic.com\"&gt;\n&lt;link href=\"https://fonts.googleapis.com/css2?family=Nanum+Gothic&amp;display=swap\" rel=\"stylesheet\"&gt; \n\n\ncss 수정\n\n파일 위치: \\_sass\\typography.scss\nbody {\n  height: 100%;\n  max-height: 100%;\n  font-family: 'Nanum Gothic', sans-serif;\n  }\n\n\n한글 검색 오류 수정\nbase-theme 기본 설정으로는 한글 등 utf-8 언어 검색이 되지 않습니다.\n그에 따라 몇가지 수정을 하면 한글 검색이 가능해집니다.\n\njs 파일 위치: \\js\\search.js\n\n기존:\nwindow.index = lunr(function () {\n\t\tthis.field(\"id\");\n\t\tthis.field(\"title\", {boost: 10});\n\t\tthis.field(\"categories\");\n\t\tthis.field(\"url\");\n\t\tthis.field(\"content\");\n\t});\n\n수정: \nwindow.index = new lunr.Index;\nwindow.index.field('id');\nwindow.index.field('title', { boost: 10 });\nwindow.index.field('author');\nwindow.index.field('category');\nwindow.index.field('content');\n\n\n다음으로 charset 을 설정합니다.\nhtml 파일 위치 : \\search.html\n기존: \n&lt;script src=\"{{ site.baseurl }}/js/lunr.min.js\"&gt;&lt;/script&gt;\n&lt;script src=\"{{ site.baseurl }}/js/search.js\"&gt;&lt;/script&gt;\n\n수정: \n&lt;script src=\"{{ site.baseurl }}/js/lunr.min.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n&lt;script src=\"{{ site.baseurl }}/js/search.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n\n상단 header bg 교체\n\n파일 위치: \\_sass\\header.scss\n\n기존:\nheader {\n\tbackground: $header-color;\n}\n\n수정: \nheader {\n\tbackground: url(\"/images/ncp-header-bg.png\");\n\tbackground-size: 2200px;\n}\n\n\nlogo 파일 교체\n\n파일 위치: \\_includes\\logo.html\n\n\n기존:\n&lt;svg version=\"1.1\" id=\"Layer_1\" ..중략.. xml:space=\"preserve\"&gt;\n\t ..중략..\n&lt;/svg&gt;\n\n수정:\n&lt;img src=\"/images/title_logo_white.png\" style=\"width:160px;height:33px;margin-top:5px\"&gt;\n\n\n상단 메뉴 수정\n\n파일 위치: \\_data\\navigation.yml\n\n- name: Docs\n  link: /\n  target: _self\n- name: FAQ\n  link: /faq/\n  target: _self\n- name: Company\n  link: https://3rdeyesys.com\n  target: _blank\n\n\n상단 header에 검색 박스 추가\n\n파일 위치: \\_includes\\navigation.html\n\n{% if page.url != \"/\" %}\n\t&lt;span style=\"width:100px\"&gt;\\{% include search.html %}&lt;/span&gt;\n{% endif %}\t\n&lt;/nav&gt;\n\n\n하단 footer social 아이콘 수정\n\n파일 위치: \\_data\\footer.yml\n\n- name:\n  link: https://www.facebook.com/3rdeyesys\n  social_icon: Facebook\n  target: _blank\n- name:\n  link: mailto:biz@3rdeyesys.com\n  social_icon: Email\n  target: _blank\n\n\n코드 블럭 스타일 수정\n\n  첫째줄만 들여쓰기 되는 현상 수정\n  컨텐츠 넓이 정도로 영역이 자동 할당되도록 수정\n  과도한 padding, margin 영역 축소\n\n\n파일 위치: \\_sass\\dark-theme.scss\n\n기존:\n.highlight { \n padding: 10px 15px;\n}\n \n수정: \n.highlight { \n  padding: 7px 30px 7px 10px;\n  display:inline-block;\n}\n\n\n파일 위치: \\_sass\\elements.scss\n\n기존:\ncode, pre, tt {\t\n\tpadding: 2px 5px;\n}\n \n수정: \ncode, pre, tt {\t\n\tmargin: 0px;\n\tdisplay:inline-block;\n}\n\n\n\n  “문서 최종 수정일 : 2021-02-23”"
					}
					
				
			
		
			
				
					,
					
					"5-database-ncp-database-compare": {
						"id": "5-database-ncp-database-compare",
						"title": "설치형 DB서버와 관리형 Cloud DB 비교",
						"categories": "5.database",
						"url": " /5.database/ncp_database_compare/",
						"content": "개요\n서버에 DB가 설치된 상태로 제공되는 설치형 DB서버와 Cloud 형태로 제공되는 관리형 DB서버는 어떤 특징과 차이점이 있는지 확인합니다.\n더불어 비용 비교와 함께 각각의 DB서버를 어떤 경우에 사용하면 좋은지 예시를 통해 DB서버 선택에 도움을 드리고자 합니다.\n\n설치형 DB  특징\n\n  저렴한 비용\n  DB관련 아주 세부적인 부분까지 직접 설정 가능\n\n\n관리형 Cloud DB 특징\n\n  빠르고 손쉬운 설치\n  네이버 클라우드에서 검증된 최적화 설정\n  자동으로 증가하는 데이터 스토리지 (MSSQL : 2TB까지, Mysql : 6000GB까지)\n  장애 발생시 자동 Fail-over를 통한 장애 최소화를 할 수 있는 탁월한 가용성 제공\n  읽기 부하 분산을 위한 읽기 전용 Slave 5개까지 지원\n  자동화된 DB 백업, 최대 30일까지 보관\n  성능 모니터링과 알람\n  원하는 시간을 선택하여 DB 자동 복원 (Mysql)\n  1분 단위의 쿼리 레벨 성능 분석을 지원 (MSSQL)\n\n\n비용 전체 비교\n\n  DB 서버 스펙 : Standard(2 vCPU, 4GB 메모리, 100GB 디스크)\n\n\n\n  \n    \n      DB 구분\n      설치형 DB (서버 비용 포함)\n      관리형 Cloud for DB\n    \n  \n  \n    \n      mysql\n      69,000원/월\n      115,200원/월\n    \n    \n      MSSQL\n      379,000원/월\n      614,880원/월\n    \n  \n\n\n비용 비교 상세 (Mysql)\n\n설치형\n\n  69,000원/월 : 서버 비용 + DB 무료\n\n\n관리형 Cloud\n-115,200원/월 : 160원(시간당) * 24시간(1일) * 30일(한달)\n\n비용 비교 상세 (MSSQL)\n\n설치형\n\n  379,000원/월 : 69,000원(서버) + 20,000원(서버 Windows 라이선스) + 290,000원(MSSQL 라이선스)\n\n\n관리형 Cloud\n\n  614,880원/월 : 854원 (시간당) * 24시간(1일) * 30일(한달)\n\n\n\n  관리형 Cloud for MSSQL에서 HA (Principal-Mirror 구성) 구성을 할 경우, DBMS 라이선스 요금은 마스터/슬레이브 서버에만 적용됩니다.\n\n\n설치형 DB서버를 사용하면 좋은 경우\n\n  사내에 DB전문가가 있을 경우\n  서비스에 최적화된 DB설정을 하고 싶은 경우\n  장애 시 자동 Fail-over가 굳이 필요하지 않은 경우\n  DB백업을 원하는 방식으로 직접 하고 싶은 경우\n  DB 사이즈가 일정 크기 이상으로 늘어나는 것을 원하지 않는 경우\n  서비스 안정성 보다 비용 절감이 더 중요한 경우\n\n\n관리형 Cloud DB를 사용하면 좋은 경우\n\n  장애 시 자동 Fail-over를 통해 서비스 중지 시간을 최소로 하고 싶을 경우\n  DB의 읽기 요청이 많아서 읽기 전용 DB를 마련했을 때 효과가 큰 경우\n  DB백업과 디스크 용량 증설 등이 특별한 작업 없이 자동으로 진행되길 원하는 경우\n  비용보다 서비스 안정성이 더 중요한 경우\n  DB전문가가 없는 경우\n\n\n참고 URL\nhttps://www.ncloud.com/product/database\n\n\n  문서 최종 수정일 : 2021-01-26"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-compare": {
						"id": "4-storage-ncp-storage-compare",
						"title": "스토리지 비교",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_compare/",
						"content": "개요\n네이버 클라우드에서 제공하는 스토리지들의 주요 기능과 용도를 QnA 형식으로 비교 정리해보겠습니다.\n\n비교 대상 스토리지\n\n  Block Storage\n  Object Storage\n  NAS\n  Archive Storage\n\n\n가격 비교\n\n\n  \n    \n      스토리지\n      구분\n      과금 단위\n      시간 당 요금\n      500G 기준 요금\n      기타 사항\n    \n  \n  \n    \n      Block Storage\n      HDD\n      10G\n      0.8원\n      40원\n       \n    \n    \n       \n      SDD\n      10G\n      1.6원\n      80원\n       \n    \n    \n      NAS\n       \n      500G\n      50원\n      50원\n       \n    \n    \n      Object Storage\n      1PB 이하\n      1G\n      0.039원\n      19.5원\n      트래픽, API요청수 요금 별도\n    \n    \n       \n      1PB 초과\n      1G\n      0.036원\n      18원\n      트래픽, API요청수 요금 별도\n    \n    \n      Archive Storage\n       \n      1G\n      0.0076원\n      3.8원\n      트래픽, API요청수 요금 별도\n    \n  \n\n\nQnA\n서버에 디스크를 추가하고 싶을 때는 어떤 스토리지를 사용하면 되나요?\nBlock Storage를 사용하면 됩니다.\nConsole - Server - 서버 상세 정보 - 스토리지 생성 메뉴에서 스토리지를 추가하고 서버에 마운트해서 사용하시면 됩니다.\n\n서버당 디스크는 최대 얼마까지 추가할 수 있나요?\n네이버 클라우드에서 서버에 직접 추가되는 디스크는 Block Storage로 최대 2,000GB를 지원하며, 서버 1대당 최대 16개의 스토리지를 추가할 수 있습니다.\n\n디스크를 추가할 수 없는 서버도 있나요?\n네이버 클라우드에서 서버에 직접 추가되는 디스크는 Block Storage로 Micro 타입의 서버, Bare Metal 서버, Application Server Launcher는 Block Storage를 추가할 수 없습니다.\n\n여러 서버에서 공용으로 사용할 스토리지가 필요합니다.\nNAS 서비스를 이용하시면 됩니다.\n서버 간 데이터 공유, 대용량 스토리지, 유연한 용량 확대/축소, 스냅샷 백업 등 NAS 서비스의 주요 기능을 활용해 안전하고 편리하게 데이터를 관리할 수 있습니다.\n특히, 프로토콜에 따른 인증 설정으로 높은 보안성을 제공하고, 이중화된 Controller 및 Disk Array Raid 구성으로 강력한 서비스 안정성을 확보하고 있습니다.\n\n유저가 업로드 하는 이미지를 저장하고 싶습니다.\nBlock Storage, Object Storage, NAS 모두 가능합니다만 용도에 따라 선택하시면 되겠습니다.\n매우 빠른 응답 속도가 필요하면 Block Storage.\n저렴한 비용과 여러 서버에서 동시에 이미지를 저장해야 한다면 Object Storage.\n\n백업 자료를 오랜기간 보관해 두고 싶습니다.\nArchive Storage를 이용하시면 됩니다.\nArchive Storage는 높은 내구성과 저렴한 비용이 특징인 데이터 아카이빙 및 장기 백업에 최적화된 스토리지 서비스입니다.\n\nAWS S3와 비슷한 스토리지는 어떤 건가요?\nObject Storage입니다.\n네이버 클라우드의 Object Storage는 AWS의 S3에서 사용하는 API와 호환이 되므로 쉽게 사용하실 수 있습니다.\n\nCDN를 서비스를 이용하려면 어떤 스토리지를 사용해야 하나요?\nObject Storage를 사용하시면 됩니다.\n물론 CDN의 원본 서버로 설정할 수 있는 것은 자체 웹 서버 및 네이버 클라우드 Object Storage, Server 등이 있는데, 그 중에서도 Object Storage를 사용하시는 것이 가장 쉽고 안정적입니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/storage-storage-5-1.html\n\n\n  문서 최종 수정일 : 2020-12-28"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-connect-by-public-ip": {
						"id": "1-compute-ncp-server-connect-by-public-ip",
						"title": "서버 접속 가이드(Linux) - 공인IP 있을 때",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_connect_by_public_ip/",
						"content": "개요\n네이버 클라우드에서 리눅스 서버에 접속하는 방법 중에서 공인아이피가 있을 때 접속하는 방법에 대한 내용을 정리하였습니다.\n여기서는 서버에 접속하는 방법을 정리하기 때문에 이미 서버는 생성되어 있다는 전제하게 정리하게 됩니다.\n\n요약\n우선은 전체 과정을 텍스트로 간단하게 요약해서 살펴보고 스크린샷을 포함한 상세 과정은 아래쪽에서 살펴보겠습니다.\n\n\n  포트 포워딩 설정 해제 (설정되어 있을 경우)\n  관리자(root) 비밀번호 확인\n  터미널 프로그램(Putty) 실행\n  공인IP로 접속\n  위 2번 관리자 비밀번호 확인에서 기록한 비번 입력\n\n\n포트 포워딩 설정 해제 (설정되어 있을 경우)\n\n네이버 클라우드에서는 Server, Bare Metal Server에서 공인 IP와 포트 포워딩을 동시에 사용하면 22(Linux), 3389(Windows) 포트가 포트 포워딩에 먼저 할당되므로 공인 IP에서 해당 포트 사용이 불가해집니다.\n즉, 포트 포워딩이 설정된 상태에서는 Putty로 접속할 때 공인IP로는 22, 3389 포트가 접속 되지 않는다는 뜻입니다.\n그러므로, 공인 IP로 22, 3389 포트에 접속하는 경우에는 포트 포워딩을 해제하시고,\n포트 포워딩을 설정하지 않았다면 다음 순서인 관리자(root) 비밀번호 확인으로 바로 이동하시면 되겠습니다.\n\n\n포트 포워딩을 해제 하시려면 아래 화면처럼 설정된 포트 포워딩에서 삭제 버튼을 클릭하시고 하단의 적용 버튼을 클릭합니다.\n\n\n관리자 비밀번호 확인\n\n네이버 클라우드에서 처음 서버를 생성하고 접속하게 되면 root와 비밀번호로 접속하게 됩니다.\n물론 매번 비번을 입력하고 접속하는 것은 번거롭기도 하고 보안 측면에서 좋지 않기 때문에 이후에 SSH Key를 생성해서 접속하는 방식으로 바꾸는 것이 좋습니다.\n\n\n관리자 비밀번호 확인 메뉴를 클릭하면 인증키를 확인하는 화면이 나옵니다.\n인증키는 서버 생성시에 설정하고 PC에 다운로드 해 둔 확장지 *.pem 파일입니다. \n\n\n인증키 파일을 마우스로 끌어오거나 화면을 클릭해서 선택합니다.\n\n\n인증키가 일치하면 아래와 같이 root 계정에 해당하는 비밀번호가 나타납니다.\n이 비밀번호를 복사하여 저장해둡니다.\n혹시 복사-저장하는 것을 잊으셨어도 언제든지 관리자 비밀번호 확인 메뉴에 들어가서 인증키를 인증하면 다시 확인할 수 있으니 걱정하지 않으셔도 됩니다.\n\n\n터미널 프로그램(Putty) 실행\n\nPutty를 실행해서 공인IP를 입력합니다. \n\n\n접속을 하면 rsa2 key fingerprint 를 Putty 캐시에 저장할 것인지 묻는 화면이 나타납니다. \n보통 예(Y)를 선택하면 됩니다.\n\n\nroot 계정과 관리자 비밀번호 입력\n\n계정 root와 관리자 비밀번호 확인에서 저장해 둔 비밀번호를 입력합니다.\n\n\n접속이 완료되면 이렇게 화면이 나타납니다.\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-3-1-v2.html\n\n\n  문서 최종 수정일 : 2020-12-22"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-connect-no-public-ip": {
						"id": "1-compute-ncp-server-connect-no-public-ip",
						"title": "서버 접속 가이드(Linux) - 공인IP 없을 때",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_connect_no_public_ip/",
						"content": "개요\n네이버 클라우드에서 리눅스 서버에 접속하는 방법 중에서 공인아이피가 없을 때 접속하는 방법에 대한 내용을 정리하였습니다.\n여기서는 서버에 접속하는 방법을 정리하기 때문에 이미 서버는 생성되어 있다는 전제하게 정리하게 됩니다.\n또한, Classic 과 VPC 환경 중에서 VPC는 포트 포워딩이 없고 공인 IP로만 접속하기 때문에 아래에서 설명하는 내용은 Classic 환경 기준입니다.\n\n요약\n우선은 전체 과정을 텍스트로 간단하게 요약해서 살펴보고 스크린샷을 포함한 상세 과정은 아래쪽에서 살펴보겠습니다.\n\n\n  포트 포워딩 설정\n  관리자(root) 비밀번호 확인\n  터미널 프로그램(Putty) 실행\n  위 1번 포트 포워딩에서 설정한 포트와 IP로 접속\n  위 2번 관리자 비밀번호 확인에서 기록한 비번 입력\n\n\n포트 포워딩 설정\n\n네이버 클라우드에서 공인IP 없이 서버에 접속하려면 외부 접속을 위한 포트 포워딩을 설정해야 합니다.\n생성된 서버를 선택하면 상단 메뉴에 포트 포워딩 설정이 있습니다.\n\n\n포트 포워딩 메뉴에 들어가면 아래와 같이 서버 접속용 공인 IP가 보이고, 외부에서 접속할 포트 (Putty에 입력할 포트)를 입력하는 곳이 있습니다.\n\n\n포트 포워딩에서 사용할 수 있는 포트 번호 범위는 1,024 ~ 65,534 이며, 이 범위 내에서 원하는 포트를 입력하시면 됩니다.\n(Tip: 서버 접속용 공인IP를 활용해서 포트 번호를 입력하면 기억하기 쉽습니다. )\n(예: OOO.12.45.178 인 경우 포트를 17822,  106.10.OO.OO 인 경우 10622 )\n\n포트를 입력하고 +추가 버튼을 클릭합니다.\n\n\n추가된 포트와 서버 접속용 공인 IP 정보를 확인하고 수정할 부분이 있으면 수정합니다.\n더 이상 수정할 내용이 없으면 하단의 적용 버튼을 반드시 클릭합니다.\n\n\n\n관리자 비밀번호 확인\n\n네이버 클라우드에서 처음 서버를 생성하고 접속하게 되면 root와 비밀번호로 접속하게 됩니다.\n물론 매번 비번을 입력하고 접속하는 것은 번거롭기도 하고 보안 측면에서 좋지 않기 때문에 이후에 SSH Key를 생성해서 접속하는 방식으로 바꾸는 것이 좋습니다.\n\n\n관리자 비밀번호 확인 메뉴를 클릭하면 인증키를 확인하는 화면이 나옵니다.\n인증키는 서버 생성시에 설정하고 PC에 다운로드 해 둔 확장지 *.pem 파일입니다. \n\n\n인증키 파일을 마우스로 끌어오거나 화면을 클릭해서 선택합니다.\n\n\n인증키가 일치하면 아래와 같이 root 계정에 해당하는 비밀번호가 나타납니다.\n이 비밀번호를 복사하여 저장해둡니다.\n혹시 복사-저장하는 것을 잊으셨어도 언제든지 관리자 비밀번호 확인 메뉴에 들어가서 인증키를 인증하면 다시 확인할 수 있으니 걱정하지 않으셔도 됩니다.\n\n\n터미널 프로그램(Putty) 실행\n\nPutty를 실행해서 포트 포워딩에서 설정한 포트와 서버 접속용 공인IP를 입력합니다\n\n\n접속을 하면 rsa2 key fingerprint 를 Putty 캐시에 저장할 것인지 묻는 화면이 나타납니다. \n보통 예(Y)를 선택하면 됩니다.\n\n\nroot 계정과 관리자 비밀번호 입력\n\n계정 root와 관리자 비밀번호 확인에서 저장해 둔 비밀번호를 입력합니다.\n\n\n접속이 완료되면 이렇게 화면이 나타납니다.\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-3-1-v2.html\n\n\n  문서 최종 수정일 : 2020-12-21"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-http-to-https-ubuntu": {
						"id": "1-compute-ncp-http-to-https-ubuntu",
						"title": "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Ubuntu",
						"categories": "1.compute",
						"url": " /1.compute/ncp_http_to_https_ubuntu/",
						"content": "개요\n웹사이트 SSL 인증서를 설치하고 https 접속을 유도할 때 http로 접속하면 https로 강제로 리다이렉트 시키는 방법을 사용하는 경우가 많습니다.\n웹페이지 소스에서 http 접속 여부를 판단해서 redirect 시키는 방법 등 여러가지 있을 수 있는데 여기서는 Apache 설정으로 쉽게 할 수 있는 방법을 소개합니다.\n\nSSL 인증서가 설치되어 있다는 가정하에 우선 Linux Ubuntu에서 설정하는 방법을 확인해보겠습니다.\n\nRewrite 모듈 설치\n혹시 Apache에 이미 mod_rewrite 가 로드 되어 있다면 설치하지 않아도 됩니다.\n\nroot@test-lamp:~# a2enmod rewrite\n\n\nApache conf 파일 수정\n\n/etc/apache2/sites-enabled/000-default.conf 의 Vritual host에 다음 코드를 추가하고 Apache를 재시작하면 됩니다.\nRewriteEngine On\nRewriteCond %{HTTPS} !on\nRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R,L]\n\n\n000-default.conf 파일에 실제로 적용하면 다음과 비슷한 모습이 되겠습니다.\n&lt;VirtualHost *:80&gt;\n\tDocumentRoot \"/ncp/data/www/\"\n\tServerName www.test.com\n\n\tRewriteEngine On\n\tRewriteCond %{HTTPS} !on\n\tRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R,L]\n&lt;/VirtualHost&gt;\n\n\nApache 재시작\nroot@test-lamp:~# systemctl restart apache2\n\n이렇게 재시작하고 http로 접속을 해보면 https로 전환되는 것을 확인할 수 있습니다.\n\nApache 재시작 오류 - SSLEngine\n위 내용처럼 아파치 재시작 명령어를 입력하면 끝입니다만, 재시작이 되지 않고 오류 메시지가 뜨는 경우가 있습니다.\nroot@test-lamp:~# systemctl restart apache2\nJob for apache2.service failed because the control process exited with error code. \nSee \"systemctl status apache2.service\" and \"journalctl -xe\" for details.\n\n\n오류 메시지에 나온 것 처럼 상세 내용을 확인해봅니다.\nroot@test-lamp:~# systemctl status apache2.service\n\n상세 오류 메시지 중에서 핵심 내용만 살펴보면 다음과 같습니다.\nDec 04 16:09:44 test-lamp apachectl[11924]: AH00526: Syntax error on line 36 of /etc/apache2/sites-enabled/000-default.conf:\nDec 04 16:09:44 test-lamp apachectl[11924]: Invalid command 'SSLEngine', perhaps misspelled or defined by a module not included in the server configuration\n\n\n위 오류 메시지에 나온 /etc/apache2/sites-enabled/000-default.conf 파일을 찾아가서 SSLEngine을 확인해보면 다음과 같습니다.\n&lt;VirtualHost *:443&gt;\n    ServerName www.test.com\n    ServerAdmin web@test.com\n\n    {==SSLEngine on==}\n    SSLCertificateFile /etc/******/server.crt\n    SSLCertificateKeyFile /etc/******/server.key\n\n    ###중략###\n&lt;/VirtualHost&gt;\n\n\n확인해보면 SSLEngine on 명령어가 제대로 동작하지 못해서 생긴 문제라는 것을 알 수 있습니다.   \n즉, SSL 모듈이 제대로 활성화 되지 않았기에 활성화 해주면 문제가 해결됩니다.\n(나중에 살펴보면 socache_shmcb 모듈이 활성화되지 않았기 때문임을 알 수 있습니다)\n\nSSL 엔진 모듈 활성화\nroot@test-lamp:~# a2enmod ssl\n\n\n그리고 나서 다시 Apache를 재시작 하면 됩니다.\nroot@test-lamp:~# systemctl restart apache2\n\n\n이제 http로 접속하셔서 https로 전환되는지 확인해보시기 바랍니다.\n\n\n  문서 최종 수정일 : 2020-12-07"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-http-to-https-centos": {
						"id": "1-compute-ncp-http-to-https-centos",
						"title": "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/CentOS",
						"categories": "1.compute",
						"url": " /1.compute/ncp_http_to_https_centos/",
						"content": "개요\n웹사이트 SSL 인증서를 설치하고 https 접속을 유도할 때 http로 접속하면 https로 강제로 리다이렉트 시키는 방법을 사용하는 경우가 많습니다.\n웹페이지 소스에서 http 접속 여부를 판단해서 redirect 시키는 방법 등 여러가지 있을 수 있는데 여기서는 Apache 설정으로 쉽게 할 수 있는 방법을 소개합니다.\n\nSSL 인증서가 설치되어 있다는 가정하에 우선 Linux CentOS에서 설정하는 방법을 확인해보겠습니다.\n\nApache conf 파일 수정\n\n/etc/httpd/conf/httpd.conf 의 Vritual host에 다음 코드를 추가하고 Apache를 재시작하면 됩니다.\nRewriteEngine On\nRewriteCond %{HTTPS} !on\nRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R,L]\n\n\nhttpd.conf 파일에 실제로 적용하면 다음과 비슷한 모습이 되겠습니다.\n&lt;VirtualHost *:80&gt;\n\tDocumentRoot \"/ncp/data/www/\"\n\tServerName www.test.com\n\n\tRewriteEngine On\n\tRewriteCond %{HTTPS} !on\n\tRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R,L]\n&lt;/VirtualHost&gt;\n\n\nApache 재시작\nroot@test-lamp-2:~# systemctl restart  httpd.service\n\n이렇게 재시작하고 http로 접속을 해보면 https로 전환되는 것을 확인할 수 있습니다.\n\nApache 재시작 오류\n위 내용처럼 아파치 재시작 명령어를 입력하면 끝입니다만, 재시작이 되지 않고 오류 메시지가 뜨는 경우가 있습니다.\nroot@test-lamp-2:~# systemctl restart  httpd.service\nJob for httpd.service failed because the control process exited with error code.  \nSee \"systemctl status httpd.service\" and \"journalctl -xe\" for details.\n\n\n오류 메시지에 나온 것 처럼 상세 내용을 확인해봅니다.\nroot@test-lamp-2:~# systemctl status httpd.service\n\n상세 오류 메시지 중에서 핵심 내용만 살펴보면 다음과 같습니다.\nDec 04 17:24:48 test-lamp-2 httpd[3217]: httpd: Syntax error on line 552 of /etc/httpd/conf/httpd.conf: Could not open configuration ...irectory\n\n\n위 오류 메시지에 나온 /etc/httpd/conf/httpd.conf 파일을 찾아가서 해당 라인을 확인해보면 다음과 같습니다.\n#&lt;IfModule ssl_module&gt;\n# Secure (SSL/TLS) connections\nInclude conf/extra/httpd-ssl.conf\n#&lt;/IfModule&gt;\n\n\n위에 나온 Include conf/extra/httpd-ssl.conf 라인을 주석처리 하면 해결이 됩니다.\n\n#&lt;IfModule ssl_module&gt;\n# Secure (SSL/TLS) connections\n#Include conf/extra/httpd-ssl.conf\n#&lt;/IfModule&gt;\n\n\n그리고 나서 다시 Apache를 재시작 하면 됩니다.\nroot@test-lamp-2:~# systemctl restart  httpd.service\n\n\n이제 http로 접속하셔서 https로 전환되는지 확인해보시기 바랍니다.\n\nSSL 모듈 설치\n혹시 Apache에 mod_ssl 가 설치되어 있지 않다면 설치하셔야 합니다.\n\n[root@test-lamp-2 ~]# yum install mod_ssl\n\n\n설치 도중에 아래와 같은 확인 화면이 나타납니다.\n========================================================================\n Package   Arch       Version                 Repository   Size\n========================================================================\nInstalling:\n mod_ssl    x86_64   1:2.4.6-97.el7.centos   updates    114 k\n\nTransaction Summary\n========================================================================\nInstall  1 Package\n\nTotal download size: 114 k\nInstalled size: 224 k\nIs this ok [y/d/N]:\n\n\n별 문제 없으면 y 를 입력하면 됩니다.\nIs this ok [y/d/N]: y\n\nDownloading packages:\nmod_ssl-2.4.6-97.el7.centos.x86_64.rpm                    | 114 kB  00:00:00\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : 1:mod_ssl-2.4.6-97.el7.centos.x86_64        1/1\n  Verifying  : 1:mod_ssl-2.4.6-97.el7.centos.x86_64        1/1\n\nInstalled:\n  mod_ssl.x86_64 1:2.4.6-97.el7.centos\n\nComplete!\n\n\n\n  문서 최종 수정일 : 2020-12-07"
					}
					
				
			
		
			
				
					,
					
					"3-security-ncp-security-service-summary": {
						"id": "3-security-ncp-security-service-summary",
						"title": "Security 서비스 요약",
						"categories": "3.security",
						"url": " /3.security/ncp_security_service_summary/",
						"content": "개요\n네이버 클라우드에서 제공하는 Security 서비스 상품들을 간단한 설명과 함께 요약 정리한 내용입니다.\n이 내용도 파트너 테크데이에서 공개된 자료입니다.\n\n서비스 요약\n\n\n  \n    \n      구분\n      상품\n      설명\n    \n  \n  \n    \n      침입탐지/대응\n      Basic Security\n      모든 고객에게 기본으로 제공되는 무료 보안 서비스\n    \n    \n       \n      Security Monitoring\n      IDS, Anti-DDos, Anti-Virus, IPS, WAF와 같은 다양한 보안 상품들을 이용하여 높은 수준의 보안 서비스를 제공\n    \n    \n       \n      Site Safer\n      고객이 개발한 웹사이트가 해킹 또는 다른 보안 문제로 인해 악성코드를 배포하는지 검사\n    \n    \n       \n      File Safer\n      고객의 서비스에서 제공하는 파일과 아웃링크 URL의 악성코드 감염 여부를 해시 기반으로 검사\n    \n    \n       \n      App Safer\n      고객의 앱이 모바일에서 실행될 때, 루팅/탈옥, 악성 앱 설치, 앱 변조 등 보안 위협 여부를 실시간으로 탐지\n    \n    \n       \n      Webshell Behavior Detector\n      고객의 웹 서비스를 공격하는 다양한 웹셀을 행위기반으로 실시간 탐지하는 서비스\n    \n    \n      접근제어\n      ACG\n      인스턴스 그룹 단위로 IP, Port 기반의 네트워크 패킷 필터링 기능을 제공\n    \n    \n       \n      Secure Zone\n      개인정보와 같이 중요한 정보를 보다 더 안전하게 보호할 수 있도록 대외 인터넷 망과 분리된 별도의 존을 제공\n    \n    \n      인증/권한 관리\n      Sub Account\n      사용자 업무 역할별로 권한 관리를 할 수 있는 기능 제공\n    \n    \n      암호화\n      KMS\n      고객 데이터의 암/복호화에 이용되는 키를 안전하게 보호할 수 있는 서비스\n    \n    \n       \n      SSL VPN\n      고객 사이트로 안전하게 접근 가능한 SSL방식의 가상 사설망을 제공\n    \n    \n       \n      Certificate Manager\n      SSL 인증서의 손쉬운 등록 및 관리 서비스를 제공\n    \n    \n      로깅 및 모니터링\n      Resource Manager\n      네이버 클라우드 서비스 내에 생성한 모든 리소스를 한 눈에 볼 수 있는 통합관리 서비스\n    \n    \n       \n      Cloud Activity Tracer\n      네이버 클라우드 서비스에서 발생한 계정 활동 로그를 자동으로 수집해주는 서비스\n    \n    \n       \n      Cloud Advisor\n      네이버 클라우드 모범 사례에 따른 서비스 이용 권장 지침 안내\n    \n    \n      취약점 관리\n      System Security Checker\n      고객 서버의 운영체제 및 WAS 시스템에 대해서 보안상 취약점이 없는지 점검하고 결과 리포트를 제공해주는 서비스\n    \n    \n       \n      Web Security Checker\n      고객의 웹서비스에 대해 총 20가지의 주요 웹 취약점을 자동으로 진단하고 결과 리포트를 제공해주는 서비스\n    \n    \n       \n      App Security Checker\n      고객의 Andorid 모바일 앱에 대해 취약점을 자동으로 점검하고 결과 리포트를 제공해주는 서비스\n    \n    \n      Compliance\n      Compliance Guide\n      고객이 보안 인증이나 규제에 대응하는데 필요한 사항을 알기 쉽게 정리한 가이드\n    \n  \n\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/security-security-1-1.html\n\n\n  문서 최종 수정일 : 2021-04-26"
					}
					
				
			
		
			
				
					,
					
					"3-security-ncp-security-ncp-onpremise-compare": {
						"id": "3-security-ncp-security-ncp-onpremise-compare",
						"title": "(Security) Ncloud vs On-Premise 비교",
						"categories": "3.security",
						"url": " /3.security/ncp_security_ncp_onpremise_compare/",
						"content": "개요\n기존의 IDC 등의 On-Premise 환경에서 사용하고 있는 보안 서비스를 네이버 클라우드 환경에서 어떻게 구현할 수 있는지에 대한 비교 가이드입니다.\nIDC에 있는 서버들을 네이버 클라우드로 마이그레이션 할 때 참고하시면 되겠습니다.\n\nOn-Premise → Naver Cloud\n\n\n  \n    \n      구분\n      On-Premise\n       \n      Naver Cloud\n      설명\n    \n  \n  \n    \n      Network\n      DDos\n      →\n      Security Monitoring\n      Security Monitoring DDos 서비스를 통해 고객별 특화된 탐지 정책을 적용\n    \n    \n       \n      방화벽\n      →\n      ACG(Access Control Group)\n      ACG Rule 변경 기능으로 서버 접속을 허용할 트래픽 규칙을 안전하고 편리하게 관리\n    \n    \n       \n      IDS/IPS\n      →\n      Security Monitoring\n      Security Monitoring IDS/IPS 서비스를 통해 고객별 특화된 탐지/차단 정책을 적용\n    \n    \n       \n      전송구간 암호화\n      →\n      IPSec/SSL VPN, Cloud Connect\n      고객의 네트워크와 네이버 클라우드에 있는 네트워크에 대한 안전한 연결을 제공\n    \n    \n      DB\n      DB 접근 통제\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n       \n      DB 암호화\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n      Server\n      서버접근통제\n      →\n      SSL VPN, Naver Cloud MarketPlace\n      SSL VPN을 이용해 서버 접근을 관리  MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n       \n      서버보안(SecureOS)\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n       \n      Anti Virus\n      →\n      Security Monitoring\n      Security Monitoring DDos 악성코드 의심 이벤트 발생 시 탐지 보고서 및 분석 정보 전달\n    \n    \n      Application\n      웹 방화벽\n      →\n      Security Monitoring\n      Security Monitoring WAF서비스를 통해 고객별 특화된 탐지/차단 정책을 적용\n    \n    \n       \n      Anti-Webshell\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n      User Access\n      사용자 접근통제\n      →\n      Sub Account\n      Sub Account 서비스를 이요하여 콘솔 접근에 대한 사용자 접속을 관리\n    \n    \n      Audit\n      -\n      →\n      Cloud Activity Tracer / Resource Manager\n      리소스(서버, 네트워크, DB등) 생성, 변경, 삭제에 대해 추적 기능을 제공\n    \n    \n      Key Management\n      -\n      →\n      Key Management Service\n      Key에 대한 접근 제어 기능을 이용하여 데이터 암호화 키를 안전하게 보호하고 관리\n    \n  \n\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/security-security-1-1.html\n\n\n  info “문서 최종 수정일 : 2020-12-02”"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-vpc-subnet-natgw": {
						"id": "2-networking-ncp-networking-vpc-subnet-natgw",
						"title": "Subnet 과 NAT GW",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_vpc_subnet_natgw/",
						"content": "개요\n네이버 클라우드에서는 VPC의 보안을 강화하기 위해 두 가지 서브넷을 제공하고 있습니다.\n\n\n  Public Subnet : 인터넷과 자유로운 통신이 필요할 때 사용할 수 있는 서브넷으로 Interget GW를 통해 외부와 통신\n  Private Subnet : 보안상 외부에서 서버에 접근하는 것을 막아야 할 때 사용할 수 있는 서브넷으로 NAT GW를 통해 외부와 통신\n\n\nPublic vs Private Subnet\n\n\n  \n    \n      구분\n      Public Subnet\n      Private Subnet\n    \n  \n  \n    \n      용도\n      인터넷 연결이 필요할 때\n      외부 접속을 최소화 해야 할 때\n    \n    \n      지원 리소스\n      서버\n      서버, 로드밸런서\n    \n    \n      인터넷 연결 시필요한 리소스\n      Internet Gateway (Default)\n      NAT Gateway\n    \n  \n\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-networking-10-1.html\n\n\n  문서 최종 수정일 : 2020-12-01"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-vpc-load-balancer": {
						"id": "2-networking-ncp-networking-vpc-load-balancer",
						"title": "Load Balancer 상품군의 변화",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_vpc_load_balancer/",
						"content": "개요\nLoad Balancer는 수신 트래픽을 다수의 서버로 분산시키는 서비스로서, 수신 트래픽을 등록된 멤버 서버로 분산시켜 가용성을 높이고 시스템 가동률을 조절하는 역할을 수행합니다.\nVPC 플랫폼에서는 Network Load Balancer / Application Load Balancer / Network Proxy Load Balancer 가 제공되어 서비스에 적합한 로드밸런서를 선택할 수 있습니다.\n\n종류\n\n\n  \n    Application Load Balancer\nHTTP 및 HTTPS 트래픽을 사용하는 웹 애플리케이션을 위한 유연한 기능을 제공\n  \n  \n    Network Load Balancer\nDSR(Direct Server Return) 구조의 고성능, 대규모 네트워크 연결에 적합한 로드밸런서로 고정 IP를 제공\n  \n  \n    Network Proxy Load Balancer\nTCP 세련 유지에 최적화 되어 있으며, Network Load Balancer와 다르게 DSR를 지원하지 않으며, Load Balander가 세션을 관리.\n  \n\n\n\n  KR존/서브넷 별 LB 생성지역 지정 가능\n\tVPC 환경에서는 내가 원하는 KR존의 특정 서브넷에 LB생성 가능, KR-1/2 존에 각각 생성하여 고가용성을 확보 할 수 있다.\n\n\nLB 선택 기준 및 기능 비교\n\n\n  \n    \n      기능\n      Network LB\n      Network Proxy LB\n      Application\n    \n  \n  \n    \n      프로토콜\n      TCP\n      TCP, TLS\n      HTTP/HTTPS\n    \n    \n      상태확인\n      O\n      O\n      O\n    \n    \n      로깅\n      X\n      O\n      O\n    \n    \n      DSR\n      O\n      X\n      X\n    \n    \n      동일 인스턴스의여러 포트로로드밸런싱\n      X\n      X\n      O\n    \n    \n      HTTP 2.0\n      N/A\n      N/A\n      O\n    \n    \n      경로기반 라우팅\n      N/A\n      N/A\n      O (출시 예정)\n    \n    \n      SSL Offload\n      X\n      O\n      O\n    \n    \n      고정 세션\n      X\n      O\n      O\n    \n  \n\n\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-loadbalancer-loadbalanceroverview.html\n\n\n  문서 최종 수정일 : 2020-12-01"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-vpc-acg-nacl": {
						"id": "2-networking-ncp-networking-vpc-acg-nacl",
						"title": "ACG와 NACL 비교",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_vpc_acg_nacl/",
						"content": "개요\n네이버 클라우드에서는 VPC의 보안을 강화하기 위해 ACG와 NACL의 두 가지 보안 정책을 제공하고 있습니다.\n\n\n  ACG : Access Control Group은 서버의 NIC별 Inbound 및 Outbound 트래픽을 제어\n  NACL : Network Access Control List는 Subnet의 Inbound 및 Outbound 트래픽을 제어\n\n\nACG vs NACL\n\n\n  \n    \n      구분\n      ACG\n      NACL\n    \n  \n  \n    \n      적용 대상\n      서버의 접근 제어\n      Subnet의 접근 제어\n    \n    \n      지원 규칙\n      허용 (Allow)\n      허용 및 거부 (Allow / Deny)\n    \n    \n      상태 저장 여부\n      상태 저장(Stateful)(규칙에 관계없이 반환 트래픽이자동으로 허용됨)\n      상태 비저장(Stateless)(반환 트래픽이 규칙에 의해명시적으로 허용되어야 함)\n    \n    \n      적용 방법\n      서버의 NIC에 ACG 정책 적용\n      Subnet 단위로 적용(Subnet 별 1개만 허용)\n    \n  \n\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailedsubnet.html\n\n\n  문서 최종 수정일 : 2020-12-01"
					}
					
				
			
		
			
				
					,
					
					"2-networking-ncp-networking-vpc": {
						"id": "2-networking-ncp-networking-vpc",
						"title": "VPC 구성요소",
						"categories": "2.networking",
						"url": " /2.networking/ncp_networking_vpc/",
						"content": "개요\n이 문서는 VPC를 구성하는 요소들에 대한 설명으로 네이버 클라우드 파트너 테크데이에서 발표된 내용을 정리한 것입니다.\n\nVPC\nVPC(Virtual Private Cloud)는 퍼블릭 클라우드 상에 논리적으로 완전하게 분리된 고객전용 네트워크를 제공하는 서비스.\n최대 /16의 IP 네트워크 공간을 제공 (IP 대역: RFC 1918).\n\n@ RFC 1918 IP대역\n\n10.0.0.0/8 (10.0.0.0 - 10.255.255.255)  \n172.16.0.0/12 (172.16.0.0 - 172.31.255.255)  \n192.168.0.0/16 (192.168.0.0 - 192.168.255.255)\n\n\nSubnet (Internet Gateway)\n할당된 VPC를 용도에 맞게 네트워크 공간을 세분화 하여 사용.\n/16 ~ /28의 네트워크 주소 할당이 가능.\nPublic Subet 생성 시 Internet Gateway가 연결됨.\n\nNAT Gateway\nNetwork Address Translation의 약자로, 폐쇄된 네트워크에서 외부와의 인터넷 동신 시 사용하는 게이트웨이.\n\nRoute Table\n네트워크 경로를 설정할 수 있는 기능을 제공. VPC 내부 통신을 위한 Local은 기본적으로 설정.\n\nACG\n서버에서 인바운드/아웃바운드의 네트워크 접근제어를 지원하며 Stateful 기반으로 동작.\n\nNACL\nNetwork Access Control List의 약자로, Subnet에서 인바운드/아웃바운드의 네트워크 접근제어를 지원하며 Stateless 기반으로 동작.\n\nVirtual Private Gateway\nCloud Connect와 IPSec VPN에 연결되는 네이버 클라우드의 VPC측 연결 접점으로서 Cloud Connect와 IPSec VPN 연결을 지원.\n\nVPC Peering\nVPC간 사설연결을 보장하는 기능으로, 일반적인 VPC &lt;-&gt; VPC 간의 통신은 인터넷을 통하게 되고, 이는 과다한 요금 발생 및 성능 저하를 일으킬 수 있음.\nVPC Peering을 이용하면 보다 안전한 사설 IP기반의 통신이 가능함.\nVPC Peering은 단방향 통신을 제공하기 때문에 양방향 통신을 원하면 Src -&gt; Dest 별로 각각 1개씩, 두개의 정책을 모두 적용해야 함.\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcoverview.html\n\n\n  문서 최종 수정일 : 2020-11-30"
					}
					
				
			
		
			
				
					,
					
					"99-etc-etc-mkdocs-install": {
						"id": "99-etc-etc-mkdocs-install",
						"title": "mkdocs  설치 (윈도 10)",
						"categories": "99.ETC",
						"url": " /99.etc/etc_mkdocs_install/",
						"content": "설치 전체과정 요약\n\n\n  \n    Python 다운로드\n  \n  \n    Python 설치\n\n    2-1. Add Python 3.9 to PATH 옵션 선택\n\n    2-2. Disable path length limit 선택\n  \n  \n    mkdocs 설치\n\n    3-1. pip install mkdocs-material\n\n    3-2. python.exe -m pip install –upgrade pip\n\n    3-3. pip install mkdocs-awesome-pages-plugin\n\n    3-4. mkdocs new {폴더명}\n\n    3-5. cd blog-mkdocs 이동 후 mkdocs serve\n  \n\n\nPython 다운로드\nmkdocs를 사용하려면 먼저 Python을 설치해야 합니다.\n\nhttps://www.python.org/downloads/\n\n2020-11-27일 현재 최신버전은 3.9.0입니다.\n\nPython 설치하기\n\nPATH 추가\nPython 설치 시작화면에 PATH에 python을 추가하는 옵션이 있습니다. \n“Add Python 3.9 to PATH” 옵션을 선택하고 설치를 시작하면 됩니다.\n\nPATH 문자 길이 제한 해제\n윈도에는 기본설정에 파일경로가 최대 260자로 제한되어 있는데, 이 제한을 풀것인지 확인하는 과정입니다.\n“Disable path length limit” 옵션이 나오는데, 특별한 문제가 없다면 해제하고 가면 됩니다.\n\nmkdocs 설치\nmkdocs 설치하는 방법이 여러가지 있지만 가장 많이 사용되는 테마인 material 테마를 적용한 상태로 설치합니다.\npip install mkdocs-material\n\n\npip 업그레이드\nmkdocs를 설치하고 나면 pip 업그레이드에 대한 안내가 나옵니다.\nWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the 'c:\\users\\{***}\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n\n안내에 나온대로 pip를 업그레이드 해줍니다.\npython.exe -m pip install --upgrade pip\n\n\nawesome-pages-plugin 설치\n문서 구조나 네비게이션을 좀 더 쉽게 표현하고 구성하게 해주는 플러그인입니다.\n기본적으로 설치해두는 것이 여러모로 편리합니다.\npip install mkdocs-awesome-pages-plugin\n\n\n블로그 문서 생성\n이제 기본으로 필요한 것들은 다 설치했으니 블로그를 만들어봅시다.\nmkdocs new {폴더명}\nmkdocs new blog-mkdocs\n\n\n블로그 실행\n이제 웹브라우져에서 블로그를 확인해봅시다.\n위에서 만들어진 폴더로 이동합니다.\ncd blog-mkdocs\nmkdocs serve\n\n\n그러면 http://127.0.0.1:8000 주소로 접속하면 기본 블로그를 확인해볼 수 있고 \nmkdocs serve 명령으로 문서 변경을 실시간으로 감지해서 문서를 수정하면 브라우져에 바로바로 반영됩니다.\n\n블로그 배포문서 생성\n이제 만들어진 블로그 문서를 github 등이나 기타 서버로 배포하려면 다음과 같은 명령어를 입력하면 됩니다.\nmkdocs build\n\n그러면 아까 만들어진 blog-mkdocs 폴더 밑에 site 라는 폴더가 생성되고 그곳에 필요한 html 문서들이 만들어집니다.\n\n설치과정 스크린샷 모음\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  “문서 최종 수정일 : 2020-11-30”"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-autoscaling-limit": {
						"id": "1-compute-ncp-server-autoscaling-limit",
						"title": "Auto Scaling 서비스 제한사항",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_autoscaling_limit/",
						"content": "개요\n모든 클라우드 서비스의 핵심 중의 하나가 Auto Scaling이라고 할 수 있습니다.\n네이버 클라우드도 예외가 아닌데, Auto Scaling을 설정할 때 몇가지 제한사항이 있어서 정리해보았습니다.\n\n스펙 및 서비스 환경 제한 사항\n서버 스펙이나 서비스 환경과 관련한 제한 사항은 다음과 같습니다.\n\n\n  총 디스크 사이즈 150GB 이하 서버만 가능\n  Windows OS는 Windows 2012 (Classic 전용), 2016만 지원\n  Micro 서버는 불가\n  Local Disk 기반 서버는 불가\n  Global Internet Service 영역 내의 서비스 불가\n\n\n따라서 서버타입 기준으로  Auto Scaling 설정이 가능한 서버타입은 다음과 같습니다.\n\n  Classic : Compact, Standard\n  VPC : High CPU, Standard, High Memory\n\n\n\n\n\n\n  현재 [Auto Scaling] - [Launch Configuration] 화면과 가이드에 나오는 [High Memory 타입은 지원되지 않습니다]는 예전 메시지로 조만간 삭제될 예정이라고 합니다.\n\n\nOS 서버 이미지 제한 사항\ncentos-7.8-64, ubuntu-18.04 이 2가지 OS 이미지는 개인 회원은 KR-1 1세대 서버에서 생성이 불가능한 이미지입니다. 2세대 서버를 선택하시거나 KR-2에서 생성해야 합니다.\n\n설정 제한 사항\n다음으로 Auto Scaling 설정을 할 때 생성 가능한 최대 서버 수 등의 설정 제한 사항은 다음과 같습니다.\n\n\n  고객별 생성 가능한 Auto Scaling Group 최대 수: 100\n  고객별 생성 가능한 Launch Configuration 최대 수: 100\n  Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100\n  Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10\n  Auto Scaling Group당 생성 가능한 최대 서버 수: 30대\n  Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10\n\n\n\n  계정당 생성 가능한 최대 서버 대수 : 네이버 클라우드에서 한 계정당 생성할 수 있는 최대 서버 수 기본 50대입니다. 서버 수 한도를 조정하려면 고객지원으로 문의해야 합니다.\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview\n\n\n  문서 최종 수정일 : 2021-07-02"
					}
					
				
			
		
			
				
					,
					
					"3-security-ncp-security-acg-guide": {
						"id": "3-security-ncp-security-acg-guide",
						"title": "ACG(Access Control Group) 가이드",
						"categories": "3.security",
						"url": " /3.security/ncp_security_acg_guide/",
						"content": "개요\nACG(Access Control Group)는 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스로 AWS에서는 비슷하게 Security Group이라는 것이 있습니다.\n\n제한 사항\n\nVPC\n\n  VPC당 최대 500개까지 ACG 생성 가능\n  NIC당 3개의 ACG를 허용\n  Inbound / Outbound 각각 50개의 규칙 생성 가능\n\n\nClassic\n\n  계정당 최대 100개까지 ACG를 생성 가능\n  각 ACG에는 최대 100개까지의 규칙을 설정할 수 있음\n  서버는 최대 5개의 ACG에 중복 포함될 수 있음\n  서버가 생성될 시 선택한 ACG는 변경이 불가하며, 반납 전까지 해당 ACG 규칙을 적용 받게 됨\n\n\n\n  Classic 환경에서는 서버 자체에 할당되는 개념이었으나 VPC에는 NIC 즉, 네트워크 카드에 할당되는 개념이어서 VPC 환경에서는 NIC 당 최대 3개까지 ACG를 적용할 수 있다.\n\n\n기본 규칙\n\nDefault ACG\n기본적으로 추가되는 ACG\n\n\n  모든 들어오는 연결(inbound traffic)을 차단함\n  모든 나가는 연결(outbound traffic)을 허용함\n  Default ACG 내 속한 서버들끼리의 네트워크 양방향 통신(TCP, UDP, ICMP)이 허용됨\n  원격 접속 기본 포트 (Linux - 22, Windows - 3389)에 대한 TCP 허용됨\n\n\nVPC 화면\n\nInbound (기본 설정)\n\n\n\n  기본으로 생성된 ACG에는 위처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 허용되어 있는데 보안을 위해 이 항목을 삭제하고 아래와 같이 지정된 IP에서만 접속하도록 수정하는 것이 좋습니다.\n\n\nInbound (권장 설정)\n\n\nOutbound\n\n\nClassic 화면 (기본 설정)\n\n\n\n  기본으로 생성된 ACG에는 위처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 허용되어 있는데 보안을 위해 이 항목을 삭제하고 아래와 같이 지정된 IP에서만 접속하도록 수정하는 것이 좋습니다.\n\n\nClassic 화면 (권장 설정)\n\n\nCustom ACG\nDefault ACG 이외에 사용자가 추가하는 ACG\n\n\n  모든 inbound traffic을 차단함(규칙으로 명시되어 있지 않음)\n  모든 outbound traffic을 허용함(규칙으로 명시되어 있지 않음)\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-2-3.html\n\n\n  문서 최종 수정일 : 2021-09-30"
					}
					
				
			
		
			
				
					,
					
					"4-storage-ncp-storage-backup-guide": {
						"id": "4-storage-ncp-storage-backup-guide",
						"title": "백업 서비스 가이드와 신청 절차",
						"categories": "4.storage",
						"url": " /4.storage/ncp_storage_backup_guide/",
						"content": "개요\n백업 솔루션을 사용해 서버의 데이터 즉, 소스 등의 파일과 데이터베이스 데이터를 정기적으로 백업하고 보관하는 서비스입니다.\n\n이용 방법\n네이버 클라우드의 백업 서비스는 이용자가 직접 모든 과정을 마칠 수 없고, 고객센터에 백업신청서를 제출해야 백업이 진행됩니다.\n\n지원 OS와 DB\n\n  Centos : 6.3, 6.6, 7.2, 7.3\n  ubuntu : 16.04, 18.04\n  Windows : 2012 R2, 2016\n  mssql : 2008std, 2012std, 2014std, 2016std, 2016exp\n  mysql : 5.7.17, 5.6.34\n  모두 64bit만 지원\n\n\n백업 방식\n\n파일백업\n\n  일회성\n  1일 1회 전체 백업\n  1주 ~ 4주에 1회 전체 백업\n  1주 1회 전체 백업 및 1일 1회 증분 백업\n\n\nDB 백업\n\n  mssql 1일 1회 전체 백업\n  mssql 1주 1회 전체 백업\n  mssql 1주 1회 전체 백업 및 1일 1회 증분 백업\n  mysql 1일 1회 전체 백업\n  mysql 1주 1회 전체 백업\n\n\n\n  증분 백업(변경된 데이터만 백업)의 경우 DBMS는 정합성을 보장하나 파일에 대해서는 정합성을 보장하지 않음\n\n\n백업 신청 절차\n\n  네이버 클라우드 플랫폼 포털(https://www.ncloud.com)에 접속하여 로그인\n  고객지원 &gt; 자료를 클릭하여 네이버 클라우드 플랫폼 백업 서비스 신청서와 백업 Agent를 다운로드\n  다운로드한 신청서 양식의 내용에 예를 참고하여 알맞게 기입.\n  다운로드한 백업 Agent는 OS에 맞는 버전을 VM에 복사하여 설치\n  백업 Agent가 설치 완료되었다면 네이버 클라우드 플랫폼 포털 내 백업 상품 소개 페이지의 “이용 문의하기”를 클릭\n  문의하기 페이지에서 제목을 “백업서비스 신청“으로 기입하고 작성한 백업 서비스 신청서를 첨부하면 백업 신청이 완료\n\n\n백업 Agent 설치 방법\n\nWindows\n\n  원격 데스크톱을 이용하여 VM 서버에 원격 접속\n  다운로드한 백업 Agent 설치 파일(NCP_Backup_Windows.zip)을 VM 내 {==C:\\Temp==} 하위에 복사하여 압축을 풀면 NCP 이름으로 총 5개의 파일이 생성\n  NCP_Backup_Install.bat을 실행하면 자동으로 설치 및 구성이 진행되며 설치 완료\n  이후 백업 Agent 관련 파일들은 자동으로 삭제됨\n\n\n\n  백업 Agent설치 후 파일이 자동 삭제되기에 반드시 설치위치는 C:\\Temp에서 수행을 권고\n\n\nLinux\n\n  Winscp 등을 이용하여 VM 서버의 {==/tmp==} 하위로 백업 Agent 프로그램(NCP_Backup_Linux.tar.gz)을 복사\n  원격 접속 프로그램(ex.putty)을 이용하여 VM 서버에 원격 접속\n  백업 Agent 프로그램을 저장한 /tmp 폴더로 이동 후 tar xvfz NCP_Backup_Linux.tar.gz을 실행하여 압축 해제\n  NCP_Backup_Install.sh 파일을 실행하면 자동으로 백업 Agent 설치 및 구성이 완료\n  이후 관련 파일은 자동으로 삭제됨\n\n\n\n  백업 Agent설치 후 파일이 자동 삭제되기에 반드시 설치위치는/tmp에서 수행을 권고\n\n\n백업 Agent 정보\n\n백업 S/W\n\n  Quest Netvault(구 Dell Netvault)\n\n\n백업 S/W 통신 정보\n\n  TCP/UDP 20031~21631\n\n\n백업 프로그램 설치 위치\n\n  Linux: /usr/Netvault\n  Windows: C:\\Program Files (x86)\\Quest Software\\NetVault Backup\n\n\nSecure Zone에서 백업하기\n\n  Secure Zone에서 사용 가능한 Agent가 별도로 존재하지 않기 때문에, 프록시 구성을 하던가 해서 Agent를 설치, 실행해야 함.\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/storage-storage-5-1.html\n\n\n  문서 최종 수정일 : 2020-11-25"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-storage-add-guide": {
						"id": "1-compute-ncp-server-storage-add-guide",
						"title": "스토리지 추가 생성 기본 가이드",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_storage_add_guide/",
						"content": "개요\n네이버 클라우드에서 서버 생성 후에 스토리지를 추가 생성하는 경우가 있는데 이때 사용되는 스토리지는 Block Storage라고 해서 AWS의 EBS(Elastic Block Store)와 유사합니다.\n\n스토리지 추가 제약 사항\n\n\n  부팅 스토리지가 SSD인 경우, 추가 스토리지로 HDD, SSD 모두 추가할 수 있습니다.\n  부팅 스토리지가 HDD인 경우, HDD, SSD 모두 추가할 수 있으나 SSD 스토리지는 최신 서버에만 추가가 가능합니다. 서버 상세정보의 ‘SSD 스토리지 추가 여부’가 적용 가능인지 확인해야 합니다.\n  Micro 타입의 서버, Bare Metal 서버는 스토리지를 추가할 수 없습니다.\n\n\n추가 가능한 최대 사이즈와 개수\n스토리지는 최대 2,000GB를 지원하며, 서버 1대당 최대 16개의 스토리지를 이용할 수 있습니다. (단, Local Disk 서버 타입 및 2017년 1월 23일 이전에 생성된 서버에 대해서는 1,000GB까지 지원됩니다.)\n\n리눅스 OS 서버 이미지별 포맷 명령어\n리눅스는 OS 즉, 네이버 클라우드에서 제공하는 서버 이미지별로 추가된 스토리지를 포맷하는 명령어가 다릅니다.\n\n\n  CentOS 5.x: mkfs.ext3 /dev/xvdb1\n  CentOS 6.x: mkfs.ext4 /dev/xvdb1\n  CentOS 7.x: mkfs.xfs /dev/xvdb1\n  Ubuntu Server / Desktop: mkfs.ext4 /dev/xvdb1\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-4-1-v2.html\n\n\n  문서 최종 수정일 : 2020-11-19"
					}
					
				
			
		
			
				
					,
					
					"7-analytics-ncp-analytics-cloud-log-analytics-info": {
						"id": "7-analytics-ncp-analytics-cloud-log-analytics-info",
						"title": "Cloud Log Analytics에서 수집하는 로그 유형",
						"categories": "7.analytics",
						"url": " /7.analytics/ncp_analytics_cloud_log_analytics_info/",
						"content": "개요\nCloud Log Analytics는 네이버 클라우드 플랫폼의 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석하게 해주는 서비스입니다.\n\n로그 템플릿 종류\nCloud Log Analytics에서 수집하는 각 종 서비스의 로그 템플릿 종류는 다음과 같습니다.\n\n\n  Server syslog\n  Apache 로그(Access log, Apache Error Log)\n  MySQL 설치형 상품의 로그(Error Log, Slow Log)\n  Microsoft SQL Server 설치형 상품의 Error Log\n  Tomcat 로그(Catalina Log)\n  Windows 서버의 Event Log\n  Windows 서버의 각종 text 형식의 로그\n  Cloud DB for MySQL 로그\n  Cloud DB for MSSQL 로그\n  Cloud DB for MongoDB 로그\n  Application Server Launcher 로그\n  Application Load Balancer 로그\n  Search Engine Service 로그\n  Cloud Data Streaming Service 로그\n  Bare Metal Server 로그\n  그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다\n\n\n로그 보관 기간\n로그 데이터의 보관 기간은 30일로, 30일이 지난 데이터는 자동 삭제되며, 사전에 별도로 통지하지 않습니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/cla-cla-1-1.html\n\n\n  info “문서 최종 수정일 : 2021-12-07”"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-stop-price": {
						"id": "1-compute-ncp-server-stop-price",
						"title": "서버 정지 시 요금할인",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_stop_price/",
						"content": "개요\n네이버 클라우드에서는 서버를 정지할 경우 일부 타입을 제외한 대부분의 서버에 대해 운영체제 설치를 위해 제공된 기본 디스크 요금만 청구가 되어 요금 할인이 됩니다.\n\n추가 요금이 청구되는 서비스\n공인 IP, 로드밸런서, 추가 디스크, Security Monitoring, 추가 Network Interface 등 서버에 연결된 다른 유료 서비스의 경우 서버가 정지되어도 정상 청구됩니다.\n\n요금 할인 횟수와 서버 정지 기한\n\n  요금이 할인되는 서버의 경우 1회 최대 90일, 12개월 누적 최대 180일까지만 서버를 정지할 수 있습니다.\n  서버 정기 가능 기한을 넘긴 서버는 고객에게 통보 후 서버를 반납하게 됩니다.\n  서버를 반납하게 될 때 서버에 저장된 데이터는 네이버 클라우드에서 30일간 직접 백업하여 보관 후 삭제하게 됩니다.\n\n\n\n\n요금 할인이 적용되지 않는 서버 타입\n일부 서버들은 서버를 정지해도 요금 할인이 되지 않고, 서버가 가동 중일 때와 동일한 요금이 청구됩니다.\n할인이 적용되지 않는 서버 타입은 다음과 같습니다.\n\n\n  Micro 서버\n  High Memory 서버\n  GPU 서버\n  Virtual Dedicated Server\n  Baremetal 서버\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-1-1-v2.html\n\n\n  문서 최종 수정일 : 2020-11-13"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-spec-change": {
						"id": "1-compute-ncp-server-spec-change",
						"title": "서버 스펙 변경",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_spec_change/",
						"content": "개요\n네이버 클라우드에서는 기본적으로 서버 타입 간의 스펙 변경을 지원하지 않고, 동일한 타입 내에서의 스펙 변경만 지원합니다.\n\n\n  다른 타입의 스펙으로 변경하려면 [내 서버 이미지] 기능을 이용해서 서버 이미지를 생성한 다음, 다른 타입으로 서버를 새로 만들어야 합니다. 이때 IP 주소는 변경됩니다.\n\n\n\n\n\n  타입 간 스펙 변경이 가능한 경우 : 타입간 스펙 변경은 대부분은 불가능하나 Classic 1세대의 Compact 타입과 Standard 타입 간에는 스펙 변경을 할 수 있습니다.\n\n\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-1-1-v2.html\n\n\n  문서 최종 수정일 : 2021-07-02"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-server-micro-limit": {
						"id": "1-compute-ncp-server-micro-limit",
						"title": "Micro 타입 서버에서 사용할 수 없는 서비스",
						"categories": "1.compute",
						"url": " /1.compute/ncp_server_micro_limit/",
						"content": "개요\n네이버 클라우드에서 제공하는 서버 타입 중에서 Micro 타입의 서버는 신규 가입 후 최초 결제수단 등록월부터 1년간 무료로 제공되는 체험용 서버입니다.\n계정당 1대만 이용 가능하며 1년이 지나면 유료로 전환됩니다.\n\n제한되는 서비스\nMicro 타입의 서버에서 사용할 수 없는 서비스는 다음과 같습니다.\n\n\n  mssql\n  LAMP, WordPress, LEMP 등\n  Network Interface\n  Private Subnet\n\n\nMSSQL\nmssql 중에서 mssql 2017 Express은 무료로 제공되는 서비스이지만, mssql이 1년 무료제공 서버인 Micro서버에서는 설치가 되지 않기 때문에, compact 이상의 유료 서버를 이용해야 합니다.\n즉, mssql 2017 Express는 무료이나 서버와 그에 따른 하드 디스크 비용은 유료입니다.\n\nLAMP\nLAMP (Linux + Apache, Mysql, PHP)의 경우 Micro 타입의 서버에 설치를 할 수 없고, Standard 이상의 서버에서만 설치할 수 있는데, 대신 네이버 클라우드에서는 LAMP 등 많이 사용되는 오픈 소스 소프트웨어가 설치된 서버를 쉽게 이용할 수 있도록 해주는 서비스인 Application Server Launcher를 제공하고 있습니다.\n\nApplication Server Launcher에서는 원하는 소프트웨어의 이미지를 선택하기만 하면 쉽게 Micro 타입의 서버를 세팅하고 이용할 수 있습니다.\n\n\n  다만, Application Server Launcher에서 생성한 서버도 Micro 타입의 서버이기 때문에 계정당 1개만 제공되는 Micro 타입 서버 기준에 따라 Micro 타입의 서버는 더 이상 추가할 수 없습니다.\n\n\nApplication Server Launcher에서 OS버전(CentOS, Ubuntu)별로 제공되는 애플리케이션은 다음과 같습니다.\n\n\n  Drupal (CMS)\n  Joomla! (CMS)\n  Magento (E-Commerce)\n  Shadowsocks (VPN)\n  LAMP (Web Stack)\n  WordPress (CMS)\n  Jenkins (Dev Tools)\n\n\nPrivate Subnet\nPrivate Subnet을 구성해서 서버환경을 만들려고 해도 Micro 서버 타입은 Network Interface를 추가할 수 없고, 그에 따라 Private Subnet도 적용할 수 없습니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-1-1-v2.html\nhttps://guide.ncloud-docs.com/docs/asl-asl_console.html\n\n\n  문서 최종 수정일 : 2021-01-19"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-lamp-config-basic": {
						"id": "1-compute-ncp-lamp-config-basic",
						"title": "네이버 클라우드 LAMP 기본 환경 설정 정보",
						"categories": "1.compute",
						"url": " /1.compute/ncp_lamp_config_basic/",
						"content": "LAMP 기본설정\n\nNcloud(네이버 클라우드 플랫폼, 이하 네이버 클라우드)에서 제공하는 Application중에서 가장 대표적인 LAMP(Linux + Apache, Mysql, PHP)의 기본설정입니다.\n\n\n  “2020-12-03 현재 LAMP를 포함한 Application 이미지들은 Classic 환경에서만 이용 가능합니다.  VPC 환경에서는 아직 지원하지 않고 향후 업데이트 예정입니다”\n\n\nLAMP 홈디렉토리\n네이버 클라우드에서 Linux 서버를 세팅하게 되면 기본적으로 root 계정으로 접속이 됩니다.\n그래서 LAMP 서비스의 홈디렉토리도 /root/lamp로 설정됩니다.\n\nLAMP 서비스 홈디렉토리 : /root/lamp\n\n\nLAMP 서비스 전체 재시작\n네이버 클라우드에서는 LAMP 전체 서비스를 빠르게 재시작할 수 있는 기능을 제공하고 있습니다.\n\nLAMP 서비스 전체 재시작 명령 : /root/lamp/lamp_restart.sh\n\n\n위 명령을 실행하면 Apache 와 mysql이 순서대로 재시작됩니다.\n\nLAMP 서비스 설치 상태 확인\n네이버 클라우드에서는 LAMP 서비스들의 설치 정보를 확인할 수 있는 기능도 제공하고 있습니다.\n\nLAMP 설치 상태와 정보 확인 명령 : /root/lamp/lamp_info.sh\n\n\n위 명령을 실행하면 LAMP의 기본 웹사이트 경로, 웹사이트 기본 디렉토리, mysql 초기 비번 안내, Apache 버전, mysql 버전, PHP와 Zend 버전 정보 등을 확인할 수 있습니다.\n\nLAMP 웹사이트 기본 디렉토리\n네이버 클라우드에서 제공하는 LAMP의 웹사이트 기본 디렉토리 위치는 다음과 같습니다.\n\n웹사이트 기본 디렉토리 : /ncp/data/www\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docslamp-lamp-1-1.html\n\n\n  문서 최종 수정일 : 2020-12-03"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-lamp-config-ubuntu": {
						"id": "1-compute-ncp-lamp-config-ubuntu",
						"title": "LAMP(Ubuntu) 기본 명령어와 환경 설정 파일 위치",
						"categories": "1.compute",
						"url": " /1.compute/ncp_lamp_config_Ubuntu/",
						"content": "Apache 시작, 중지, 재시작\nApache 시작, 중지, 재시작 명령어는 OS별로 조금씩 다른데 Ubuntu의 경우에는 systemctl [stop|start|restart] {서비스명} 의 순서로 되어 있습니다.\n\nUbuntu\n- 중지 : systemctl stop apache2\n- 시작 : systemctl start apache2\n- 재시작 : systemctl restart apache2\n\n\nmysql 시작, 중지, 재시작\nmysql 시작, 중지, 재시작 명령어도 Apache와 마찬가지로 systemctl [stop|start|restart] {서비스명} 의 순서로 되어 있습니다.\n\nUbuntu\n- 중지 : systemctl stop mysql\n- 시작 : systemctl start mysql\n- 재시작 : systemctl restart mysql\n\n\nApache 환경 설정 파일\nApache의 기본 환경설정 파일은 CentOS의 경우 httpd.conf라는 파일로 간단하게 구성되어 있는데 Ubuntu의 경우에는 포트, 가상호스트, 로그 등 각각의 항목별로 파일이 나뉘어져 있습니다.\n\nUbuntu\n- 기본 설정 : /etc/apache2/apache2.conf\n- 포트 설정 : /etc/apache2/ports.conf\n- 가상호스트 설정: /etc/apache2/sites-enabled/000-default.conf -&gt; /etc/apache2/sites-available/000-default.conf\n- 로그 : /var/log/apache2\n- 기타 옵션 설정 :\n  /etc/apache2/mods-enabled/*.load -&gt; /etc/apache2/mods-available/*.load\n  /etc/apache2/mods-enabled/*.conf -&gt; /etc/apache2/mods-available/*.conf\n\n\nPHP 환경 설정 파일\nPHP의 환경 설정파일인 php.ini는  PHP버전에 해당 하는 디렉토리에 위치하고 있습니다.\nphp.ini : /etc/php/7.2/apache2/php.ini\n\n\nmysql 환경 설정 파일\n\nmysql 환경  설정파일인 my.cnf는 OS버전과 관계없이 /etc/mysql/my.cnf 에 위치하고 있으며, 실제로는 /etc/alternatives/my.cnf로 링크되어 있습니다.\nmy.cnf : /etc/mysql/my.cnf -&gt; /etc/alternatives/my.cnf\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/lamp-lamp-1-1.html\n\n\n  문서 최종 수정일 : 2020-11-13"
					}
					
				
			
		
			
				
					,
					
					"1-compute-ncp-lamp-config-centos": {
						"id": "1-compute-ncp-lamp-config-centos",
						"title": "LAMP(CentOS) 기본 명령어와 환경 설정 파일 위치",
						"categories": "1.compute",
						"url": " /1.compute/ncp_lamp_config_CentOS/",
						"content": "Apache 시작, 중지, 재시작\n\nApache 시작, 중지, 재시작 명령어는 CentOS 6에서 사용하던 것이 CentOS 7이 되면서 변경되었습니다.\nCentOS 6.x 이하에서는 service {서비스명} [stop|start|restart] 순서였다면 CentOS 7.X 에서는 systemctl [stop|start|restart] {서비스명} 의 순서로 바뀌었습니다.\n내용을 정리하면 다음과 같습니다.\n\nCentOS 6.x 이하\n- 중지 : service httpd stop\n- 시작 : service httpd start\n- 재시작 : service httpd restart\n\n\nCentOS 7.x\n- 중지 : systemctl stop httpd\n- 시작 : systemctl start httpd\n- 재시작 : systemctl restart httpd\n\n\nmysql 시작, 중지, 재시작\nmysql도 Apache와 마찬가지 방식으로 CentOS 6 이하와 CentOS 7에서 사용하는 명령어가 변경되었습니다.\n\nCentOS 6.x 이하\n- 중지 : service mysqld stop\n- 시작 : service mysqld start\n- 재시작 : service mysqld restart\n\n\nCentOS 7.x\n- 중지 : systemctl stop mysqld\n- 시작 : systemctl start mysqld\n- 재시작 : systemctl restart mysqld\n\n\nApache 환경 설정 파일\n\nApache의 환경 설정 파일은 CentOS의 버전과 관계없이 모두 동일합니다.\nhttpd.conf : /etc/httpd/conf/httpd.conf\n\n\nPHP 환경 설정 파일\nPHP의 환경 설정파일인 php.ini는  PHP버전에 해당 하는 디렉토리에 위치하고 있습니다.\nphp.ini : /etc/php/7.2/apache2/php.ini\n\n\nmysql 환경 설정 파일\n\nmysql 환경  설정파일인 my.cnf는 OS버전과 관계없이 /etc/mysql/my.cnf 에 위치하고 있으며, 실제로는 /etc/alternatives/my.cnf로 링크되어 있습니다.\nmy.cnf : /etc/mysql/my.cnf -&gt; /etc/alternatives/my.cnf\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/lamp-lamp-1-1.html\n\n\n  문서 최종 수정일 : 2020-11-13"
					}
					
				
			
		
			
				
					,
					
					"91-aws-aws-cloudwatch-log": {
						"id": "91-aws-aws-cloudwatch-log",
						"title": "AWS CLOUDWATCH LOG 수집 매뉴얼",
						"categories": "91.AWS",
						"url": " /91.aws/aws_CLOUDWATCH-LOG/",
						"content": "사전 작업\n\nIAM 계정생성 및 권한 부여\n\ncloudwatch log수집을 위해서는 서버 작업과 별도로 IAM 계정생성과 권한할당 작업을 선 진행하여야하며 작업이 완료된 후 계정의 액세스키, 비밀키를 발급 받는다.\n\n\n  \n    계정생성\n   계정생성- 계정이름 입력- 액서스 유형 Programmatic access 선택\n  \n  \n    권한설정\n  \n\n\n기존 정책 직접 연결 선택 - CloudWatchAgentServerPolicy정책 추가\n\n  키확인\n\n\n액세스 키 확인 및 비밀키 확인\n\n서버 작업\n\n설치 작업\n\n\n  awslogs 설치는 다음 명령어를 통해 설치\nyum install -y awslogs\n  \n    aws configure를 통한 IAM 키 입력\n\n    aws configure 명령어 입력 - 액세스키 요구 및입력 - 비밀키 요구및 입력(위 IAM계정의 키 입력)\n  \n\n\n설정 관련\n\n\n  \n    /etc/awslogs/awscli.conf\n\n    region = ap-northeast-2 추가 설정없이 리전만 로그 수집을 위한 리전으로 변경\n  \n  \n    /etc/awslogs/awslog.conf\n\n    해당 컨피그 파일의 제일 하단에 로그 수집 대상 로그를 아래의 형식으로 작성\n\n    [/var/log/messages] – 수집로그 경로와 파일 지정\n\n    datetime_format = %b %d %H:%M:%S (로그의 데이터 포맷 지정)\n\n    file = /var/log/messages (로그 파일 위치)\n\n    buffer_duration = 5000 (로그 이벤트를 일괄 처리하는 기간을 지정합니다. 최소값은 5000ms이고, 기본값은 5000ms입니다.)\n\n    log_stream_name = {instance_id} (대상로그 스트림 이름 지정{instance_id}, {hostname}, {ip_address})\n\n    initial_position = start_of_file\n\n    log_group_name = /var/log/messages(cloudwatch 로그 그룹네임 지정 )\n\n    time_zone=LOCAL\n\n    multi_line_start_pattern ={datetime_format} (로그 줄 단위 기준점. datetime_fomat 멀티라인 처리)\n  \n  \n    /var/log/awslogs.log\n\n    awslogs서비스 실행 후 발생되는 로그.\n  \n\n\n실행 및 자동실행 등록\n\n\n  실행 명령어 service awslogs start\n  리붓시 자동실행 등록 chkconfig awslogs on (amazon linux2 인 경우 systemctl enable awslogsd.service)\n\n\ncloudwatch 설정\n\n정상적으로 서버의 로그가 수집된다면 cloudwatch - log항목에서 서버에서 지정한 로그 그룹네임이 보이며 이를 클릭시 서버 인스턴스 ID별로 로그 수집되는 내역 확인 가능\n\n수집된 데이터는 대시보드를 통해 데이터를 보여주는기능은 바로 가능하나 이를 가지고 그래프를 통한 시각화를 할수 없어 지표를 통한 그래프를 생성하여야함.\n\n\n  \n    cloudwatch -로그- 로그그룹중 필터기능을 쓸 지표선택 -지표 필터 클릭\n  \n  \n    지표 필터 추가 버튼 클릭\n  \n  \n    필터링 하고자하는 값을 넣고 [정규식지원]패턴 테스트 후 지표할당 클릭\n  \n  \n    이후 지표 네임스페이스는 로그 그룹 네임 중 추출하고자하는 지표영역 지표이름은 해당 지표를 선택\n  \n  \n    cloudwatch - 지표 선택 - 모든 지표에서 로그 그룹 필터를 적용한 로그 그룹의 incomingLogEvents선택\n  \n  \n    그래프로 표시된 지표 탭 선택 - 필터가 적용된 그래프가 나오며 그래프의 작업 대시보드 추가를 선택하여\n\n    대시보드로 그래프 등록\n  \n\n\n오류 대처 법\n\n로그 수집이 되지 않고 awslogs.log파일에 아래와 같이 로그 가 찍히는 경우 처리 방안\n\n\n  reason: timestamp is more than 2 hours in future.\n\n\n\n  /var/lib/awslogs/agent-state를 삭제\n\n\n해당 방법으로 처리시 수집되는 로그가 처음부터 다시 로그가 수집됩\n\n\n  \n    sqlite3 명령어를 통해 agent-state 오류 처리\n  \n  sudo sqlite3 /var/lib/awslogs/agent-state\n  select * from stream_state; 통해 문제가 되는 소스ID확인\n  select * from push_state where k=”확인된 소스ID”;\n  update push_state set v=’… insert new value here …’  where k=’7675f84405fcb8fe5b6bb14eaa0c4bfd’;\n  service awslogs restart\n\n\n참고 URL\n\nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/AgentReference.html\nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html\nhttps://stackoverflow.com/questions/40604940/cloudwatch-logs-acting-weird"
					}
					
				
			
		
	};
</script>
<script src="/js/lunr.min.js" charset="utf-8"></script>
<script src="/js/search.js" charset="utf-8"></script>
			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="edit-footer"><a class="editor-link btn" href="cloudcannon:collections/_data/footer.yml" class="btn" style="padding: 5px;"><strong>&#9998;</strong> Edit footer</a></p>
		<ul class="footer-links">
			
				<li><a target="_blank" href="https://www.facebook.com/3rdeyesys" class="Facebook-icon">
					
						
		<svg class="facebook" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M19,4V7H17A1,1 0 0,0 16,8V10H19V13H16V20H13V13H11V10H13V7.5C13,5.56 14.57,4 16.5,4M20,2H4A2,2 0 0,0 2,4V20A2,2 0 0,0 4,22H20A2,2 0 0,0 22,20V4C22,2.89 21.1,2 20,2Z" /></svg>
	

					
					</a></li>
			
				<li><a target="_blank" href="mailto:biz@3rdeyesys.com" class="Email-icon">
					
						
			<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/><path d="M0 0h24v24H0z" fill="none"/></svg>
		

					
					</a></li>
			
		</ul>
		<p class="copyright">&copy; 3rdeyesys 2021. All rights reserved.</p>
	</div>
</footer>

		<script>
			$(function() {
				$('a[href*=\\#]').not(".no-smooth").on('click', function(event){
					var el = $(this.hash);
					if (el.length > 0) {
						// event.preventDefault();
						$('html,body').animate({scrollTop:$(this.hash).offset().top - 50}, 500);
					}
				});

				$('svg').click(function() {
					$(this).parent('form').submit();
				});
			});

			document.getElementById("open-nav").addEventListener("click", function (event) {
				event.preventDefault();
				document.body.classList.toggle("nav-open");
			});
		</script>
	</body>
</html>
